{"text": "Levakov, Gidon and Rosenthal, Gideon and Shelef, Ilan and Raviv, Tammy Riklin and Avidan, Galia\nHum Brain Mapp, 2020\n\n# Title\n\nFrom a deep learning model back to the brain\u2014Identifying regional predictors and their relation to aging\n\n# Keywords\n\nbrain aging\nconvolutional neural networks\ndeep learning\ninterpretability\nneuroimaging\n\n\n# Abstract\n \nWe present a Deep Learning framework for the prediction of chronological age from structural magnetic resonance imaging scans. Previous findings associate increased brain age with neurodegenerative diseases and higher mortality rates. However, the importance of brain age prediction goes beyond serving as biomarkers for neurological disorders. Specifically, utilizing convolutional neural network (CNN) analysis to identify brain regions contributing to the prediction can shed light on the complex multivariate process of brain aging. Previous work examined methods to attribute pixel/voxel\u2010wise contributions to the prediction in a single image, resulting in \u201cexplanation maps\u201d that were found noisy and unreliable. To address this problem, we developed an inference scheme for combining these maps across subjects, thus creating a population\u2010based, rather than a subject\u2010specific map. We applied this method to a CNN ensemble trained on predicting subjects' age from raw T1 brain images in a lifespan sample of 10,176 subjects. Evaluating the model on an untouched test set resulted in mean absolute error of 3.07\u2009years and a correlation between chronological and predicted age of   r   =\u20090.98. Using the inference method, we revealed that cavities containing cerebrospinal fluid, previously found as general atrophy markers, had the highest contribution for age prediction. Comparing maps derived from different models within the ensemble allowed to assess differences and similarities in brain regions utilized by the model. We showed that this method substantially increased the replicability of explanation maps, converged with results from voxel\u2010based morphometry age studies and highlighted brain regions whose volumetric variability correlated the most with the prediction error. \n  \nThe current work has two main contributions, a CNN ensemble shown to estimate \u201cbrain age\u201d from structural MRI with a mean absolute error of ~3.1\u2009years, and a novel scheme highlightighting brain regions contributing to the age prediction. This scheme results in explanation maps showing consistency with the literature, and as sample size increases, these maps show higher inter\u2010sample replicability. Cerebrospinal fluid cavities, possibly reflecting general atrophy, were found as a prominent aging biomarker.   \n \n\n# Body\n \n## INTRODUCTION \n  \nThe human brain undergoes complex structural changes across the lifespan (Sowell, Thompson, & Toga,  ). These include widespread synaptic pruning and myelination from early life through puberty and neurodegenerative processes, such as ventricle expansion and cortical thinning that peaks with aging. The course and extent of these changes are not uniformly distributed across the brain (Storsve et al.,  ). Thus, for example in healthy aging, higher atrophy rates were reported in the hippocampus, while regions like the early visual cortex remain relatively intact (but see Lemaitre et al.,  ). Nevertheless, studies that examined the correspondence between brain structure and chronological age provide inconsistent findings. Such inconsistencies may be related to the specific parcellation schemes employed (Mikhael & Pernet,  ), surface\u2010based structural measurements (Lemaitre et al.,  ), global volume covariates (J\u00e4ncke, M\u00e9rillat, Liem, & H\u00e4nggi,  ), or specific statistical assumptions regarding the changes of brain\u2010aging rate across lifespan (e.g., linear, polynomial; Ziegler et al.,  ). These concerns add to discrepancies due to the usage of relatively small samples and different statistical procedures, which together impede the attempts to characterize the relation between aging and structural changes in the brain. \n\nStudying brain aging has important implications for differentiating typical and pathological aging. Alzheimer's disease (AD), the most prevalent type of dementia, affects about 22% of the population over the age of 75 (in the United States, 2010; Hebert, Weuve, Scherr, & Evans,  ). AD patients exhibit extensive cell loss in cortical and subcortical regions, but such findings are also evident in typical aging (Barnes et al.,  ; Ledig, Schuh, Guerrero, Heckemann, & Rueckert,  ). Moreover, behavioral manifestations such as cognitive decline and memory deficits that accompany AD are also apparent in aging in the absence of AD (Cardenas et al.,  ; Koen & Yonelinas,  ). Thus, a reliable measure of typical brain aging may be beneficial in order to better distinguish between the two (Lorenzi, Pennec, Frisoni, & Ayache,  ). \n\n### Predicting age from structural brain imaging using machine learning \n  \nRecent growth in data availability and advancements in the field of machine learning (ML), applied to the analysis of structural imaging, have allowed addressing regression problems such as brain age prediction based on preselected sets of anatomical features or regions of interest (ROIs). Predicting age from brain anatomy enables to estimate a measure of \u201cbrain age\u201d which is independent of one's chronological age. Different studies generally reveal that an over\u2010estimation of that measure is associated with neurodegenerative diseases and various clinical conditions and might even predict mortality (Cole et al.,  ). Hence, brain age estimation could be used as a potential biomarker for brain health (Cole & Franke,  ). While ML methods were shown to provide a mean error of ~5\u2009years (Cole & Franke,  ), age predictions are largely dependent upon the selection of features that would be used as input to the algorithm. \n\n\n### Application of deep convolutional neural network for predicting \u201cbrain age\u201d \n  \nDeep convolutional neural network (CNN) has enabled a major leap in many applications including neuroimaging analysis, among others, by learning the features, or representation from the raw data, that is, an image or a volume (Goodfellow, Bengio, & Courville,  ). CNNs are biologically inspired algorithms in which the connectivity between the different neurons implements a convolution operation. The neurons are ordered in stacked layers in a hierarchical deep formation and hence they are termed deep CNN (LeCun, Bottou, Bengio, & Haffner,  ). CNN\u2010based models achieved state\u2010of\u2010the\u2010art results in serval neuroimaging tasks including cortical segmentation and tumor detection (Kamnitsas, Chen, & Ledig,  ; Pereira, Pinto, Alves, & Silva,  ) and were recently applied to age prediction from raw T1 magnetic resonance imaging (MRI) images (Cole et al.,  ). Nonetheless, significant improvement can still be achieved by substantially increasing the sample size and utilizing practices such as prediction based on an ensemble of models. Both of these approaches were shown to produce a remarkable improvement in other visual task domains (Lee, Purushwalkam, Cogswell, Crandall, & Batra,  ). \n\n\n### Model interpretability\u2014Which brain regions underlie a given prediction? \n  \nA major limitation of studies utilizing CNNs pertains to the issue of the model interpretability. While CNNs have provided high accuracy for age prediction (Cole & Franke,  ; Qi, Du, Zhuang, Huang, & Ding,  ), it is typically difficult to identify the features that enabled a given prediction. Several recent studies attempted to identify or visualize intermediate representations of the CNN (Olah et al.,  ), but still, the size and complexity of the networks make it a challenging task. In the context of structural neuroimaging analysis, there might be an advantage to focus on the input level since it could be directly related to specific brain structures. Knowing which image parts, or in the current research, brain regions or neural attributes, contribute most to the prediction have theoretical, as well as translational value. A possible approach to this issue is the usage of \u201csaliency maps\u201d or \u201cexplanation maps\u201d indicating the influence of each voxel in the input volume on the model's prediction. Such a map can be generated by calculating the partial derivative of each voxel in the input volume with respect to the model's output (Simonyan, Vedaldi, & Zisserman,  ; Springenberg, Dosovitskiy, Brox, & Riedmiller,  ). However, local gradients in nonlinear functions such as CNN were previously shown to be noisy. Recent work has demonstrated that this could be partially addressed by repeatedly calculating and averaging several explanation maps derived from the same input after adding random noise to it (Smilkov, Thorat, Kim, Vi\u00e9gas, & Wattenberg,  ). Nevertheless, these explanation maps are typically created on a single sample, hence they provide only a subject\u2010specific, rather than a population\u2010based explanation (Yang, Rangarajan, & Ranka,  ; but see Bermudez et al.,  ; Wang et al.,  ). In a task or a model where large variability exists in these explanation maps, that is, if different subject\u2010level maps highlight different regions, any translational or theoretical conclusion could only be subject\u2010specific. \n\n\n### The current study \n  \nIn light of the limitations outlined above, we aimed to examine brain aging using a CNN model for \u201cbrain age\u201d prediction and identify the brain structures that supported this prediction. Therefore, this study has two important contributions. The first is the prediction model, which is composed of an ensemble of multiple CNNs trained to predict individuals' age from minimally processed T1 MRI scans. The model was trained and tested on an aggregated lifespan sample of 10,176 subjects. These were collected from several large\u2010scale open\u2010access databases (  n   =\u200915) in order to produce a result that is more robust to scanner's type, field strength, and resolution. Second, we provided and validated a novel scheme for identifying the importance of the various anatomical brain regions to the age prediction by aggregating multiple subject\u2010level explanation maps, creating a population\u2010based map. Combining subject\u2010level maps into a population\u2010based map is done by image realignment after training the model, thus no special preprocessing or architecture modification is required, as opposed to previous work (Ito et al.,  ). We empirically show that this significantly improves the explanation maps and allows the inference from the model back to the brain's anatomy. Finally, we demonstrate how the usage of an ensemble of CNNs which increases the prediction accuracy, also allows to evaluate the diversity or similarity of independently trained models, to asses model uncertainty, and to examine the extent to which different models exploit similar brain regions for the age prediction. \n\n\n\n## MATERIALS AND METHODS \n  \n### Datasets \n  \nTo train a model that would be more robust to different sites and scanning protocols, we collected a sample of 10,176 T1w MRI brain scans of individuals ranging between 4 and 94\u2009years old from various open databases (  n   =\u200915), acquired at different locations, scanners, and scanning parameters. To examine whether the trained model presents a dataset\u2010specific bias, that is, over or under\u2010estimated age within a specific set, we examined the mean signed error for each study. The analysis was conducted within the test set and was limited for studies with more than 15 test samples (4 excluded, 11 remained). Several databases from longitudinal studies consist of brain scans acquired at several time\u2010points. For these databases, we only used scans of the first time point to avoid data leakage between the train and validation/test sets. Three exclusion criteria were applied to all subjects: missing age report, major artifacts in a visual inspection of the T1 volume and diagnosis of AD or another form of dementia. The complete list of studies, age, and gender distributions are reported in Table  . \n  \nList of all studies which comprise the dataset \n    \n\n### Data preprocessing \n  \nTo minimize the model reliance on preprocessing steps such as image realignment and registration that are both computationally intensive and time\u2010consuming, we designed a minimal preprocessing procedure. To ensure that the model \u201cbrain age\u201d estimation would rely solely on regions within the skull, the only substantial preprocessing step was the removal of extra\u2010cranial regions from the volume. Thus, the preprocessing procedure included four stages: applying a coarse (90\u00b0) rotation so that all the volumes would appear in similar L\u2013R, A\u2013P, S\u2013I orientation (FSL   fslreorient2std   tool; Woolrich et al.,  ), skull removing tool (ROBEX; Iglesias, Liu, Thompson, & Zhuowen,  ), volume resize to standard size (90, 126, 110) and volume standardization (  \u03bc   =\u20090,   \u03c3   =\u20091). Resizing of each volume was implemented by applying an identical scaling factor to all three dimensions, such that brain voxels (intensity >0) would occupy the maximum portion within the final volume (90, 126, 110). For each volume, voxels' intensities were standardized by a subtraction of the volume's mean intensity followed by division by the intensity's   SD  . \n\n\n### Data augmentation \n  \nHead orientation, the field of view and the level of signal to noise ratio may differ between scans even if they were acquired by the same machine and are of the same subject. To improve the robustness of the models to these variations, we augmented the training data by randomly manipulating the head position, size, and noise level. This procedure was previously shown to improve generalization and avoid overfitting (Simard, Steinkraus, & Platt,  ). Specifically, the series of transformation to the brain image included a rotation in the x/y/z\u2010axis  , shifting   voxels, scaling   and an addition of random noise  . Data augmentation was applied only during training and was not used for validation/test. The optimal augmentation parameters were chosen as the ones that maximized the validation accuracy using a random hyperparameter search. \n\n\n###  CNN   architecture \n  \nThe CNN models were implemented using Keras (Fran\u00e7ois Chollet and contributors,  ) with TensorFlow (Abadi et al.,  ) backend. Each 3D CNN model was trained separately to predict age from a T1 MRI. The input for each network was a 3D volume, of size [90, 126, 110] and the output was a single scalar representing chronological age (years). The model was composed of two blocks, each with a batch normalization layer (Ioffe & Szegedy,  ) followed by two 3D convolutional layers and a max\u2010pooling layer. The two blocks were followed by two fully connected layers (FC). All layers, but the last fully connected one were followed by a ReLU nonlinear activation (Nair & Hinton,  ). To reduce overfitting, we added dropout layers after the convolutional layer and before the last layer for the training stage (see Figure   for the complete architecture). The loss function for each CNN was the mean squared error between the real and predicted age. The network architecture was designed using random hyperparameters search and was chosen as the one that maximized the accuracy within the validation set. \n  \nNetwork architecture for age prediction. (a) The detailed architecture of the network used for age prediction from 3D T1 MRI volume. BatchNorm = batch normalization, Conv = convolutional layer, ReLU = rectified linear unit, FC = fully connected layer. (b) The ensemble procedure combining the output of 10 separately trained CNNs (\u0393 ) using linear regression to create the final age prediction \n  \n\n### The ensemble model \n  \nThe ensemble in the current work included multiple 3D CNNs (  m   =\u200910) each trained separately to predict age from a T1 MRI. As in previous work utilizing CNNs (Lakshminarayanan, Pritzel, & Blundell,  ; Lee et al.,  ), ensemble models differ only in their random weight initialization. Hence, they had identical architecture and were trained on the same samples. We picked   m   =\u200910 due to consideration of training time given the large number of parameters in a 3D CNN and the large training set. After each network was independently trained, a linear regression model for age prediction is learned from the outputs of the 10 networks using the same training set (see Figure  ). The similarity of prediction error among models was tested using the signed error correlation between each two networks within the test set. \n\n\n### Performance metrics \n  \nAll databases were randomly divided into training (90%), validation (5%), and test (5%) sets. The training set was used to train each network separately and to find the optimal ensemble weights. The validation set was used for hyperparameters tuning, for example, augmentation and network's architecture parameters, and to assess over\u2010fitting. All performance measures were calculated on the untouched test set. The prediction was evaluated using mean absolute error (MAE) and the Pearson correlation coefficient between the network prediction and the chronological age values. \n\n\n### Ensemble variability and uncertainty estimation \n  \nA recent work by Lakshminarayanan et al. ( ) pointed out that prediction variability within an ensemble could be utilized to evaluate uncertainty in neural networks. Here for each subject, uncertainty was quantified as the   SD   of the signed prediction error within the ensemble. In all analysis, uncertainty was evaluated within the test set. To compare uncertainty to available training sample and prediction error in different age ranges, we divided the 5\u201385 age range to 16 bins of 5\u2009years each. Then, for each age range, we calculated the training sample size, mean uncertainty within the test set and the mean absolute error. \n\n\n### Individual explanation maps \n  \nWe employed the SmoothGrad method (Smilkov et al.,  ) that was implemented using iNNvestigate (Alber et al.,  ). This is a gradient\u2010based method in which a given input image is first distorted with random noise from a normal distribution   N  (  \u03bc   =\u20090,   \u03c3   =\u20090.1), then the partial derivative of each voxel is computed with respect to the trained model's output. This was repeated several times (  k   =\u200932), then the produced gradient maps were averaged. We used partial derivative following Adebayo et al. ( ) work that demonstrated that it best captures the CNN's training process. \n\n\n### Aggregating explanation maps across samples \n  \nFirst, the models preprocessed input was transformed into the raw anatomical space using FSL FLIRT (Jenkinson, Bannister, Brady, & Smith,  ) followed by surface\u2010based nonlinear registration to the MNI space using Freesurfer (Greve & Fischl,  ). The transformations were computed on the T1 images, then applied to the explanation maps. The complete pipeline was created using Nipype (Gorgolewski et al.,  ). Next, each volume was standardized (  \u03bc   =\u20090,   \u03c3   =\u20091), and smoothed with a 3D Gaussian using Scikit\u2010image (Full width at half maximum = 4; van der Walt et al.,  ). Finally, all volumes were averaged to create population\u2010based explanation maps. In line with previous work, we used the absolute value of the resulting maps (Ancona, Ceolini, \u00d6ztireli, & Gross,  ). To identify regions with the highest contribution to the model's prediction, we threshold the map, keeping only 1% of the voxels with the highest gradient value (see Figure  \u2014for the inference scheme). To create an ensemble population\u2010based map, we aggregate these population\u2010based maps generated for each of the 10 CNN by taking the median of each voxel across the 10 maps. We will refer to the statistics obtained for these explanation maps, which is the standardized partial derivative, as an   explanation score   (ES). \n  \nA layout of the inference scheme. For a subset of   n   subjects, an explanation map was computed, representing the contribution of each voxel to the model's output. Each saliency map was first registered to the subject anatomical image, then it was transformed to the MNI space. Next, each volume was smoothed with a 3D Gaussian. Finally, all the volumes were averaged to create a population\u2010based explanation map \n  \n\n### Assessing the similarity of explanation maps within the ensemble \n  \nTo assess the diversity among independently trained CNNs, or the extent to which different CNNs utilize different brain regions for the prediction, we examined the similarity among their explanation maps. Specifically, the similarity between each pair of population\u2010based explanation maps (  n   =\u2009100) was evaluated with two measures: Dice similarity (Zou et al.,  ) and the modified Hausdorff distance (MHD; Dubuisson & Jain,  ) on the threshold maps. Maps thresholding was generated by taking the absolute value of each population\u2010based map, computing the fifth percentile of the ES within the brain mask and creating a binarized map for super\u2010threshold values:  . For each pair of binarized maps, the Dice coefficient was defined as  , where   is the number of overlapping super\u2010threshold voxels in both maps, and |  X  | and |  Y  | are the number of super\u2010threshold voxels for maps   X   and   Y  , respectively. MHD was derived by first finding the surface for each cluster of super\u2010threshold voxels within each map by using a gradient\u2010based edge detector. Then, the MHD, or the symmetric average surface distance was calculated as follows: where   is the Euclidian distance,   M   is the number of voxels in the surface map   X   and   x   and   y   are points on the surface in maps   X   and   Y  , respectively. Both the MHD and Dice coefficients were calculated for each pair of maps creating a distance/similarity matrix. The mean distance/similarity was calculated by taking the mean over the lower triangle of that matrix. \n\n\n### Relating contribution to specific tissues and brain structures \n  \nTo obtain a general view of the features utilized by the model, we first segmented the brain volume to four classes of tissue type: cerebrospinal fluid (CSF) and choroid plexus, white matter (WM), subcortical gray matter (GM), and cortical GM. These were determined by applying the Desikan\u2013Killiany Atlas (Desikan et al.,  ) using Freesurfer on the MNI template. Taking the calculated ensemble population\u2010based explanation map, we devised a volume\u2010normalized class ES by dividing the mean ES in each class by the total class volume. The resulting class scores were reported as a percentage of the sum of class scores. Next, to identify the specific brain regions that contributed the most to age prediction, we identified clusters of voxels in the threshold map (first percentile) using FSL cluster (Woolrich et al.,  ). For each cluster, we report the name of the brain region, its MNI coordinates, the cluster size and peak ES within the cluster. Brain regions were identified by locating the pick value of each cluster in the Desikan\u2013Killiany Atlas for GM structures and with the ICBM\u2010DTI\u201081 Atlas (Mori, Wakana, Van Zijl, & Nagae\u2010Poetscher,  ) for WM structures. Since many of the clusters were located within CSF spaces, whose subparts are poorly delineated in most parcellation, we manually identified subdivisions of the cisterns and ventricles. The unthresholded population\u2010based maps for each of the 10 CNN and the ensemble map are available at Neurovault (Gorgolewski et al.,  ;  ). \n\n\n### Validating the population\u2010based inference scheme \n  \n#### Replicability of the produced explanation map as a function of sample size \n  \nTo examine whether creating explanation maps based on a larger population would increase the split\u2010sample similarity, two population\u2010level explanation maps were created by sampling   m   subjects (  m   =\u20091, 6, 11, \u2026, 101) with replacement from two groups. The groups were created by randomly splitting to half, a sample of 200 subjects from the test and validation sets. Each map was thresholded, binarized (see Section  ) and the Dice similarity and the MHD were calculated between the two maps as a function of the sample size   m  . The procedure was repeated 100 times, and for each iteration, the 200 subjects were randomly assigned to the two groups. This test was repeated independently for each population\u2010based explanation map derived from the 10 CNNs. \n\n\n#### Similarity between explanation maps and voxel\u2010based morphometric meta\u2010analysis \n  \nTo examine whether the derived explanation map elicits similar regions to those detected with established methods, we compared it with a baseline obtained from studies that use voxel\u2010based morphometry (VBM; Ashburner & Friston,  ) to test structural age\u2010related changes. Briefly, in the VBM method, a mass\u2010univariate test between the tissue composition of any voxel in the brain and a given external variable (age) is conducted. To address the differences in brain position and anatomy, all brain volumes were normalized to a common space and then smoothed by a Gaussian kernel to account for small registration differences. In the current study, we used a published activation likelihood estimation (ALE) meta\u2010analysis of age VBM studies (Vanasse et al.,  ). Here, by utilizing peak reported coordinates from several VBM studies (  n   =\u200943), the ALE analysis assigns each voxel the probability that it lies within a reported peak (Laird, Bzdok, Kurth, Fox, & Eickhoff,  ). The ALE value across all the superthreshold (first percentile) voxels in the ensemble population\u2010based explanation map was averaged. This empirical value was compared to a null distribution created by randomly sampling 1% of the voxels within the brain mask. \n\n\n#### Specificity of the regions obtained in the analysis to the employment of the current model \n  \nTo evaluate the contribution of the regions discovered using the population\u2010based explanation map to the prediction of the current model, we examined how variability in their age\u2010controlled volume correlated with the model's prediction error. Regional volumes of cortical and subcortical areas were extracted using the Desikan\u2010Killiany atlas (Desikan et al.,  ) computed using Freesurfer following by regressing out the total intracranial volume (Voevodskaya et al.,  ). Next, subjects' chronological age was further regressed out from these values to produce the age\u2010normalized volume. Prediction error was formulated as the signed difference between the chronological age and the predicted age. The test was conducted separately for each anatomical ROI in the parcellation. Specific ROIs within the Desikan\u2013Killiany parcellation, such as WM hyperintensities and the fifth ventricle, exist for only some of the subjects (  n   =\u2009619; from the test/validation sets), and thus were subsequently excluded (9 excluded, 98 remained; see Figure S  for the complete list). \n\n\n\n\n## RESULTS \n  \nWe start by presenting the model's ensemble performance for predicting subject chronological age from their T1 structural images on an unseen test set (  N   =\u2009526). Then, using a novel inference scheme, we locate the anatomical regions that contributed the most to the model's prediction. We validate the robustness of our inference scheme in three ways. First, we demonstrate that it substantially increases reliability compared to previous methods, creating more coherent and localized explanation maps. Second, we quantitatively compare these explanation maps to age voxel\u2010based morphometric studies, demonstrating significant overlap with a simple baseline model. Finally, we demonstrate that this approach enables to gain specific insights about the model by identifying brain regions for which the model exhibits the highest correlation to inter\u2010subject volumetric variability. \n\n### Estimating \u201cbrain age\u201d \n  \nSeveral attempts were previously made to identify the relation between chronological age and brain structure, using various feature extraction techniques, advanced preprocessing methods and a relatively limited sample size (Irimia, Torgerson, Goh, & Van Horn,  ; Kandel, Wolk, Gee, & Avants,  ; Shamir & Long,  ). Here, we build upon recent progress in utilizing CNNs for predicting chronological age from raw structural brain imaging (Cole & Franke,  ) and introduce substantial improvements using an ensemble of models. In the current work, 10 randomly initialized CNNs were separately trained. The mean MAE across networks was 3.72\u2009years (\u00b10.17), and the Pearson correlation between the predicted and the chronological age was 0.97 (\u00b10.001). Next, a simple linear regression model was trained on the output of each network to find an optimal linear combination between them, yielding an MAE of 3.07 and a Pearson correlation of 0.98 to the chronological age (Figure  ; see Figure S  for evaluation per dataset). To demonstrate the prediction similarity among all CNNs, evident in the ensemble prediction gain, we tested the signed error correlation between each two networks within the test set. The mean correlation coefficient value was 0.73 and the   SD   was 0.09 (see Figure S ). A model dataset\u2010specific bias was found only for the SLIM dataset, in which age was over\u2010estimated in 1\u2009year (  t   =\u20092.61,   p   =\u2009.01). All other datasets did not present such bias (all   t  's\u2009<\u20091.51, all   p  's\u2009>\u2009.14; see Figure S ). An analysis of MAE as a function a training sample and age range is included in the supplementary section (Figures S  and S , respectively). \n  \nRegression plot of the chronological age compared to the model's prediction for the test set. The main plot depicts the Pearson correlation coefficient between the chronological and the predicted age; the Pearson correlation coefficient (  r  ) and the mean absolute error (  MSE  ) are indicated on the plot. The data points are presented with partial transparency thus overlapping points are shown in darker gray. The top and right panels of the figure depict histograms and kernel density plots of the distribution of the chronological age and the predicted age (respectively) obtained in the test set \n  \n\n### Ensemble variability and uncertainty estimation \n  \nApart from a prediction gain, the use of an ensemble provides a simple way to evaluate prediction uncertainty (Lakshminarayanan et al.,  ). Model uncertainty can be viewed as the lack of confidence in the prediction made, given the inability of the model to capture the true data generating process. Here, uncertainty was measured by calculating the prediction variability within the ensemble. Since the uncertainty metric aims to evaluate the lack of confidence in the prediction, it is expected to be correlated with the prediction error (Kendall & Gal,  ). Accordingly, we found a significant correlation between the MAE and uncertainty (  r   =\u20090.398,   p   <\u2009.001; Figure S ). We additionally examined whether uncertainty would be higher for age ranges where less training data is available (Gal & Ghahramani,  ). We found the maximum uncertainty in the 30\u201335 age range where the availability of data samples was more limited. The opposite was found for the 10\u201325 and the 65\u201375 age ranges that had the largest sample size (see Figure S ). \n\n\n### From the model to the brain\u2014A novel inference scheme \n  \nBuilding upon previous attempts to assign pixel\u2010wise (or voxel\u2010wise) explanation measures to a model's prediction (Smilkov et al.,  ), we propose that creating explanation maps based on a population, rather than on a specific sample, may substantially improve the coherence and reliability of these maps. We create these maps for each of the 10 independently trained CNNs and examine their similarity. Then, using an aggregated map across all 10 networks we present the brain regions that contributed the most to predicting age. \n\n#### Assessing the similarity of explanation maps within the ensemble \n  \nExplanation maps for the 10 CNNs, averaged across 100 subjects from the test/validation set were produced to create a population\u2010based map (see Section  ; Figure S ). First, to assess the similarity between each pair of these produced maps among the 10 independently trained networks, each map was thresholded (fifth percentile) and binarized, then the Dice coefficient similarity measure was computed for each pair of maps (Figure S ). We found a significant Dice similarity across all 45 possible pairs (Dice coefficient:   m   =\u20090.17,   SD   =\u20090.058; binomial test:   p   <\u2009.001). Since Dice similarity fails to capture the relation between two maps that are adjacent in the Euclidean space but nonoverlapping, we additionally computed the MHD (Dubuisson & Jain,  ), taking the symmetric average surface distance, among all pairs. We found that the mean MHD among all possible pairs was 6.44\u2009mm (  SD   =\u20091.22). Thus, even though these different population\u2010based maps were derived from independently trained networks, there is a moderate, significant, overlap between them. The fact that this overlap is merely moderate coincides with the prediction differences that allow the accuracy gain in ensemble prediction. \n\n\n#### Mapping the anatomical regions underlying \u201cbrain age\u201d prediction \n  \nAfter estimating the similarity among the different explanation maps for the 10 CNNs, we created an ensemble population\u2010based map by taking the median value for each voxel across all networks. We report how the ES is distributed among different tissue types, and among different anatomical regions in order to examine their contribution for age prediction. Testing the volume\u2010normalized contribution of each tissue type, we found that cavities containing CSF and choroid plexus had the highest contribution (35.62%), followed by subcortical GM (27.66%), WM (19.49%), and finally, cortical GM (17.23%) which contributed the least. Table   presents the location of clusters (>100 voxels) in the threshold explanation map (first percentile). We found that the structures contributing most to age prediction in our model were the ventricles, subarachnoid cisterns, and their borders (see Figure  ). Specifically, the fourth ventricle, the ambient cistern bilateral to the midbrain, the superior cerebellar cistern, the bilateral Sylvian cistern, the lateral ventricles, the interpeduncular cistern, and the right parahippocampal fissure. WM tracks that were found important for age prediction were the bilateral tapetum, the right anterior limb of the internal capsule and the left medial lemniscus. Finally, the bilateral thalamus and the right precentral gyrus were the GM regions that contributed most to the prediction. Both of these analyses support the notion that age prediction in the current model is largely based on age\u2010related morphological changes in the cavities containing CSF. \n  \nAnatomical location of clusters in the threshold explanation map \n      \nThe threshold explanation map shown on a midsagittal (top left), a coronal (top row left) and 3 axial (bottom row) slices. Aggregated explanation map across 100 subjects and the 10 networks, thresholded for the first percentile of the ES. Abbreviations: ant. = anterior, cis. = cistern, g. = gyrus, fis. = fissure, ven. = ventricle. For each image, the slice number in the MNI template is indicated on the left upper corner. The color bar indicates the values of the ES \n  \n\n\n### Validating the population\u2010based inference scheme \n  \nTo validate the suggested approach for detecting regional contribution to a CNNs ensemble, we conducted three tests. First, we tested the importance of sample size to the explanation maps replicability by testing the half\u2010split similarity of these maps as a function of the population size. Second, to test whether these results coincide with data from other studies, we tested the extent of the similarity between the produced maps and a meta\u2010analysis of VBM studies. Lastly, to confirm the specificity of these results to the current model, we examined whether the produced maps highlight the particular brain regions for which the model exhibits the highest correlation to inter\u2010subject volumetric variability. \n\n#### Replicability of the produced explanation map as a function of sample size \n  \nIt is not clear to what extent an explanation map derived from a single sample would indeed represent the entire population. To examine this issue, we tested the split\u2010sample similarity of the explanation maps with a gradually increasing sample size obtained from two separate groups. In each test repetition (  k   =\u2009100), the groups were created by randomly half\u2010splitting a sample of 200 subjects (see Section  ). We report the Dice similarity and the MHD among these maps as a function of the sample size drawn from them (see Figure  ). Across all 10 networks, we found an increase of the Dice similarity and a decrease of the MHD as a function of the sample size, ranging from a single sample to 101 samples (mean Dice = 0.19, mean MHD = 3.73; mean Dice = 0.74, mean MHD = 1.00; respectively) (Figure  ). The relative improvement in the replicability of these maps asymptotes at 40\u201360 subjects, such that adding more samples had little further impact. Figure   shows 2D glass brain projections of the population\u2010based maps to illustrate the change as a function of the sample size, resulting in a visually apparent increase in coherence and a decrease in noise. These results suggest that whether due to noise or fundamental differences in subject\u2010specific maps, an explanation produced from a single sample rather than a population has low replicability. \n  \nThe split\u2010sample similarity of the explanation maps as a function of sample size. The similarity of two maps produced from an increased sample size from two separate groups (  n   =\u2009100 for each group) was measured using (a) Dice coefficient and (b) MHD (mm). The results are reported for all 10 CNNs and each is presented in a separate color. (c) A visual illustration of an explanation map for network 1 produced by increasing the sample size (from top to bottom,   N   =\u20091,510,100). The error bars represent a 95% confidence interval \n    \nDeviation in volume from age norm and prediction error. (a) Graphs of five ROIs, detected with the current inference scheme, showing the correlation between the age\u2010controlled volume and the signed prediction error. Age\u2010normalized volume was computed by regressing out subjects chronological age from the measured volume. Volume was determined according to the Desikan\u2010Killiany atlas fitted with Freesurfer. Prediction error was formulated as the chronological age minus the predicted age. Note that for the sake of brevity, in the upper five plots, the volume of the lateral ventricles and choroid plexus was computed as the sum of their subparcellations. (b) The bar graph depicts the correlation between the age normalized volume and the signed prediction error for all the 98 regions in the parcellation. Positive correlations are presented in blue and negative in orange for simple magnitude comparison. As shown, the age\u2010controlled volume of cavities containing CSF and the choroid plexus (L/R Lateral Ventricle, L/R inferior Lateral Ventricle, 3rd ventricle, nonventricles CSF, L/R choroid plexus), except for the 4th ventricle, had the largest correlation with the model's prediction error compared with all other WM/GM regions (see Figure S  for the full labels) \n  \n\n#### The similarity between explanation maps and voxel\u2010based morphometric meta\u2010analysis \n  \nTo quantitatively assess whether the regions detected in the current inference scheme coincide with previous findings, we compared the resulting explanation maps to data obtained from VBM studies testing structural age\u2010related changes. The VBM method has the desired property of allowing to test the relation between the estimated tissue composition of each voxel and any given relevant variable, age in the present case. In contrast, other methods are limited to a specific set of ROIs or a given brain parcellation that often fails to properly parcellate non\u2010GM regions. We used a published activation likelihood estimation (ALE) meta\u2010analysis of age VBM studies (  n   =\u200915, Vanasse et al.,  ) in which each voxel is assigned with a probability for its location in a reported peak coordinate in one of the studies (Laird et al.,  ). Using this map, we examined whether that ALE value is significantly higher within the regions identified using the threshold explanation map with a permutation test. The mean ALE value within the super\u2010threshold (first percentile) explanation map was higher than any set of randomly selected voxels in the permutation test (k = 10,000; meta\u2010analysis: empirical mean ALE: 0.003,   p   <\u2009.0001; see  ). Interestingly, both methods highlighted regions surrounding the lateral and third ventricles, subcortical areas, and the bilateral insula/Sylvian cistern, as opposed to cortical regions that appeared only in the ALE map (see  ). \n\n\n#### Specificity of the regions obtained in the analysis to the employment of the current model \n  \nPrediction errors could result from the inability of the model to capture the complexity of the brain aging process or due to the natural variability in brain morphology within the population. Exploiting the latter, in the current analysis, we aimed to examine whether prediction error would correlate with volumetric variability of specific brain regions. Specifically, by applying the Desikan\u2013Killiany atlas using Freesurfer, we tested whether age\u2010controlled volume of the ventricles and cisterns that were highlighted by the inference scheme were correlated with the CNNs ensemble prediction error. Indeed, we found a significant correlation between the age\u2010normalized volume and the prediction error for the ventricles excluding the fourth ventricle, the choroid plexus and nonventricular CSF (  n   =\u2009619; for all 9 regions but fourth ventricle:   r   >\u20090.13,   p   <\u2009.002). This correlation was higher in these regions than in any other brain region in the parcellation supporting the specificity of the results to the regions obtained using the population\u2010based explanation maps (see Figure  ). Interestingly, this specificity was not apparent when examining the correlation between regional volume and chronological age, in which significant correlation is seen in almost all regions (>93% of the ROI; see  ). Put differently, while the volume of almost all regions correlated with age, deviance from the age norm in the ventricles and CSF, detected using the population\u2010based maps, best reflected the prediction error. This suggests that the current inference scheme not only detected regions that are altered in aging, but it also detected the distinct regions that had the highest contribution to the current prediction, attesting to the high specificity of this method to the applied model. \n\n\n\n\n## DISCUSSION \n  \nIn the current study, we examined whether individuals' chronological age could be predicted from T1 MRI scan and whether it is possible to localize the underlying brain regions that allow such prediction. Using a large aggregated sample of 10,176 subjects we trained and validated an ensemble of 3D CNN models, and showed that \u201cbrain age\u201d could be estimated from raw T1 MRI with MAE of ~3.1\u2009years. We demonstrated that the use of an ensemble of models rather than a single estimator reduces the MAE in more than 6\u2009months and provided evidence that such gain is due to the difference in the features or brain regions that are utilized by each model. Models ensemble additionally allowed a simple estimation of model uncertainty. We found that model uncertainty correlated with prediction error and was higher in age ranges where less training data was available. Brain age was previously shown to be indicative of neurodegenerative diseases and other clinical conditions (Cole & Franke,  ), thus improving the precision, confidence estimation, as well as the interpretability of this biomarker, could be an important step toward integrating it in clinical use. \n\n### Identifying the brain regions underlying age prediction using population\u2010based explanation maps \n  \nDrawing from previous studies aiming at identifying regional contributions to the model's prediction, we aimed to locate the brain regions that governed our brain age estimation. Here we presented a novel approach to aggregate multiple explanation maps from several subjects, thus creating a population\u2010based map. This was achieved by deriving a series of transformations warping the 3D volumes presented to the CNN into the MNI space. We then applied those transformations to the computed explanation maps, thus allowing to average different explanation maps in a common space. This approach precludes the need for pre\u2010registration to a common template in the training stage, as done previously (Ceschin et al.,  ), a step that is error\u2010prone, time\u2010consuming and might result in the loss of relevant structural information (Iscan et al.,  ). Thus, these maps are obtained without compromising predictive accuracy, since the model's training objective is not altered. \n\nTo validate our method, we tested how it affects three important aspects. First, we quantitatively assessed how sample size in population\u2010based maps improved their reproducibility. We reported a substantial improvement in split\u2010sample similarity as moving from a map based on a single subject to a map based on a population of 40\u201360 subjects. The low split\u2010sample similarity of single\u2010subject maps emphasized the need to apply such practices when analyzing these explanation maps. Next, we demonstrated that despite the methodological differences, the proposed map exhibited significant similarity to ALE maps obtained from an age VBM meta\u2010analysis study (Vanasse et al.,  ), attesting to its convergence validity. Finally, using regional volumetric measures, we demonstrated that the brain regions highlighted by our method were those with the highest correlation to the model's prediction error, indicating the specificity of the derived maps to the current model. \n\n\n### Reducing noise or averaging over true relevant population differences? \n  \nComparing our approach for deriving population\u2010based explanation maps to an approach based on a single sample as in Smilkov et al.'s ( ) paper, we demonstrate an increase in reproducibility and a distinct visual improvement in the coherence of these maps. We therefore discuss possible mechanisms that may account for these findings. In their study, Smilkov et al. ( ) demonstrated that the derivative of CNNs are highly noisy, and averaging explanation maps obtained from several noised samples of the same input can improve these maps. Here, after applying the Smilkov et al. ( ) method, we further averaged multiple explanation maps derived from different inputs, that is, brain volumes of different subjects. A possible explanation to the apparent reproducibility improvement is that sampling from the true input distribution (brain volumes of different individuals), rather than mere noised samples of the same input, would result in estimation that is more robust to local gradient noise. A second, nonexclusive possible account might be that the model was trained on brain volumes from a heterogenic population. Differences in brain aging trajectory were found both at the individual level (Raz, Ghisletta, Rodrigue, Kennedy, & Lindenberger,  ) and among different populations, for example, in relation to gender (J\u00e4ncke et al.,  ). Thus, it is possible that the model extracts different features due to relevant structural variability in different populations. \n\n\n### The ventricles and cisterns as biomarkers for brain aging \n  \nAging is accompanied by multiple processes affecting the human brain, manifested in structural changes that could in part be quantified by neuroimaging (see Lorio et al.,  ). Accordingly, a wealth of literature reported a complex pattern of morphological changes evident across all brain regions, but arguably more apparent in some areas such as the frontal lobes, insular cortices, and the hippocampus (Fjell et al.,  ). Previous work that examined the predictive value of voxel\u2010wise feature maps reported that features derived from GM, compared to nonbrain tissue, served as better age predictors (Mont\u00e9\u2010Rubio, Falc\u00f3n, Pomarol\u2010Clotet, & Ashburner,  ). Interestingly, in our model, the ventricles and cisterns were highlighted as most relevant for age prediction. Several possible reasons might account for this finding. First, CSF volume was found to increase already from young adulthood (Courchesne et al.,  ), thus it may constitute an early aging biomarker. Since CSF pressure remains relatively constant and even decreases in old age (Fleischman et al.,  ), it is likely that CSF expansion reflects a decrease in WM/GM volumes rather than an increase in CSF pressure. Thus, CSF volume changes might be a surrogate for general brain atrophy, as suggested in previous work (De Vis et al.,  ). In line with this account, CSF volume was previously found as a better aging marker compared to WM/GM/hippocampal volume (Vinke et al.,  ). Notably, CNN representations are learned from the raw data and can potentially identify morphological alterations in these regions that facilitate aging prediction. In contrast, previous models (Liem et al.,  ; Valizadeh, H\u00e4nggi, M\u00e9rillat, & J\u00e4ncke,  ) exclusively based on regional volumetric measurements presented substantially lower accuracy. It is important to stress that the created explanation maps do not directly highlight regions that are indicative of age. Instead, given a specific model and a set of images, the maps highlight regions that are likely to contribute to the model's prediction. Accordingly, it has been previously suggested that neural networks present an inductive bias to more simple or parsimonious solutions (Neyshabur, Tomioka, & Srebro,  ). Thus, it is possible that although brain regions other than the ventricular system are indicative of age, the saliency of the ventricles and cisterns, due to their high contrast, allows their capture by the network. These possible reasons could be tested in future work but nevertheless, the ability to generate new biologically relevant hypotheses from a deep learning predictive model is a desirable practice supported here by our novel inference scheme. \n\n\n### Ensemble diversity among models' population\u2010based explanation maps \n  \nEvidence suggests that prediction based on a set of learning algorithms instead of a single algorithm will result in an accuracy gain (Sagi & Rokach,  ) that increases as these models are more accurate and diverse (Breiman,  ; Kuncheva & Whitaker,  ). Learning diverse models could be achieved by changes in architecture (Singh, Hoiem, & Forsyth,  ) or introducing different subsets of the training data to each model (Benou, Veksler, Friedman, & Riklin Raviv,  ). In the context of deep CNN, as opposed to convex or shallow learning algorithms, it has been shown that models that differ only in their random weight initializations, constitute an ensemble that is not only adequately diverse, but performs better than models exposed to different subsets of the data (Lakshminarayanan et al.,  ; Lee et al.,  ). In the current work, we examined the similarity among pairs of population\u2010based explanation maps derived from different models within such an ensemble. Although within each model population maps showed high reliability, on average, pairs of models exhibit only moderate similarity. This supports the notion that random weight initializations generate diverse models that utilized different parts of the input, that is, different brain regions. This might explain the observed improvement in prediction accuracy when using an ensemble. The apparent variability of explanation maps within the ensemble could be additionally considered in terms of uncertainty. Ensembles were previously utilized to evaluate uncertainty for regression and classification problems (Lakshminarayanan et al.,  ), for evaluating actions in reinforcement learning (Gal & Ghahramani,  ) and in estimating voxel\u2010wise uncertainty in diffusion imaging super\u2010resolution (Tanno et al.,  ). In line with this, we suggest that the variability of voxel\u2010wise explanation maps could be similarly viewed as confidence in the importance of various regions for a given model architecture and a training set. Thus, regions such as the ambient and cerebellar cisterns, consistently utilized across all models, could be viewed as important for the prediction with higher confidence. Overall, it seems that general conclusions regarding the contribution of different brain regions to age prediction should be made based on maps converging from multiple models. \n\n\n### Limitations \n  \nThis study has a number of limitations. First, it is unclear whether the trained model is fully invariant to variables such as scanning site or acquisition parameters. When testing for bias in the dataset level, each dataset with its own scanning parameters, we found evidence for a systematic prediction bias in only one of 11 studies. It is still possible, however, that the network could distinguish between scans based on their acquisition statistics and utilize such information for the prediction. This issue should be further examined in future work (see Tzeng, Hoffman, Saenko, & Darrell,   for domain invariance in machine learning). Second, since the model was trained solely on cross\u2010sectional data, it only gained information on between\u2010subjects aging variability. Incorporating longitudinal data can allow to model individuals' aging trajectories. Finally, CNNs are complex functions with hundreds of thousands of parameters and multiple layers with nonlinearities, thus they could not be fully reduced to a set of local contributions. CNNs are likely to entail complex multivariate interactions that are not necessarily local. Hence it is important to state that our maps, based on partial derivatives, are merely an approximation of the significance of various input regions. \n\n\n### Population\u2010level explanation maps: Future directions \n  \nComputing population\u2010based explanation maps allow examining group differences in maps produced from different populations. For example, one might ask whether a CNN model would extract different aging biomarkers for men versus women or for healthy elderly versus individuals diagnosed with AD. These tests could be applied on maps derived from two identical models separately trained on different populations or within the same model trained on both populations. In the latter case, subjects' group affiliation could be explicitly introduced to the model as an input. Alternatively, it will be possible to test whether a distinction among populations in the form of explanation maps differences, would arise without introducing such an input. Hence, explanation maps obtained from a population of subjects, registered to the same template could allow harnessing known neuroscience statistical procedures based on voxel or regional wise comparison of within compared to between\u2010group variability. Another possible extension of the current work is the adoption of population\u2010level explanation maps to other neuroimaging prediction problems. An example of such potential usage could be a deep learning decoding model of neural activity (Beliy et al.,  ), a model predicting the presence of a neurological condition (Li, Liu, Sun, Shen, & Wang,  ), or any machine learning application based on a differentiable function. This, of course, would require a pre\u2010trained model for a given task, and relies on the assumption that the model exploits regional features for the prediction. \n\n\n### Conclusions \n  \nIncorporating deep learning for analysis of neuroimaging data requires improvement in both the accuracy of these predictive models and the ability to interpret them, as we aimed to address in the context of age prediction. Respectively, in the current work, we demonstrated that an individual's chronological age could be estimated with a MAE of 3.1\u2009years from their raw T1 images, yielding a robust biomarker across several datasets. We further showed that aggregating multiple explanation maps substantially increases their reproducibility and allow to create a coherent and localized map depicting and quantifying the contribution of different brain regions to age prediction. From these maps, we conclude that the ventricles and cisterns govern these predictions. We argue that this ability to pinpoint specific brain areas is a key step for utilizing these models as possible brain health biomarkers. \n\n\n\n## Supporting information \n  \n \n", "metadata": {"pmcid": 7426775, "text_md5": "ffb9ad58ef099107be37fdb03e8055dc", "field_positions": {"authors": [0, 95], "journal": [96, 110], "publication_year": [112, 116], "title": [127, 231], "keywords": [245, 331], "abstract": [344, 2655], "body": [2664, 56571]}, "batch": 1, "pmid": 32320123, "doi": "10.1002/hbm.25011", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7426775", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7426775"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7426775\">7426775</a>", "list_title": "PMC7426775  From a deep learning model back to the brain\u2014Identifying regional predictors and their relation to aging"}
