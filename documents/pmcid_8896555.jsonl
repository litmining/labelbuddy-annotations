{"text": "Quirmbach, Felix and Limanowski, Jakub\neNeuro, 2022\n\n# Title\n\nA Crucial Role of the Frontal Operculum in Task-Set Dependent Visuomotor Performance Monitoring\n\n# Keywords\n\naction\nfrontal operculum\nperformance monitoring\nsensorimotor integration\nvisuoproprioceptive integration\n\n\n# Abstract\n \nFor adaptive goal-directed action, the brain needs to monitor action performance and detect errors. The corresponding information may be conveyed via different sensory modalities; for instance, visual and proprioceptive body position cues may inform about current manual action performance. Thereby, contextual factors such as the current task set may also determine the relative importance of each sensory modality for action guidance. Here, we analyzed human behavioral, functional magnetic resonance imaging (fMRI), and magnetoencephalography (MEG) data from two virtual reality-based hand\u2013target phase-matching studies to identify the neuronal correlates of performance monitoring and error processing under instructed visual or proprioceptive task sets. Our main result was a general, modality-independent response of the bilateral frontal operculum (FO) to poor phase-matching accuracy, as evident from increased BOLD signal and increased source-localized gamma power. Furthermore, functional connectivity of the bilateral FO to the right posterior parietal cortex (PPC) increased under a visual versus proprioceptive task set. These findings suggest that the bilateral FO generally monitors manual action performance; and, moreover, that when visual action feedback is used to guide action, the FO may signal an increased need for control to visuomotor regions in the right PPC following errors. \n \n\n# Body\n \n## Significance Statement \n  \nThe brain uses feedback from the senses to guide behavior and correct errors. During hand movements, this feedback can come from seen and felt hand positions. Here, we used brain scanning to show that brain regions in the frontal operculum responded to action errors in a hand\u2013target matching task, when either seen or felt hand positions were task relevant. Furthermore, when the seen hand position had to be prioritized for the task, these regions increased their communication with the right posterior parietal cortex, which is known to guide hand movements based on visual cues. These results suggest a crucial role for the frontal operculum in monitoring hand actions; in particular, when vision is task relevant. \n\n\n## Introduction \n  \nTo effectively perform goal-directed action in the environment, the brain needs to monitor motor performance and detect errors, so that it can enable adaptive changes in behavior ( ;  ;  ;  ). During performance monitoring, the predicted outcome of one\u2019s actions is compared with actual sensory feedback, and behavioral changes are initiated if a mismatch between both is detected ( ). The neurofunctional basis of performance monitoring and error correction has been illuminated by recent brain imaging and electrophysiological work. Specifically, a \u201csalience network\u201d comprising, among others, the dorsal anterior cingulate cortex, the bilateral insular cortex (IC) and the inferior frontal gyri, is assumed to integrate sensory input, responding to behaviorally salient stimuli\u2014behavioral errors\u2014with increased activation ( ;  ;  ;  ). Thereby, regions like, for example, the frontal operculum (FO; also anterior IC;  ;  ;  ;  ;  ) may signal a need for increased cognitive control to the executive control network, consisting (among other regions) of the lateral prefrontal cortices, the posterior parietal cortex (PPC), supplementary motor area (SMA), and the inferior parietal lobule ( ;  ). This network, in turn, may direct (e.g., attentional) resources to the relevant stimuli, driving behavioral adaptations ( ;  ). \n\nNotably, action performance and error may be conveyed via different sensory modalities; in manual action, for instance, via visual and proprioceptive cues about body position. In the context of body representation for action, visual and proprioceptive body position cues can be weighted depending on the current context (e.g., based on their relative relevance for the specific task at hand ( ;  ;  ;  ). Recently, we have used virtual reality (VR) to examine this contextual sensory weighting during action under conflicting visual (virtual) and proprioceptive (real, unseen) body position feedback. Our fMRI and MEG studies ( ;  ) specifically shed light on the effects of adopting a visual versus proprioceptive attentional set during goal-directed manual action tasks, demonstrating that participants can prioritize either modality over the other; and we observed corresponding changes of neuronal gain in the respective sensory (visual and proprioceptive) brain regions. \n\nHere, we capitalized on the novel task design of these studies. First, we aimed to investigate the neuronal correlates of performance monitoring in this ecologically valid VR-based goal-directed grasping task, and to compare the results to previous work using more abstract study designs. Second, as the original studies had demonstrated behavioral and neuronal effects of an experimentally controlled task set prioritizing vision versus proprioception, another goal of our analysis was to determine whether performance monitoring would be modality specific (i.e., involve different brain regions when vision versus proprioception was task relevant) or modality general. Based on the above literature, we expected task inaccuracy to be reflected by activity in the performance monitoring network and, potentially, also in frontoparietal attentional areas. Furthermore, in contrast to the original MEG results, which had suggested low oscillatory frequencies (in the beta band) as encoding an attentional task set ( ), we expected high frequencies to reflect error processing (in line with assumptions of the predictive coding framework;  ). We therefore reanalyzed the behavioral, fMRI, and MEG data from our above studies, correlating participants\u2019 task performance with hemodynamic and oscillatory activity, and testing for differences in brain connectivity. \n\n\n## Materials and Methods \n  \n### Participants \n  \nFor this study, we reanalyzed fMRI and MEG data acquired by   and  . Healthy, right-handed volunteers with normal or corrected-to-normal vision participated in both experiments after providing written informed consent. The fMRI study included 16 subjects (8 females; mean age, 27 years; age range, 21\u201337 years), and the MEG study included 18 subjects (9 females; mean age, 29 years; age range, 21\u201339 years). Both experiments were approved by the local research ethics committee (University College London) and conducted in accordance with these approvals. \n\n\n### Experimental design and task \n  \nParticipants wore an MR-compatible data glove (1 sensor per finger; 8\u2009bit flexure resolution per sensor; sampling rate, 60\u2009Hz; communication with the PC via USB; Data Glove MRI, 5DT) on their right hand. The glove measured the flexion of each finger via sewn-in optical fiber cables and was carefully calibrated before scanning to fit each participant\u2019s movement range. Recorded hand movement data were used to control a photorealistic virtual hand (VH) model, moving in accordance with the participant\u2019s hand movements and presented as part of a virtual reality task environment. This virtual environment, consisting of the VH, a fixation dot, and task instructions, was created in the open-source 3D computer graphics software Blender ( ). The environment was presented via a projector on a screen (for details, see  ;  ). \n\nParticipants were instructed to perform repetitive right-hand grasping movements, paced by oscillatory (0.5\u2009Hz) size changes (12%) of the central fixation dot. Thus, participants had to match the fully open hand position with the biggest dot size and, conversely, the fully closed hand with minimal dot size. Choosing the fixation dot as a target for the phase matching was done to ensure fixation (for the corresponding eye tracking analyses that support this, see  ;  ) and to prevent participants from looking away from the VH\u2014this was necessary since we wanted the visual action feedback (from the hand) to be comparable across VH and real hand (RH) conditions (while it was effectively a distractor in the RH condition). However, note that what was tracked was an oscillatory size change (i.e., a rather abstract quantity). In other words, the task was a phase-matching task ( ) rather than a visuospatial pursuit task; with this, we aimed to minimize the visual bias implicit in the design. Participants performed the task in movement blocks of 32 s (16 close-and-open movements; the last movement was signaled by brief blinking of the fixation dot), separated by 16 s rest periods during which only the fixation dot was visible. All participants trained extensively before scanning. Note that this task was not designed to investigate visuomotor adaptation or learning, but to maintain hand\u2013target phase matching during a sustained visual versus proprioceptive attentional task set. \n  \nPhase-matching task. Participants controlled a photorealistic VH model with a data glove worn on their right hand. In all experimental conditions, the RH was occluded from view, while the VH was visible at all times. Participants had to match the oscillatory phase of a virtual target (fixation dot, changing its size sinusoidally at 0.5\u2009Hz) with grasping movements (i.e., open at maximum target size, closed at minimum size). Thereby, participants were instructed to match the oscillatory phase of the target with the grasping movements of either the VH or the unseen RH (while ignoring the movements of the VH). These instructions induced a specific task set, in which either visual or proprioceptive hand movement information was task relevant. In half of all trials, RH and VH moved congruently (\u201ccongruent\u201d), while in the other half of the trials (\u201cincongruent\u201d) the movements of the VH were delayed with respect to the actually executed movements (RH); this introduced visuoproprioceptive incongruence. Reprinted from  . Copyright Elsevier (2020) under the terms of the Creative Commons CC-BY license. \n  \nIn half of the conditions, a lag was introduced to the movements of the virtual hand to evoke visuomotor incongruence (i.e., the virtual hand movements lagged behind the actually executed movements). In the fMRI experiment, a lag of 267\u2009ms was introduced in the second half of each movement block; this delay length was chosen based on the results of a previous study that showed this amount of lag was well perceptible and could be adapted to with recurrent grasping movements ( ). Since a pretest for the subsequent MEG study showed that the behavioral effects observed in the fMRI study were slightly stronger when introducing longer delays, in this experiment a lag of 500\u2009ms was presented in separate delay blocks. However, differences in the amount of lag did not change the nature of the task; and the behavioral results were comparable across fMRI and MEG experiments ( ;  ). Before the start of each movement block, participants were instructed to match the phase of the fixation dot with either the seen virtual hand model or their unseen real hand. The virtual hand was visible in both conditions. Under incongruence, only one modality could be aligned with the target phase, which resulted in a misalignment of the other modality; when trying to align their unseen real hand with the phase of the dot, participants therefore had to ignore the movements of the virtual hand. Note that it was visual hand movement that was therefore task relevant or irrelevant, not visual information per se (which included the visually presented target dot). The task instruction (\u201cVIRTUAL\u201d or \u201cREAL\u201d) was presented 2.5 s before the start of each movement block for 2 s, and through the block, the color of the fixation dot reminded participants of the current condition. In the fMRI experiment ( ), we additionally varied the visibility (high or low) of the virtual hand during half of the movement blocks. However, we found no differences in performance between different visibility levels; in our present reanalysis, there were no significant differences between visibility levels either. Therefore, we present the differential fMRI task contrasts in terms of VH versus RH task, summing over high- and low-visibility levels in each condition. In sum, despite minor technical differences between fMRI and MEG experiments, both can be described as a balanced 2\u2009\u00d7\u20092 factorial design with the factors \u201ctask\u201d (VH vs RH) and \u201ccongruence\u201d (congruent vs incongruent). \n\n\n### Behavioral data analysis \n  \nIn our previous analyses, we examined the neuronal correlates of the instructed task set, and analyzed only condition-specific differences in average performance ( ;  ). In the present study, we examined the neuronal correlates of phase-matching accuracy (i.e., fluctuations around those average performances). All analyses were performed using MATLAB (MathWorks). \n\nTo quantify hand\u2013target phase-matching accuracy/inaccuracy, we calculated the root mean square error (RMSE) of the difference between the target position (i.e., the position within the oscillatory cycle) and the position of the task-relevant hand (i.e., the position within the grasping cycle, averaging the recorded finger position data per hand). Thus, the virtual hand position was evaluated for the VH condition movements, and the real hand position for the RH condition. For construction of the fMRI/MEG regressors, we binned the resulting RMSE values into 1 s time windows, each centered on a time point of minimum or maximum target size, corresponding to the hand fully closed or opened if moved synchronously with the target. To focus on within-subject fluctuations in performance, rather than between-subject differences, the overall RMSE across the entire experiment was normalized for each single subject (i.e., minimum and maximum performance error value was equal across participants; 0 and 1, respectively). The resulting RMSE values were assigned to one regressor per experimental condition (VH congruent, VH incongruent, RH congruent, RH incongruent), and demeaned separately to reflect only variation around the condition mean. To evaluate whether phase matching differed between conditions, we calculated a two-way repeated-measures ANOVA with the factors \u201ctask set\u201d (VH or RH) and \u201ccongruence\u201d on the RMSE values. \n\nThe amplitude of the hand movement at each time point was calculated via a cubic spline interpolation of the respective minimum and maximum hand position values in each time window. The resulting time series was also demeaned per condition and was used as a noise regressor for the following fMRI and MEG analysis (see below). We also calculated the mean values of hand movement velocity, acceleration, and jerk per subject and condition. For each of these movement parameters (including amplitude), we calculated a two-way repeated-measures ANOVA with the factors task set (VH or RH) and congruence to evaluate condition-specific differences. Note, however, that the calculated RMSE values implicitly captured all potential differences in movement characteristics as they imply a deviation from the optimal movement trajectory; therefore, these differences are considered negligible and are reported here: Movement amplitude was found to be significantly higher for condition RH than VH in both datasets (ANOVA, main effect of task set: fMRI:   F   = 7.705,   p  \u2009=\u20090.014; MEG:   F   = 8.038,   p  \u2009=\u20090.011); in the fMRI data, movement amplitude was also significantly higher for incongruent than congruent trials (  F   = 6.499,   p  \u2009=\u20090.022). Mean amplitude values with associated SD for the fMRI dataset were as follows: VH_congruent\u2009= 0.607 (0.088); VH_incongurent\u2009=\u20090.640 (0.079); RH_congruent = 0.644 (0.098); and RH_incongurent\u2009=\u20090.664 (0.094). Mean amplitude values with associated SD for the MEG dataset were as follows: VH_congruent\u2009=\u20090.696 (0.101); VH_incongurent = 0.681 (0.108); RH_congruent\u2009=\u20090.722 (0.089); and RH_incongurent\u2009=\u20090.721 (0.119). Furthermore, in the fMRI study data (but not in the MEG study data), movement velocity was, on average, significantly higher for RH than VH (  F   = 6.726,   p\u2009  =  \u2009  0.020), and higher in trials with delayed compared with congruent seen movements (  F   = 5.044,   p  \u2009=\u20090.040); mean velocity values with associated SDs were as follows: VH_congruent\u2009=\u20090.0106 (0.0014); VH_incongurent\u2009=\u20090.0111 (0.0013); RH_congruent\u2009= 0.0112 (0.015); and RH_incongurent\u2009=\u20090.0114 (0.0015). It should be noted that, although significant, these differences were very small; there were no significant effects of acceleration or jerk. For completeness, we also tested for correlations between performance error and movement amplitude, velocity, acceleration, and jerk by calculating the Pearson correlation coefficients for each participant; and testing it for significance (i.e., significant difference from zero) with a   t   test on the group level. Similarly, we calculated the correlation between performance error and fMRI head movements (realignment parameters), via subject-level Pearson correlation and group-level   t   test, adjusted for multiple comparisons for the six realignment parameters. On average, phase-matching accuracy correlated significantly, but only weakly, with movement amplitude (for fMRI data: mean Pearson\u2019s   r\u2009  =  \u2009  0.27; for MEG data: mean   r\u2009  =  \u2009  0.18; both   t   values  > 5,   p   values  \u2009  <  \u2009  0.05). It also correlated significantly\u2014again, very weakly\u2014with velocity, acceleration, and jerk (highest   r  \u2009=\u20090.178, lowest   r  \u2009=\u20090.073; for fMRI and MEG data, all   p   values  \u2009  <  \u2009  0.05). Phase matching did not significantly correlate with the fMRI realignment parameters (all   r   values < 0.02, n.s.). \n\n\n### FMRI data preprocessing and analysis \n  \nAll analyses were performed using MATLAB (MathWorks) and SPM12.6 (Wellcome Trust Centre for Neuroimaging, University College London;  ). \n\nWe reused the preprocessed fMRI data by  . The fMRI data had been acquired using a 3 T scanner (Magnetom TIM Trio, Siemens), equipped with a 64-channel head coil. T *-weighted images were acquired using gradient echo-planar imaging sequences (voxel size\u2009=\u20093\u2009\u00d7\u20093 \u00d7 3 mm ; matrix size = 64\u2009\u00d7\u200972; TR\u2009=\u20093.36 s; TE\u2009=\u200930\u2009ms; flip angle\u2009=\u200990\u00b0). \n\nWe fitted a general linear model (GLM; 128 s high-pass filter) to each participant. Each condition (VH, RH) was modeled with a boxcar function as a 32 s movement block; we added a parametric modulator (1/\u22121) to each condition encoding the first half of each block as congruent (\u22121) and the second half as incongruent (1) movement periods. Additionally, we included a regressor encoding the (demeaned and convolved) RMSE values for each condition; the values were resampled to match the 3.36 s scan length before this. Regressors modeling the task instructions and movement amplitude were added to the GLM alongside the realignment parameters as regressors of no interest. \n\nFor each subject, we calculated contrast images of each RMSE regressor against the baseline. These were then entered into a group-level flexible factorial design, with the factors task (VH, RH) and congruence (congruent, incongruent), and an additional factor modeling the subject constants. To assess potential differences between congruent and incongruent movement periods, we calculated separate first-level GLMs, in which the RMSE values of the second movement half were inverted; this effectively encoded the contrast congruent\u2013incongruent. The resulting contrast images were entered into an analogous group-level GLM, as described above. \n\nGroup-level results were assessed for statistical significance using a voxelwise threshold of   p\u2009  <  \u2009  0.05, familywise error (  p  ) corrected for multiple comparisons. We projected the resulting statistical maps onto the mean normalized structural image or rendered it on the brain template of SPM12. The unthresholded T-maps corresponding to the contrasts reported here can be inspected online at  . For anatomic reference, we used the SPM Anatomy toolbox ( ). \n\n\n### MEG data preprocessing and analysis \n  \nMEG signals had been acquired using a 275-channel whole-head setup with third-order gradiometers (CTF Omega, CTF MEG International Services) at a sampling rate of 600\u2009Hz. Following the original analysis by  , the MEG data were high-pass filtered (1\u2009Hz), downsampled to 300\u2009Hz, and epoched into trials of 2 s each (each corresponding to a full target oscillation/grasping cycle). \n\nIn the main (sensor space) MEG data analysis, we looked for spectral power differences under \u201csteady-state\u201d assumptions (i.e., treating the spectral profile as a \u201csnapshot\u201d of performance-dependent responses as manifest in quasi-stationary power spectra;  ;  ;  ). We computed trial-by-trial power spectra in the 0\u201398\u2009Hz range using a multitaper spectral decomposition ( ) with a spectral resolution of \u00b12\u2009Hz. The spectra were log transformed, converted to volumetric scalp \u00d7 frequency images\u2014one image per trial\u2014with two spatial and one frequency dimension ( ), and smoothed with a Gaussian kernel with full-width at half-maximum of 8 \u00d7 8 \u00d7 4\u2009Hz. The resulting images were entered into a GLM using a within-subject ANOVA with the respective RMSE values as a covariate (first-level analysis). As in the fMRI analysis, movement amplitude was moreover included as a covariate of no interest to capture movement-related fluctuations. Contrast images were then calculated for the accuracy covariate of each condition. These contrast images were then entered into a group-level GLM using a flexible factorial design including the two within-subject experimental factors (task and congruence), and a factor modeling the between-subject variance. The statistical parametric maps obtained from the respective group-level contrasts were evaluated for significant effects using a threshold of   p\u2009  <  \u2009  0.05, familywise error (  p  ) corrected for multiple comparisons at the peak (voxel) level. \n\nAs a   post hoc   analysis, source localization of trial-by-trial correlation of gamma-band power with performance error was performed using a variational Bayesian approach with multiple sparse priors ( ). Source localization was performed in the 34\u201388\u2009Hz range (which was the range of effects in the spectral analysis thresholded at   p\u2009  <  \u2009  0.001, uncorrected). As we had already performed an analogous localization on the fMRI data (see above), we could use the superior spatial acuity of fMRI to improve MEG source localization [i.e., the fMRI activations (thresholded at   p\u2009  <  \u2009  0.001, uncorrected) were used as empirical (spatial) priors for the Bayesian inversion routine;  ;  ]. For comparison, we also reconstructed the sources using a Bayesian beamforming approach ( ). This produced very similar results [i.e., the strongest effects were localized to the bilateral inferior frontal gyri, including the FO (a further, weaker source was localized to the primary visual cortex)]. The results of this source localization were summarized as 3D images and were entered into a group-level   t   test. Since the significance of the effects on spectral responses had already been established with the sensor space analysis, the ensuing statistical parametric maps were displayed at a threshold of   p\u2009  <  \u2009  0.05, uncorrected, rendered on the smoothed average brain template of SPM. The unthresholded T-map corresponding to the source localization can be inspected online at  . \n\n\n### fMRI functional connectivity analysis \n  \nIn our main analysis (see above), we identified brain areas that showed a significant response to phase-matching inaccuracy. The fMRI and MEG results consistently highlighted the bilateral FO [while further fMRI activations were found in the dorsal premotor cortex (PMd) and the dorsolateral prefrontal cortex (dlPFC)]. \n\nIn our original analyses ( ;  ), the FO did not show any task-specific effects (i.e., activity differences between VH and RH tasks) per se, and neither did the SMA or the dlPFC. However, following the clear response of the FO to poor task performance in general, we now asked whether these areas would change their connectivity to other (potentially, task relevant) brain areas depending on whether the inaccuracy was registered during the VH or RH task [i.e., while participants focused either on visual (VH) or proprioceptive (RH) action feedback]. \n\nTo answer this question, we used psychophysiological interaction (PPI) analysis for fMRI data. This analysis aims to explain coupled neuronal activity among brain areas in terms of an interaction between psychological factors (the specific task condition) and physiological factors (the BOLD signal time course in the region of interest;  ;  ). The resulting PPI reveals voxels in the brain that increase their connectivity with a specific seed region in a given context (e.g., in a specific task condition). Note that task-dependent changes in connectivity per se (i.e., between VH and RH task sets) were identified in both fMRI and MEG datasets ( ;  ). However, in the fMRI data, the SPM approach allowed us to select a spatially isolated volume of interest (i.e., voxels from the FO) that was not part of the original connectivity analysis. This was not analogously possible for the MEG data, which in the original connectivity analysis were already modeled on the whole-scalp level ( ). Therefore, we limited the connectivity analysis to the fMRI data. \n\nFor the PPI analysis, we calculated separate GLMs with concatenated runs for each participant, and thus identified subject-specific peaks of the main effects observed on the group level. The individual peaks were defined as the maximum effect within a 10-mm-radius sphere of the respective group-level maximum ( ). From these individual peaks, we extracted the BOLD signal of the seed regions as the first eigenvariate of activity across all voxels in a 4-mm-radius sphere centered on the participant-specific peak. For three subjects where no effect could be identified for the specific PMd seed region as well as one case where no effect was found for the dlPFC region, we resorted to the group-level maximum for seed region localization. \n  \nSignificant (  p   < 0.05) activations for all reported fMRI contrasts \n    \nThe SPM12.6 PPI routine was then used to form the interaction between the psychological factor and the summarized BOLD signal time course of the seed region. Note that while the seed regions were identified per their significant response to phase-matching inaccuracy ( ), our psychological factor was the task set (i.e., the instructed hand modality at the beginning of each movement block; VH vs RH, pooled over different levels of virtual hand visibility; see above). After forming the interaction term, a second GLM was constructed for each participant, including the interaction, the extracted signal of the seed region, the task set, and the realignment parameters as regressors of no interest. \n  \nBOLD signal increases related to phase-matching inaccuracy. The renders (left) and slice overlays (right) show brain areas in which hemodynamic activity was correlated with the relative inaccuracy of hand\u2013target phase matching (displayed at   p   <  \u2009  0.001, uncorrected). Significant activations (  p   < 0.05; voxels outlined in blue on the slice overlays) were located in the bilateral FO, the left SMA, and the left dlPFC. \n  \nOn the group-level, the connectivity of the bilateral FO was evaluated using a paired   t   test (i.e., a GLM including the PPI contrast images of the left and right FO of each participant, and another factor modeling the between-participant variance). We also tested whether the other two regions showing significant responses to phase-matching inaccuracy (PMd and dlPFC) would exhibit connectivity changes, using a similar approach. \n\n\n\n## Results \n  \n### Behavioral results \n  \nIn both studies, participants reported allocating their attention to the respective instructed hand, which is in line with the assumption that the task instructions would create a visual versus proprioceptive task set. Both VH and RH tasks were perceived as comparably difficult, with the incongruent conditions being judged as more difficult in each case. Moreover, in both studies, participants were able to follow the task instructions [i.e., to keep the grasping movements of the instructed modality (vision or proprioception) significantly better aligned with the phase of the dot than the noninstructed modality]. See the original studies ( ;  ) for details. \n\nOur analysis was aimed at identifying the neuronal correlates of fluctuations of performance (i.e., fluctuations around condition-specific mean performances). For completeness, we still report the condition-specific RMSE means and SDs, as follows: for the fMRI dataset: VH_congruent\u2009=\u20090.265 (0.045); VH_incongruent\u2009= 0.244 (0.041); RH_congruent\u2009=\u20090.273 (0.058); and RH_incongruent\u2009=\u20090.257 (0.061); for the MEG dataset: VH_congruent\u2009=\u20090.213 (0.045); VH_incongruent\u2009=\u20090.244 (0.040); RH_congruent\u2009=\u20090.206 (0.041); and RH_incongruent\u2009=\u20090.322 (0.095). Overall, participants performed slightly better in the VH than the RH task; although this difference was statistically significant only for the MEG study data (ANOVA; main effect of task set:   F   = 7.136,   p  \u2009=\u20090.016). In the MEG study, RMSE was significantly higher for incongruent than congruent trials in both datasets (ANOVA:   F   = 30.026,   p  \u2009<\u20090.001); in the fMRI data, RMSE was higher for congruent than incongruent trials (  F   = 6.820,   p  \u2009<\u20090.05). In sum, the behavioral results and self-reports showed that participants could follow the task instructions, that this induced the desired cognitive-attentional task set, and that behavior in the VH versus RH tasks was comparable across fMRI and MEG studies. \n\n\n### FMRI results \n  \nIn our main fMRI analysis, we sought to identify brain regions in which neuronal activity correlated with phase-matching accuracy/inaccuracy ( ). A significant (  p   < 0.05) main effect of inaccuracy was observed in the bilateral FO, the left dorsal premotor cortex (PMd; at uncorrected thresholds, this activation cluster spanned to the left SMA), and the left dlPFC ( ,  ). More liberal thresholds (  p\u2009  <  \u2009  0.001, uncorrected) revealed further activation clusters in the right middle and superior frontal gyri, the precuneus, the midcingulate cortex (MCC), the right middle temporal gyrus (MTG), and bilaterally in the cerebellum ( , compare the render). Conversely, a significant main effect of accuracy was found in the left pre- and postcentral gyrus, corresponding to the primary motor cortex (M1). No other comparisons (i.e., contrasting the effects of accuracy among task conditions, delay, or visual salience levels; see Materials and Methods) yielded significant effects. At uncorrected thresholds (  p\u2009  <  \u2009  0.001), voxels in several brain areas showed a stronger correlation with task inaccuracy under the VH task than under the RH task; namely, in the MCC, the bilateral FO, the right MTG, the left cerebellum, the right dlPFC, and the bilateral PPC (peak within the intraparietal sulcus). \n\n\n### MEG results \n  \nThe MEG sensor space analysis revealed that phase-matching inaccuracy was associated with significantly increased spectral power in the gamma frequency range over midfrontal sensors (main effect; peak at 52\u2009Hz,   T  \u2009=\u20095.31,   p   < 0.05;  ). These spectral effects were source localized to the bilateral inferior frontal gyri, including the bilateral FO ( ). No other spectral power comparisons yielded statistically significant results; but there was a statistical trend suggesting inaccuracy was associated with reduced alpha (8\u2009Hz) power over posterior sensors (  T  \u2009=\u20094.61,   p   = 0.069). \n  \nSpectral gamma power increases related to phase-matching inaccuracy.    A   , The \u201cglass brain\u201d (maximum intensity) projections show the sensor level scalp frequency maps of spectral power correlated with the relative inaccuracy of hand\u2013target phase matching (the darkest voxels show the strongest effect along the respective projection; the maps are thresholded at   p\u2009  <  \u2009  0.001, and effects significant at   p   < 0.05 are outlined in blue; the top plots have one frequency dimension, 0\u201398\u2009Hz, and one spatial dimension. P-A, Posterior-anterior; L-R. left-right. The bottom plot has two spatial dimensions.    B   , Renders (left) and slice overlays (right) showing the corresponding source localization of the spectral correlation to regions around the FO. \n  \n\n### Functional connectivity analysis \n  \nThe above fMRI activations and source-localized MEG gamma power consistently suggested that periods of poor phase matching activated the bilateral FO, in line with previous literature that had established the role of this region in error processing and performance monitoring (see Introduction). However, we did not find any significant difference between conditions (i.e., between visual and proprioceptive task sets). Therefore, we next performed a connectivity (PPI) analysis on the fMRI data to explore whether task-relevant brain areas would change their connectivity to the FO depending on the instructed task condition (VH or RH). \n\nThis analysis revealed a significantly increased coupling of several brain areas with the bilateral FO during the VH task > RH task, most strongly expressed in the right inferior parietal lobe (IPL;  ,  ). The increase in coupling with the right IPL was evident for both the left and right FO independently, as revealed by an additional \u201cnull\u201d conjunction analysis ( ; a conjunction of voxels activated in the PPI with the left FO and PPI with the right FO, each thresholded at   p\u2009  <  \u2009  0.001, uncorrected). Correspondingly, there were no significant differences in coupling between the left and right FO. A supplementary analysis testing for potential coupling differences with the FO during VH_incongruent versus VH_congruent yielded no significant effects either. There were no significant connectivity changes with the FO under the RH task > VH task. No significant changes in connectivity were observed in analogous analyses calculated for the PMd or the dlPFC, with the other two brain regions showing significant effects in the main analysis (see above). \n  \nBrain areas showing significant (  p   < 0.05) coupling increases with the bilateral FO during the VH task > RH task \n      \nTask-dependent connectivity changes of the bilateral FO.    A   , Brain areas showing increased coupling with the bilateral FO during the VH task relative to the RH task (displayed at   p\u2009  <  \u2009  0.001, uncorrected). The strongest effects were located in the right IPL (voxels significant at   p   < 0.05 are outlined in blue).    B   , A corresponding null conjunction contrasts confirmed this increased task-dependent coupling with the right IPL for the left and right FO independently (each PPI contrast thresholded at   p\u2009  <  \u2009  0.001, uncorrected). \n  \n\n\n## Discussion \n  \nWe used data from a virtual reality-based hand\u2013target phase-matching task to identify the hemodynamic and oscillatory correlates of performance (i.e., phase-matching accuracy) monitoring under instructed task relevance of visual or proprioceptive hand position feedback. The specific design of this task, with continuous goal-directed movements and the experimentally controlled switching of attentional task set, created a novel, ecologically valid context for performance monitoring. \n\nOur main result was a general, modality-independent response of the bilateral FO to poor phase-matching accuracy, as evident from the increased BOLD signal levels and increased source-localized gamma power. Furthermore, connectivity of the bilateral FO to the right PPC/IPL increased while participants executed the phase-matching task with the visible virtual hand, compared with when they executed it with the real, unseen hand. \n\nThe observed general BOLD signal increase in the bilateral FO with task (phase-matching) inaccuracy replicates observations of previous studies using more abstract study designs, where the BOLD signal in the FO increased in response to performance errors. For instance, the FO was activated by error trials versus correct trials in the Simon task ( ;  ), in an antisaccade task ( ), and in a flanker task ( ). Similarly, FO error-related BOLD signal increases were observed in visuomotor adaptation tasks ( ) and in response to tactile \u201coddball\u201d stimuli ( ). Some studies found activation of the FO correlated positively with task performance ( ;  ). This could, however, be explained with a general underlying function of FO activation in performance monitoring; acting not as an error signal per se, but as part of a mechanism to improve performance in response to errors ( ). Thus, it has been proposed that neuronal activity in the FO may indicate the need for increased allocation of attentional resources to specific stimuli to achieve task-appropriate behavior ( ;  ;  ;  ). Additionally, because of the reciprocal connections of the FO to multiple sensory, limbic, and association areas ( ), it may act as crucial \u201crelay\u201d station for switching between different task-relevant networks (e.g., switching from default network to executive control network;  ;  ;  ;  ). \n\nThe spectral correlates of task inaccuracy were expressed in the gamma frequency range, thus confirming the potential role of high-frequency oscillations for conveying error signals ( ). Furthermore, notably in agreement with the BOLD signal increases, they were source localized to the bilateral FO (as part of larger sources in the inferior frontal gyrus). A general correspondence and spatial colocalization of the BOLD signal and gamma power has been established in previous studies ( ;  ; notably, including colocalization of responses in the insula,  ). Our findings also align with previous studies that reported increases in intracranially recorded gamma activity in the FO following (stop-signal) task errors ( ). Moreover, gamma-band activity per se is often interpreted as indicating enhanced processing of attended (e.g., task-relevant) sensory information ( ;  ;  ;  ). In other studies, increased gamma power (over mid-frontal sensors) during response competition has been interpreted as indicating increased cognitive control ( ). A Granger causality analysis by   suggested that, during perceptual decision-making, the FO may exert causal influence over frontoparietal areas within the gamma band. \n\nIn sum, and in light of the above literature, our fMRI and MEG results suggest that the FO is involved in performance monitoring during goal-directed hand movements, corroborating its role as suggested by previous studies in other, nonmotor tasks. Notably, while most of the above studies used trial-by-trial designs, our study featured continuous movements; thus, our results complement previous literature in showing that the FO shows similar responses in task settings requiring \u201conline\u201d performance monitoring and adjustment during manual actions. Specifically, we propose that FO activation (expressed through BOLD signal and gamma power increase) may have indicated a reaction to task inaccuracy or error, and a corresponding need for behavioral adjustment. Tentatively, this interpretation is supported by the fact that posterior alpha power behaved opposite to gamma (i.e., it decreased with increasing inaccuracy, although this effect did not reach statistical significance; see Results). It is well established that posterior alpha inversely correlates with attention and task engagement ( ;  ;  ;  ). \n\nIn addition to increased activation of the bilateral FO, our fMRI connectivity analysis revealed that these areas also increased their functional coupling with the right PPC (peak located in the IPL) during the VH task (phase matching with vision) compared with the RH task (phase matching with proprioception). An fMRI study by   used a task requiring attention to faces, houses, or body parts, and found that the FO increased its functional coupling with visual areas processing the respective task-relevant stimulus category. In our case, the connectivity increase of the FO was not with primary and secondary visual cortices, which had shown task-dependent (attentional set) activity increases in our previous studies ( ;  ). Instead, FO coupling increased with the IPL of the right PPC; an area that is involved in more high-level processes including multisensory and sensorimotor integration, and visuospatial attention ( ;  ;  ). \n\nWe propose that this result is related to the fact that visual hand movements were task relevant in the VH task, but had to be ignored in the RH task (where phase matching was done with proprioception). Thus, visual hand movements were essential for correcting phase-matching error in the VH task, but irrelevant in the RH task. Notably, FO connectivity was not significantly different during periods of visuoproprioceptive incongruence; neither did we find significant differences between congruent and incongruent conditions in the main fMRI GLM analysis. This suggests that the observed VH > RH task-dependent connectivity difference was related to the task-relevant hand feedback modality being vision > proprioception per se, rather than to congruence/incongruence between vision and proprioception. This interpretation fits with previous work showing that the right PPC, specifically areas in the right IPL, are critical hubs for executing and correcting visually guided arm movements ( ;  ;  ;  ;  ;  ). \n\nPotentially, this effect might have been enhanced by intrinsic differences between the modalities in relation to visuoproprioceptive integration and error detection [i.e., it might have been easier for participants to notice a phase-matching error when focusing on visual action feedback (VH task) than when focusing on proprioception (RH task)]. This could have been because of visual body position estimates being intrinsically less variable than proprioceptive ones ( ), and because the visual body position was easier to compare with, and integrate with, the visually presented target (in the VH task) than the proprioceptive body position (in the RH task). However, note that the target quantity was not visuospatial but abstract (i.e., the oscillatory growing-and-shrinking phase of the fixation dot). When we lowered the statistical threshold of the main GLM analysis to   p\u2009  <  \u2009  0.005, uncorrected, the bilateral FO (the PPI seed regions) and the right PPC (the PPI target region) showed a stronger correlation with task inaccuracy under the VH task compared with the RH task. Although this was a weak effect, it could mean that, overall, errors were more easily processed (in those areas) in the VH task. Interestingly, participants performed slightly worse in the RH than in the VH task, which could support the interpretation that proprioceptive performance monitoring was less efficient than when vision was used. This may also fit with previous reports of increased BOLD signal in the FO for error trials of which participants were aware, compared with unaware errors ( ;  ). Specifically,   also observed increased functional connectivity of the FO to the PPC [bilaterally, in addition to the bilateral primary somatosensory cortex (S1)] during aware > unaware errors. \n\nIn sum, we suggest that the increased connectivity between the FO and the right PPC during the VH > RH task indicates that the FO signals an increased need for control and attentional and/or behavioral adjustment (following poor performance) to visuomotor regions in the right PPC, which could also be related to how easily those performance deficits could be detected. \n\nThe above speculations could explain why we did not observe any connectivity increases of the FO during the RH > VH task. Accordingly, this could be because participants were less aware of their phase-matching accuracy/inaccuracy when performing the task with the unseen real hand. Future work should evaluate this possibility. \n\nIn addition to activations in the bilateral FO, we also found BOLD signal increases because of poor phase matching in the PMd (spanning to the SMA at uncorrected thresholds) and in the dlPFC (at the junction of middle frontal gyrus and frontal pole). Both areas have been strongly implied in performance monitoring in other contexts, albeit implying the SMA rather than the more lateral PMd ( ). The SMA has been shown to respond to unexpected stimuli (e.g., surprising action outcomes;  ;  ;  ;  ). Furthermore, BOLD signaling in the SMA and the PMd has previously been reported to correlate with positional error in a visuomotor learning task ( ) and in continuous hand\u2013target tracking ( ). In line with the interpretation provided in these studies, the PMd (and, uncorrected, SMA) activation we observed may indicate an updating of movement plans in response to poor detected phase matching. Similarly, the lateral PFC is considered a crucial part of the sensorimotor hierarchy ( ;  ) and is thought to contribute to performance monitoring and error detection (e.g., by preparing attentional task sets and comparing behavioral output against them;  ;  ;  ;  ). In our experiment, the dlPFC activation could imply similar underlying \u201chigh-level\u201d functions. \n\nConversely, we observed that BOLD signal in the contralateral M1 correlated positively with task accuracy. This effect could be related to the fact that higher task accuracy coincided with more pronounced hand movements and, thus, also with associated differences in movement velocity, acceleration, and jerk. Future work will have to clarify whether differences in movement trajectories contribute to differential M1 activation, as observed here. However, we had included movement amplitude as a regressor of no interest in our first-level GLMs, which should have largely accounted for this potential bias. Alternatively, this observation also aligns with the known role of M1 in motor learning ( ;  ;  ), with previous findings that M1 activity correlated with visuomotor adaptation performance ( ) or with visuomotor target-tracking performance ( ), and with the fact that a perturbance of the M1 via transcranial magnetic stimulation resulted in reduced sensorimotor adaptation ( ). \n\nOur results should be compared with previous studies with some caution, since our task was designed around continuous movements; therefore, we could not isolate specific time points\u2014and neuronal correlates\u2014that would clearly correspond to specific cognitive or motor processes like, for example, error detection or correction. Future variations of our task design should therefore try to validate our interpretation. \n\nIn conclusion, our results suggest a critical role for the bilateral FO in performance monitoring during goal-directed manual action, and that, following errors in visually guided manual action specifically, the FO may signal an increased need for control to visuomotor regions in the right PPC. \n\n \n", "metadata": {"pmcid": 8896555, "text_md5": "132f710f43c0140a56945b7dd84c16bc", "field_positions": {"authors": [0, 38], "journal": [39, 45], "publication_year": [47, 51], "title": [62, 157], "keywords": [171, 276], "abstract": [289, 1696], "body": [1705, 47224]}, "batch": 1, "pmid": 35165200, "doi": "10.1523/ENEURO.0524-21.2021", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8896555", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=8896555"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8896555\">8896555</a>", "list_title": "PMC8896555  A Crucial Role of the Frontal Operculum in Task-Set Dependent Visuomotor Performance Monitoring"}
