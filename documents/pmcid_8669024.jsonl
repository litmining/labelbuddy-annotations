{"text": "Goh, Ariel X.-A. and Bennett, Daniel and Bode, Stefan and Chong, Trevor T.-J.\nCommun Biol, 2021\n\n# Title\n\nNeurocomputational mechanisms underlying the subjective value of information\n\n# Keywords\n\nHuman behaviour\nDecision\nMotivation\nMotivation\n\n\n# Abstract\n \nHumans have a striking desire to actively seek new information, even when it is devoid of any instrumental utility. However, the mechanisms that drive individuals\u2019 subjective preference for information remain unclear. Here, we used fMRI to examine the processing of subjective information value, by having participants decide how much effort they were willing to trade-off for non-instrumental information. We showed that choices were best described by a model that accounted for: (1) the variability in individuals\u2019 estimates of uncertainty, (2) their desire to reduce that uncertainty, and (3) their subjective preference for positively valenced information. Model-based analyses revealed the anterior cingulate as a key node that encodes the subjective value of information across multiple stages of decision-making \u2013 including when information was prospectively valued, and when the outcome was definitively delivered. These findings emphasise the multidimensionality of information value, and reveal the neurocomputational mechanisms underlying the variability in individuals\u2019 desire to physically pursue informative outcomes. \n  \nIn this study, authors investigate the neurocomputational mechanisms that drive an individual\u2019s subjective preference for information. Using fMRI and model-based analysis, they demonstrate that information value is multidimensional, accounting for the individual variability in the pursuit of informative outcomes. \n \n\n# Body\n \n## Introduction \n  \nSeminal studies in information processing have shown that humans and other animals consistently pursue information even if it cannot be utilised to improve future outcomes . This is in striking contrast with traditional theories of reward maximisation, which propose that information is only valuable when it has instrumental utility (i.e., is useful for obtaining other rewards or primary reinforcers) that outweighs its costs . Several frameworks suggest that the intrinsic value of information may be quantified along multiple dimensions, including the capacity of that information to (1) reduce uncertainty; and (2) generate desirable beliefs (i.e., its expected valence) . Although there is considerable data on how the brain estimates these features, most current models assume that such estimates are computed in a similar manner across participants. Importantly, however, individuals vary widely both in their subjective estimates of uncertainty, and their desire for positively valenced information . These elements together modulate the importance, or subjective value, that individuals place on the information, and their desire to physically pursue it . However, the neural mechanisms underlying this individual variability remain unclear. \n\nAt the core of many current theories of information-seeking is the axiom that the desire to seek information reflects a desire to reduce uncertainty  (although see ). Such frameworks define the value of information as the amount of uncertainty (or entropy) that it has the capacity to reduce . Typically, uncertainty is defined according to the Shannon entropy of beliefs\u2014a function from information theory that stipulates a fixed relationship between entropy and objective outcome probabilities . However, the assumption that individuals perceive uncertainty in a fixed manner is at odds with behavioural observations that individuals vary widely in their preference to reduce it . Despite the fact that perceived uncertainty lies at the core of many extant models of information value, an outstanding question is how individuals vary in their subjective estimates of uncertainty, and their tolerance of it. \n\nDebate has also centred on how information value is driven by its expected valence. In general, humans exhibit a bias towards obtaining information that they expect will be positive versus negative. For example, individuals may prefer to remain ignorant about results from a medical test when the outcome may be potentially negative versus positive , or about the value of their stock portfolio in a downward-trending market . However, models of uncertainty reduction predict that any information that reduces uncertainty should have value, regardless of its expected valence . This is consistent with findings that rats and humans prefer early information about an upcoming electric shock even if it is unavoidable , and that there is an overall preference for information regardless of whether it conveys a positive or negative outcome . The issue of how the valence of information modulates information value is therefore yet to be definitively addressed. \n\nIn determining how individuals subjectively value information, a useful approach is to examine the sacrifices that they are willing to incur in exchange for it. To date, the majority of studies have asked participants to decide on the amount of money they would be willing to sacrifice in return for information  (although some have used temporal delays ). A limitation of monetary and temporal costs is that, in either case, a small initial increment of each cost substantially discounts the willingness of individuals to choose the information at hand. Similarly, individual differences in price elasticity (i.e., marginal value of money) also affect preference for information, thereby impairing the ability to measure individual differences in the value of information itself . These factors could potentially reduce the sensitivity of models to capture individual differences in information valuation . An alternative cost that has been shown to discount rewards more gradually and incrementally is physical effort , which may offer a sensitive approach to examining cost-benefit trade-offs in acquiring information. \n\nNeuroimaging studies have shown that information-seeking is associated with activation in brain regions often implicated in reward-based decision-making . These include the ventromedial prefrontal cortex (vmPFC) , orbitofrontal cortex (OFC) ; anterior cingulate cortex (ACC) ; and ventral striatum (VS) . Importantly, few studies have focussed on the processes underlying the subjective estimates of information value , particularly across its multiple dimensions (such as how individuals estimate and tolerate uncertainty, and how they value positively valenced information). Consequently, it remains unclear which areas encode the value of information across multiple stages of decision-making: from the prospective valuation of information to be received, to the actual delivery of the information itself. This is an important question, given that areas that are fundamental to information-seeking behaviour may be predicted to hold representations of subjective information value in a similar manner across multiple stages of the decision process. \n\nIn this model-based neuroimaging study, we applied a novel information-seeking paradigm to determine the neurocomputational mechanisms underlying the subjective value of information across its component dimensions. Participants in our study had to decide how much physical effort they were willing to invest for advanced information about an unchangeable lottery outcome. Importantly, information in our task was non-instrumental, which allowed us to separate the intrinsic value of information from any potential utility to alter future outcomes. We systematically varied the initial probability of winning the lottery on each trial, which allowed us to examine the effect of both uncertainty and expected valence on the desire to seek information. By estimating the subjective value of information across multiple stages of decision-making\u2014from when it was prospectively evaluated to when it was definitively delivered\u2014we were able to determine the brain regions critical to information value. \n\nTo anticipate our results, our computational models revealed that the best-fitting model of information value incorporated three key parameters: the sensitivity of individuals to uncertainty; the subjective value of reducing that uncertainty; and the subjective value of positive over negatively valenced information. Critically, fMRI data revealed that a single node within the anterior cingulate cortex encoded the subjective value of information both when prospectively valued, as well as when the outcome related to that information was actually delivered. \n\n\n## Results \n  \nThe critical task was an information-seeking paradigm, in which participants had to decide how much physical effort they were willing to invest in return for non-instrumental information (Fig.\u00a0 ). We operationalised physical effort as the amount of force exerted on a hand-held dynamometer, and defined six different effort levels as proportions of each individual\u2019s maximum voluntary contraction (MVC, as defined at the beginning of the study). Twenty-six young, healthy adults performed this task while being scanned with fMRI. To confirm the efficacy of our effort manipulation, and to accurately model each individual\u2019s sensitivity to effort costs, participants performed a standard physical effort-discounting task outside the scanner . The information-seeking task in the scanner and the effort-discounting task were closely matched in their effort requirements and overall task structure, and were performed in counter-balanced order (see \u201cMethods\u201d).    Trial structure for the effort-discounting, and information-seeking tasks.  \n a   In the effort-discounting task, participants chose between a fixed low-reward/low-effort baseline (left of screen), and a variable high-reward offer (right of screen) associated with an equal or higher level of effort. Effort was indicated as the height of a target line on a vertically-oriented force bar. Participants received real-time feedback of their force exertion, before the outcome of their choice was revealed.   b   In the information-seeking task, participants had to decide whether they were willing to invest effort to obtain advanced information regarding an unchangeable lottery outcome. Each lottery involved a set of nine red or black cards, and participants won the lotteries in which the majority of the cards belonged to a predesignated winning colour (here, black). In the \u2018Scenario\u2019 event, participants were presented a subset of cards, and were asked whether they were willing to invest effort to reveal the identity of the remaining cards. Higher effort levels were depicted further to the right of a horizontal force bar. They were told that their choices would not alter the final outcome of the lottery, which was predetermined. At the \u2018Choice\u2019 event, participants could either choose to reveal the remaining cards for that effort level (\u2018Y\u2019), or remain ignorant about the remaining cards for minimum effort (\u2018N\u2019). If participants chose to reveal the cards, they exerted their chosen level of effort (the \u2018Effort\u2019 event), and the hidden cards were revealed (the \u2018Reveal\u2019 event). If participants chose not to reveal the cards, they exerted minimal effort, and the same starting configuration of cards as in the \u2018Scenario\u2019 event was displayed. The final outcome of the lottery was presented at the end of the trial (\u2018Outcome\u2019). \u0394t indicates jitters of 3\u20136\u2009s. \n  \n\n### Behavioural results \n  \n#### Effort-discounting task \n  \nIn the effort-discounting task, participants had to choose between a fixed, low-effort/low-reward baseline versus a more lucrative offer (Fig.\u00a0 ). The low-reward option involved exerting minimal effort (Level 1) to earn 1 cent. In contrast, the more lucrative offer required individuals to exert an equal or higher level of effort (Level 1\u20136) to earn 2 to 10 cents. We performed a mixed-effects logistic regression on choice data by modelling the fixed effects of: (1) the Effort and (2) Reward of the more lucrative offer, and (3) Task Order (effort discounting vs information-seeking first); and allowed random intercepts for participants. As expected, the probability of choosing the more lucrative offer was greater with decreasing Effort (  \u03c7  (1) = 169.50,   \u03b2  \u2009=\u2009\u22123.25,   p  \u2009<\u2009.001; Fig.\u00a0 ), and increasing Reward (  \u03c7  (1) = 94.65,   \u03b2  \u2009=\u20093.47,   p  \u2009<\u2009.001; Fig.\u00a0 ). The order in which participants completed the tasks did not influence choice (  \u03c7  (1) = 0.62,   \u03b2  \u2009=\u20090.49,   p  \u2009=\u2009.43). Overall, this confirmed the efficacy of our effort manipulation.    Behavioural choice data for the effort-discounting and information-seeking tasks.  \n a  ,   b   Proportion of trials in the effort-discounting task in which participants chose the High Reward option (Pr(HR)), as a function of the (  a  ) effort and (  b  ) reward on offer. The red lines indicate the condition median, and the boxes extend over the interquartile range (25th to 75th percentile). The whiskers extend to the largest value no further than 1.5 times the interquartile range. Outliers (i.e., those whose data lie beyond 1.5 \u00d7 the interquartile range) are indicated by red \u2018+\u2019s. (  c  ,   d  ) Preference for the informative option in the information-seeking task (Pr(Info)), plotted as a function of: (  c  ) effort, and (  d  ) the prior probability of winning, Pr(Win). Triangles depict group means, and error bars one standard error of the mean. \n  \n\n\n#### Information-seeking task \n  \nIn the information-seeking task, participants were presented with a lottery on every trial, the outcome of which was determined by the majority colour amongst a set of nine black or red cards. If the majority of cards belonged to a predesignated winning colour (e.g., black), participants would win 10c; otherwise, they would win nothing (Fig.\u00a0 ). At the beginning of the trial (the \u2018Scenario\u2019 event), participants were shown a subset of cards from the full set of nine, and had the option to either: (1) gain advanced information about the ultimate outcome of the lottery (the \u2018informative\u2019 option), or forego such information, and wait until the end of the trial to discover the outcome (the \u2018non-informative\u2019 option). Choosing either option required the exertion of effort. Importantly, however, the non-informative option required only minimum effort (Level 1), whereas the informative option required effort that was equal to or greater than the non-informative option (Levels 1\u20136). Furthermore, we emphasised to participants that the outcome of each lottery was predetermined, and that their decisions could not influence those outcomes. Thus, any information gained by effort was entirely non-instrumental, as it only affected participants\u2019 certainty regarding the lottery outcome. \n\nDuring the \u2018Scenario\u2019 event, we systematically varied the number and proportion of revealed cards, which allowed us to manipulate both the initial level of uncertainty (maximal when Pr(win) = 0.50, and minimal when Pr (win) = 0.0 or 1.0), and the expected valence of information (positive when Pr (win) > 0.50, and negative when Pr (win) < 0.50). Participants registered their preference for the informative or non-informative option through a button press with their left hand (\u2018Choice\u2019). Participants were provided with a motor cue that mapped onto the corresponding response, with mappings randomly assigned on each trial. If they chose the informative option, they were required to exert the required level of effort (\u2018Effort\u2019). We then revealed the full card set (\u2018Reveal\u2019), before providing them with the monetary outcome (\u2018Outcome\u2019). If they chose the non-informative option, participants had to exert the minimum amount of effort. No further information was provided, however, and participants had to wait for the final \u2018Outcome\u2019 event for the lottery outcome to be revealed. \n\nTo verify that effort had a comparable effect on discounting information value as it did on reward, we conducted a mixed-effects logistic regression, with participants as a random effect, in which we modelled the fixed effects of five factors. We modelled the Prior Probability of Winning (Pr (win)), as well as its squared value (Pr (win) ) given that the effect of Pr (win) on choice was hypothesised a priori to be concave down (i.e., minimal when uncertainty was low; and maximal when uncertainty was high). We also examined whether participants simply estimated information content based on the raw amount of visual information on the screen (the number of cards initially revealed), which served as a rough proxy for the mathematically defined amount of information. Including this regressor allowed us to ensure that participants were actually considering the amount of information, rather than solely adopting a simpler heuristic whereby they sought information if there were fewer cards initially displayed. Finally, as in the effort-discounting task, we analysed the effects of Effort requirements, and Task Order. \n\nThis regression showed that participants chose the informative option less often with increasing Effort (  \u03c7  (1) = 56.12,   \u03b2   = \u22122.59,   p   < .001; Fig.\u00a0 ). In addition, they chose information more often as the probability of winning increased (Pr(win),   \u03c7  (1) = 108.94,   \u03b2   = 5.87,   p   < .001). Furthermore, they chose the informative option least often when uncertainty was minimal, and most often when uncertainty was maximal (Pr(win) ,   \u03c7  (1) = 116.90,   \u03b2   = \u22125.76,   p   < .001; Fig.\u00a0 ). Finally, they were less likely to choose the informative option as more cards were initially revealed (  \u03c7  (1) = 49.07,   \u03b2   = \u22120.77,   p   < .001). As for the effort-discounting task, Task Order was not significant (  \u03c7  (1) = 0.04,   \u03b2   = 0.11,   p   = .84). \n\nTogether, these logistic regressions confirmed that: (1) effort monotonically discounted both monetary reward and information value; (2) the value of an informative option was greater when the lottery outcomes were more uncertain; and (3) the value of information was greater when the expected valence of information was positive. Next, we applied a computational model of choice to determine how information itself was subjectively valued. \n\n\n\n### Computational modelling results \n  \nOur computational modelling focused on determining whether choices were best described by models that captured individual differences in the sensitivity to uncertainty, the desire to reduce that uncertainty, and the valence of information. To obtain estimates of information-valuation parameters that were independent of estimates of effort-discounting parameters, we jointly modelled choice data from both tasks simultaneously. \n\n#### Effort discounting \n  \nTo obtain a precise estimate of subjective value, we took as our starting point a set of canonical effort-discounting functions, which considers that the subjective value of an option is a function of the reward on offer discounted by the effort involved in obtaining it. We modelled each participant\u2019s choices in the effort-discounting task using three commonly applied functions that capture the simplest canonical patterns of effort discounting\u2014linear, concave (parabolic), and convex (hyperbolic)\u2014with previous work showing that parabolic functions tend to provide the best fit in dynamometer-based effort-discounting tasks : \n\nIn these equations, the subjective value (  V  ) of an option,   O  , on a given trial,   t  , is a function of its reward (  R  ), and associated effort (  E  , the proportion of MVC required). The effort itself is scaled by a subject-specific effort-discounting parameter,   k  , with higher values indicating a greater aversion to effort. \n\n\n#### Information seeking \n  \nIn the information-seeking task, we built on these models of effort discounting by incorporating the added value of information into the functions for subjective value. We took the   k   values defined from the effort-discounting task to determine the sensitivity of individuals to effort in the Information-Seeking task. For each of the three effort-discounting functions, we tested three main model families, which together comprised seven separate models (Fig.\u00a0 ).    We compared 21 different models of information value.  \nFor each of three effort discounting functions (linear, parabolic, hyperbolic), we compared seven different models. Model Family 1 (yellow) was a control model, which ascribed no value to information. Model Family 2 assumed that the value of information was driven only by its content (lighter colours). Model Family 3 assumed that value of information was driven by both its content and its valence (darker colours). Each of Model Families 2 and 3 tested competing hypotheses on how the content of information is computed. Uncertainty was computed in Models 2.1/3.1 as a function of Shannon entropy (blue), and in Models 2.2/3.2 as a function of R\u00e9nyi entropy (red). Models 2.3/3.3 tested the hypothesis that participants used the initial number of cards as a heuristic for information content (purple). \n  \n\n\n#### Model Family 1 \n  \nThis family comprised a single   control model  , which assumed that non-instrumental information has no value (as predicted by traditional reward maximisation theories). Such theories state that the only reward available is the expected monetary value of that option,   R   (i.e., 10 \u00a2 / 2 = 5 \u00a2 for all trials). Thus, the control models for the information-seeking task were identical to those for the effort-discounting tasks above, with   R = 5  . \n\n\n#### Model Family 2 \n  \nA second model family assumed that   the value of information is driven by its content  . Recall that the content of information is traditionally quantified based on its capacity to reduce uncertainty, which is in turn operationalised in terms of the entropy of beliefs . Thus, this family postulates that the content of information (  I  ) has some intrinsic value that varies across individuals, and that this variability can be captured by a subject-specific parameter that reflects the preference of individuals to reduce uncertainty (  k  , \u2212\u221e <   k   < \u221e), with positive values indicating a greater preference for information, and negative values a lower preference. The term   k   \u2219   I   therefore represents the subjective value that an individual places on reducing uncertainty within the environment. The value of a given option on a given trial can then be considered the effect of the expected monetary reward on offer, added to   k   \u2219   I  . \n\nThis family comprised three specific models, each of which tested competing hypotheses on how information is subjectively valued: \n\nModel 2.1. Shannon entropy model\u2014Information theory formally defines the information content of an option,   I  (  O  ), as the reduction in uncertainty (quantified as the entropy of beliefs,   H  ), after viewing the stimulus, relative to before the stimulus was revealed: \n\nThis family of models defined entropy according to the Shannon entropy function \u2014the typical function used to quantify information value\u2014which assumes that the relationship between outcome probabilities and uncertainty is constant across individuals: where {  x  ,   x  } represents the set of discrete outcomes (  x   = win;   x   = loss). \n\nModel 2.2. R\u00e9nyi entropy model\u2014A limitation of Shannon entropy is that it is unable to account for potential variability in individuals\u2019 sensitivity to uncertain outcomes. For example, a model quantifying information in terms of reduction of Shannon entropy is constrained to treating, for all individuals, a prior win probability of Pr(win) = 0.3 as being twice as uncertain as a prior win probability of Pr(win) = 0.09. However, it is not necessarily true that all participants appraise probabilities in exactly this way. In contrast, R\u00e9nyi entropy  is a more generalised function, which includes a weighting parameter (\u03b1) that denotes the degree to which an individual is sensitive to uncertainty (Fig.\u00a0 ): \n\nAs   \u03b1   approaches 0, all possible events are weighted more equally, regardless of their probabilities, implying a lower sensitivity to uncertainty. Conversely, as   \u03b1   approaches infinity, entropy is increasingly determined by the events of greatest uncertainty, indicating a greater sensitivity to uncertainty. Note that, as   \u03b1   approaches 1, the function approximates the Shannon entropy function. R\u00e9nyi entropy therefore represents a more flexible function than Shannon entropy, and is therefore capable of capturing the variability in how individuals estimate the uncertainty of the environment.    Computational modelling results.  \n a   Illustration of the generalised R\u00e9nyi entropy function, and its capacity to flexibly estimate an individual\u2019s sensitivity to uncertainty. Entropy varies with the probabilty, p, of a binary outcome\u2014a relationship that is modulated by different values of the R\u00e9nyi weighting parameter   \u03b1  . As   \u03b1   approaches 1, this function approximates the Shannon entropy.   b  \u2013  d   Stepwise model selection revealed that: (  b  ) Effort discounting was best fit by a parabolic function (P = parabolic; L = linear; H = hyperbolic); (  d  ) The expected valence of information contributed significantly to information value; and (  d  ) Information content was best quantified with the R\u00e9nyi entropy function (R = R\u00e9nyi, in red; S = Shannon, in blue; C = Number of cards, in purple). WAIC is presented on a deviance scale, such that lower values indicate better relative model fit.   e   Model comparisons over the entire model space confirmed that Model 3.2 was the best-fitting model. The colour key is identical to (  c  )\u2013(  d  ) and Fig.  . Control models (assuming that information has no value) are depicted in yellow. Models incorporating an effect of information valence are depicted in darker shades, and those without in a lighter shade. Models are ordered by goodness-of-fit (note the change in scale for the poorer fitting models depicted on the right side of the panel).   f  \u2013  i   Individual parameter estimates and inferred group-level parameter distributions from the best-fitting computational model for: (  f  )   k   (effort-discounting), (  g  )   \u03b1   (R\u00e9nyi weighting parameter), (  h  )   k   (value of information content), and (  i  ) k  (value of information valence). Each plot visualises the distribution that is implied by using the medians of the posterior distributions of the group-level mean and standard deviation as hyperparameters. Parameter estimates for individual participants are presented above each distribut on.   j   The k  and k  parameters were significantly correlated across participants. \n  \n\nModel 2.3. \u2018Visual information\u2019 model\u2014Finally, we considered the possibility that information content was not related to uncertainty at all, but that participants simply used the number of cards on the screen as a heuristic for the amount of information available. Here, the value of information for an option,   I  (  O  ), is simply based on the proportion of cards that are yet to be revealed: \n\n\n#### Model Family 3 \n  \nA final model family tested the hypothesis that the value of information is driven by both its content and its valence. Valence,   W  , was defined as Pr(win) \u2212 0.5. Thus, positive values of   W   indicated a higher probability of winning, and negative values a lower probability.   W   was then scaled by a parameter   k   (\u2212\u221e <   k   < \u221e), which represented participants\u2019 individual preference for positively valenced information, such that   k   > 0 indicated a preference for information expected to be positive, and   k   < 0 a preference for information expected to be negative. In this family, we assumed that valence had an additive effect on information value: \n\nWithin this family, we tested the same models of information content as in Model Family 2 (i.e., the Shannon entropy model (3.1), the R\u00e9nyi entropy model (3.2), and the \u2018visual information\u2019 model (3.3)). \n\nTogether, the model space therefore comprised 21 candidate models (seven for each effort-discounting function). On every trial for every participant, we used a   softmax   function to estimate the probability of choosing the informative (  I  ) over the non-informative (  NI  ) option on every trial: where   \u03b2   is an inverse temperature parameter that defines each individual\u2019s choice stochasticity. We fit our models to data from the effort discounting and information-seeking tasks simultaneously, holding   k   and   \u03b2   constant between both tasks. All models were fit using a hierarchical Bayesian approach, and Hamiltonian Monte Carlo sampling as implemented in Stan . Model comparison was performed using the Watanabe-Akaike Information Criterion (WAIC) . \n\nIn keeping with previous studies, the best-fitting model (Model 3.2; Fig.\u00a0 ) was one that described physical effort discounting as a parabolic function (mean   k   = 7.75; highest density interval, HDI [6.44 9.23]) . Importantly, this model defined information value as a function of   both   uncertainty reduction   and   expected information valence: \n\nImportantly, information content was best modelled in terms of the R\u00e9nyi entropy function. Indeed, the top two models both incorporated R\u00e9nyi entropy, and differed only in their inclusion of the valence modifier (\u0394 WAIC = 30.96). The best-fitting model incorporating the Shannon entropy function was, overall, the third best-fitting function (\u0394 WAIC = 66.27). The fact that the R\u00e9nyi entropy function provided the best fit indicates significant variability in how individuals estimate uncertainty. This conclusion is further emphasised by the variance of \u03b1 across the group (mean 1.22; HDI [0.22 11.74]; Fig.\u00a0 ). Furthermore, this model also captured the variability in individuals\u2019 desire to reduce their estimated uncertainty, as indicated by the positive group mean for the   k   parameter (mean 3.01; HDI [2.02, 3.83]; Fig.\u00a0 ). Finally, this model demonstrated that expected valence had a significant effect on information value, as emphasised by the   k   parameters that were positive for all except three participants, which implies an overall preference for information about expected positive versus negative outcomes across the group (HDI [0.17, 1.03], mean 0.60; Fig.\u00a0 ). \n\nGiven that this model distinguishes the value of information content (  k  ) from its valence (  k  ), we next asked whether these two parameters are related. A correlation analysis between all model parameters revealed a positive correlation between   k   and   k   (  r   = .60,   p   < .01, Bonferroni-Holm-corrected for multiple comparisons; Fig.\u00a0 ; Supplementary Table\u00a0 ). This indicated that individuals with a greater preference to reduce uncertainty (i.e., with a higher   k  ) also had a greater preference for positively valenced information (a higher   k  ). This significant correlation raised the question of whether simpler models that included only a single free parameter for information value (instead of two separate parameters for   k   and   k  ) could provide a better and more parsimonious fit to the data. However, a simpler control model containing only a single free parameter for information performed notably worse than the winning model that included separate parameters for   k   and   k   (see \u201cMethod\u201d). \n\nFinally, we performed a model recovery analysis to confirm the validity of our model comparison procedure. This showed that we were able to identify the true generative model from amongst a set of similar competitors with an accuracy in excess of 95% for each model (Supplementary Table\u00a0 ). We also conducted a parameter recovery analysis from the best-fitting model to ensure that its parameters were precisely recoverable. This analysis confirmed that we were able to accurately recover each of the five parameters from the wining model (all   p  -values < .001; Supplementary Table\u00a0 ). Furthermore, posterior predictive checks indicated a good fit between participants\u2019 choices and model predictions (Supplementary Fig.\u00a0 ). \n\n\n\n### fMRI results \n  \nOur key imaging question was to determine whether there are common areas that encode the subjective value of information, both when it is prospectively valued, and when it is definitively delivered. We restricted our analyses to all voxels within four regions of interest (ROIs) that form the core of the reward valuation network\u2014the anterior cingulate cortex (ACC), ventromedial prefrontal cortex (vmPFC), orbitofrontal cortex (OFC), and ventral striatum (VS). Whole-brain analyses were conducted as additional, more exploratory analyses. \n\n#### A cluster within the ACC encoded the prospective value of information \n  \nFirst, we considered areas that were engaged during the prospective valuation of information. Using the parameters from our best-fitting model, we determined the subjective value of information of the chosen option on every trial for every participant. This comprised the value related to individuals\u2019 preference for uncertainty reduction (  k   \u2219   I  , with   I   defined according to R\u00e9nyi entropy) added to the expected value for positively valenced information (  k   \u2219   W  ). We took these values for every trial, and entered them as parametric modulators, time-locked to the onset of the Scenario event. This revealed a significant cluster within the caudal anterior cingulate cortex (Fig.\u00a0 , red cluster; Table\u00a0 ). No activity was detected in the remaining ROIs, even at uncorrected thresholds. At a whole-brain level, other clusters that survived correction with a voxel-wise FWE rate of 0.05 included the primary motor areas, the pre-supplementary motor area, and insula/frontal operculum (Supplementary Fig.\u00a0 ).    A cluster within the caudal anterior cingulate cortex encoded the subjective value of prospective information, and lottery outcomes when definitively delivered.  \n a   Clusters show activity that parametrically varied with the subjective value of information when prospectively evaluated (red), and when the outcome was definitively delivered (blue). The cingulate cluster that encoded information value at the delivery of the Outcome entirely encompassed the cluster that encoded the prospective valuation of information at Scenario. These results depict an analysis of all voxels within the predefined ROIs, with significant voxels indicating those that survived cluster-wise corrections for family-wise error (FWE,   p   < 0.05), with a cluster-forming threshold of   p   = 0.001 (uncorrected). No voxels encoded the value of information at the Reveal event.   b   Parameter estimates from the ACC cluster that encoded the prospective value of information at the Scenario event (i.e., the cluster shown in red in panel (  a  )). The red lines denote the median parameter estimate across the group, with the edges of each box plot indicating the 25th and 75th centiles; the whiskers extend to the most extreme data points not considered outliers, and the outliers are indicated by red \u2018+\u2019s. *,   p   <0.0005. \n    \nAreas in which activation reflected the subjective value of information of the chosen option. \n  \nVoxels survived cluster-wise corrections for family-wise error (  p   < 0.05), with an uncorrected cluster-forming threshold of   p   = 0.001. \n  \n\nAs a secondary analysis, we also considered those areas involved in the subjective valuation of the effort required for the chosen option (  k   \u2219   E  ) (Supplementary Fig.\u00a0 ). This recruited a larger, bilateral cluster encompassing both the anterior and mid-cingulate cortices. This cluster encompassed the smaller ACC region that encoded the subjective value of information. \n\nWe then decomposed the subjective value of the chosen information into its component parts, and modelled separately the value of uncertainty reduction (  k   \u2219   I  ), and the expected value of positively valenced information (  k   \u2219   W  ). This analysis revealed a similar cluster of activity within the ACC that parametrically varied with the value of uncertainty reduction. However, there was no significant activity that varied with the expected value of information valence, either within the ROIs, or at a whole-brain FWE-corrected level. This is most likely driven by the fact that decisions on every trial involved assessing two alternatives that differed in the amount of uncertainty that each had the capacity to reduce, but not in their expected information valence. Given that a value comparison was not required for information valence, it may be unsurprising that this value was not explicitly represented in BOLD activity. Regardless, these analyses indicate that the value of information was primarily signalled by a comparison between the capacity of both the informative and non-informative options to reduce uncertainty. \n\n\n#### Medial prefrontal areas encoded the delivered value of information \n  \nNext, we considered which areas were engaged during the valuation of information when it was definitively delivered. As in the preceding analysis, we computed the value of information as a function of uncertainty reduction and expected valence (  k   \u2219   I   +   k   \u2219   W  ). In our task, uncertainty could be reduced at either the Reveal stage (if the informative option was chosen), or the Outcome stage (if the non-informative option was chosen). We therefore entered   k   \u2219   I   +   k   \u2219   W   as a parametric modulator time-locked to the onset of the Reveal and Outcome event, and considered activity at each of these events separately. \n\nInterestingly, there was no significant activity at the Reveal event within our ROIs. Across the whole brain, there was a cluster within the right fusiform gyrus that survived voxel-wise correction for family-wise error (  p   = 0.001; Supplementary Fig.\u00a0 ). In contrast, activity at the Outcome event was present at significant thresholds across a large cluster spanning the caudal ACC. This cluster entirely encompassed the more focal ACC cluster that was engaged during the prospective valuation of information. Indeed, we found that activity within the ACC cluster engaged during the earlier Scenario event varied positively with the value of delivered information at the Outcome event (Fig.\u00a0 ). In addition, there was a separate cluster within the rostral (pregenual) ACC (Table\u00a0 , Fig.\u00a0 , blue clusters). At the whole-brain level, activity at the Outcome event was found within areas including the right supramarginal gyrus, left inferior temporal sulcus, and right inferior frontal gyrus (  p   < 0.01; Supplementary Fig.\u00a0 ). \n\nFinally, a convergent finding amongst several recent studies is that there is a substantial overlap between the neural mechanisms that encode information value and reward . Although this was not a principal question in our study, we did consider the effect of reward delivery on BOLD activity at the Reveal and Outcome stages. The main result was that the encoding of information value and reward involved regions that partially overlapped, but also those that were unique to each entity. The outcomes of this analysis are summarised in Supplementary Fig.\u00a0  and Supplementary Table\u00a0 . \n\n\n\n\n## Discussion \n  \nIndividuals vary considerably in the subjective value they place on information, but the neurocomputational mechanisms underlying this valuation process remain unclear. Our key result was that the value of information depends critically on an individual\u2019s estimates of uncertainty, their desire to reduce it, as well as their desire for positive information. Applying our computational model to fMRI data revealed that the anterior cingulate cortex was critical in prospectively estimating the future value of information, as well as the subjective value of that information when the final outcome was delivered. Importantly, a subset of voxels within the ACC encoded value at both stages of the decision-making process, suggesting a key role for this area in processing information value, and guiding information-seeking behaviour. Overall, our results emphasise the multidimensionality of information value, and reveal the key areas involved in the subjective valuation of information across multiple phases of decision-making. \n\nSeveral studies have consistently demonstrated that information is intrinsically valuable, over and above any potential utility in obtaining tangible benefits . The majority of studies have quantified the value of information in terms of its capacity to reduce uncertainty. Such a metric provides useful insights into how information signals can be used to update predictions about the external world. However, one important assumption of these studies is that uncertainty is estimated in a fixed manner across participants, based on an arbitrary weighting of event probabilities (i.e., according to Shannon entropy ). Importantly, we showed that a more generalised entropy function (the R\u00e9nyi entropy ) was better able to capture the significant variability in individuals\u2019 sensitivity to uncertain outcomes. In addition, participants demonstrated an overall appetite for positive information , but the distribution of   k   values indicated substantial variability in their desire to reduce their estimated levels of uncertainty. This result has notable implications for future studies on information processing, by arguing for a more flexible approach to capture the wide range of differences in how individuals estimate uncertainty, and their tolerance of it. \n\nOur modelling results speak to recently proposed frameworks of curiosity\u2014the intrinsic desire of individuals to know, and to actively seek out information . Normative frameworks of behaviour, such as the free energy principle, argue that organisms have an intrinsic tendency to minimise surprise, in order to optimise their predictions about future states of the world . The proposition that information value is related to its capacity to reduce uncertainty fits parsimoniously into such accounts . More recent frameworks, however, have highlighted the multidimensionality of information value, by arguing that information-seeking is motivated, not only by the desire to reduce uncertainty, but also by the anticipatory utility of that information . Our findings offer support to these more recent theories, by showing that models containing a valence modifier consistently outperformed those without. This result, that the valence of information contributes positively to its value, is consistent with accounts that individuals may experience a positive emotional \u2018boost\u2019 from the anticipation of a positive outcome , which may act as an additional source of internal motivation  for the individual to pursue information. Indeed, some have proposed that this anticipatory utility may give information hedonic value (by inducing a positive affect), while the capacity of information to reduce uncertainty provides information with its cognitive value (by allowing an agent to update their internal models of the world) . \n\nOur data also demonstrate a strong link between separate dimensions of information value. The vast majority of participants in our task preferred positively to negatively valenced information, as evidenced by the overall positive   k   values across the group. This is consistent with the overall weight of evidence in the literature. Although individuals tend to exhibit a greater preference for information relating to potentially positive versus negative outcomes , this is not universal, as some studies have shown that individuals demonstrate the opposite preference . Across our sample, the   k   parameter was significantly positively correlated with the   k   parameter, indicating that individuals with a greater preference to reduce uncertainty (high   k  ) tended to be those who had a stronger preference for potentially positive information (high   k  ). This suggests that the cognitive and hedonic values of information, though distinct constructs, may nevertheless be closely related. \n\nOur fMRI analyses built on previous neuroimaging studies which focused on where and how information prediction errors are encoded . These previous studies have shown that areas of the reward network are also sensitive to the updating of internal predictive models to minimise uncertainty . Although such studies have provided insight into the areas that might encode objective uncertainties in the environment, few studies have examined which areas represent the subjective value of information to the individual, particularly across its multiple dimensions . We reasoned that areas that are critical to encoding the subjective value of information across its multiple dimensions should represent that value similarly when decisions are prospectively made, and when outcomes are actually delivered. Our results implicated a region within the ACC as a critical node that encodes information value at both stages, which is consistent with recent neurophysiological data demonstrating the selectivity of subpopulations of ACC neurons to the information signal . \n\nAlthough the activity related to information value was manifest when the Outcome was definitively delivered, it was not evident at the intermediate Reveal stage, when information was presented in the absence of the explicit lottery outcome. Although speculative, one explanation relates to the potential utility of the presented information . At the initial Scenario event, the utility of information was obviously substantial, given that it was the key variable on which participants based their decision. At the final Outcome event, the utility of information was central to reinforcing the conditional relationship between any previously delivered information, and the result of the lottery itself. In contrast, the Reveal event was an intermediate event, at which the veracity of any delivered information had yet to be confirmed by receipt of the final outcome. This may have been particularly relevant given that all participants were na\u00efve to our paradigm, and were unlikely to have yet formed a strong conditional relationship between the stimulus (card array) and the definitive outcome of the lottery . Of course, this interpretation that the neural representation of information value is a function of its utility remains to be formally addressed in future experiments. \n\nThe involvement of the ACC in computing the predicted value of information, as well as the value of received outcomes, makes adaptive sense. The sensitivity of the ACC to information value at the time of the decision is consistent with previous studies showing that ACC activity reflects prospective information about a chosen option . In addition, our result that the ACC represents the value of information on delivery of the outcome is in keeping with those of separate studies showing that the ACC indexes uncertainty  and \u2018surprise\u2019 more generally when an outcome becomes known . Together, representing information value within the same region at different stages of the decision process may be advantageous, as the predicted value of information within this region can then be used to compute expectations about the environment, and the value of the received outcome can then be used to update value estimates within this same region to guide future decisions . \n\nInterestingly, information value in our task was not associated with activity in our other ROIs. It is of course difficult to interpret the absence of activity, but we note that there has been some variability in the involvement of these areas in previous studies on information-seeking. For example, although there is a substantial body of work implicating the ventral striatum in processing other types of reward, its involvement in information valuation has been equivocal\u2014whereas some studies on information value have noted ventral striatal activity , others have not . Similarly, although the vmPFC has been consistently implicated in reward-related processing, such studies have tended to focus on more tangible reinforcers (e.g., food, juice, or money ), and less data are available on its role in information valuation . Importantly, information is distinct from these other reinforcers in that it tends to be associated with high outcome variance, and past studies have indeed shown a sensitivity of vmPFC neurons to outcomes with higher event probabilities . Previous studies have implicated the OFC when non-instrumental information is delivered , but not when uncertainty is initially evoked . The reasons for the discrepancies between studies are not clear, and may potentially be driven by differences in task design, or, in the case of the ventral striatum, the lower signal-to-noise ratio in deeper brain structures. Nevertheless, such inconsistencies indicate potentially important points of difference in how information and other types of reinforcers are processed, and should be a focus of future work. \n\nIn summary, our findings provide insights into the neurocomputational mechanisms underlying the subjective valuation of information. A critical finding was that information value can be decomposed along several dimensions that are all subject to significant interindividual differences\u2014including one\u2019s sensitivity to uncertainty; desire to reduce it; and preference for information with an expected positive valence. Our neuroimaging data reveal the ACC as a key region involved in the processing of information value, both prospectively and upon receipt of the outcome associated with that information. Together, these results inform current frameworks of curiosity, which emphasise the intrinsic value of information, and the desire of individuals to pursue information for information\u2019s sake . Our study provides a robust method to measure individual differences in information valuation, which can potentially be used to understand deficits in curiosity that lead to sub-optimal information-seeking behaviour, both in healthy individuals and clinical populations who suffer from impairments of decision-making. \n\n\n## Methods \n  \n### Participants \n  \nWe recruited 30 young, healthy adults, four of whom were excluded for not understanding task instructions, leaving 26 participants in the final sample (12 male, 14 female; aged 20 to 33 (  M   = 25.19, SD = 3.25); all right-handed). As compensation, participants received a flat payment of AUD $30 plus an additional amount earned from the task (  M   = $4.83, SD = $0.32). All participants had normal or corrected-to-normal vision. All participants provided written informed consent, and protocols were approved by the Monash University Human Research Ethics Committee (ID CF16/2332-2016001170). \n\n\n### Materials and procedure \n  \nParticipants performed two separate tasks: a physical effort-discounting task (performed outside the scanner), and a non-instrumental information-seeking task with physical effort costs (while being scanned). Participants completed both tasks in a single session, with the order of tasks counter-balanced across participants. Stimuli were presented using the Psychophysics Toolbox implemented in MATLAB R2015b (Mathworks Inc., US). Participants held an fMRI-compatible dynamometer (SS25LA, BIOPAC Systems, USA) in their dominant (right) hand, and provided button responses with their non-dominant (left) hand. \n\n#### Effort calibration and familiarisation \n  \nEffort in this study was operationalised as the amount of physical force applied to the hand-held dynamometer. To normalise effort requirements across tasks and across individuals, effort levels were defined as a proportion of each individual\u2019s maximum voluntary contraction (MVC). The MVC for each participant was defined at the beginning of the study as the maximum of three successive, self-paced contractions of the dominant hand . We then defined six levels of effort, ranging from 13% MVC (Level 1) to 78% MVC (Level 6), at increments of 13%. Participants were familiarised with these effort levels in a preliminary training phase, during which they had to perform a ballistic contraction to match or exceed the required effort level on each of 24 trials (4 per effort level). This training phase was conducted prior to each of the Effort-Discounting and Information-Seeking tasks. \n\n\n#### Effort-discounting task \n  \nThe goal of the effort-discounting task was to estimate the degree to which individuals were averse to investing effort in return for reward . By assessing this behaviour separately from the information-seeking task, we were able to measure individual differences in effort discounting independently of individual differences in information valuation. On each trial, participants chose between a fixed low-reward/low-effort baseline, and a more lucrative high-reward offer that required them to invest an equal or greater amount of effort (Fig.\u00a0 ). The fixed baseline was always a reward of 1 cent for investing minimal effort (Level 1), while the variable offer was the option to win a higher reward (2, 4, 6, 8 or 10 cents) for an equal or higher level of effort (Levels 1\u20136). On each trial, participants viewed the Effort and Reward levels for the two options, and chose the option they thought was \u201cmore worth the effort\u201d. Trials were self-paced, and their choice was highlighted for 0.5\u2009s. They then had 2.5\u2009s to exert their preferred level of effort, and were provided feedback at the end of the trial. If they successfully reached the target effort level, they were rewarded with the stake on offer; otherwise, they were rewarded 0 points. Each of the 6 Effort \u00d7 5 Reward conditions was sampled four times, for a total of 120 trials, which were divided into ten blocks to minimise the effect of fatigue. \n\n\n#### Information-seeking task \n  \nTo investigate preferences for non-instrumental information, we developed a novel paradigm which required participants to choose between exerting higher levels of effort to obtain predictive information about an unchangeable lottery outcome, or exerting minimum effort and foregoing such information (Fig.\u00a0 ). Each trial was a lottery comprising a set of nine black or red cards. In each lottery, participants could win 10 \u00a2 if the majority of cards belonged to a predesignated winning colour (e.g., black); otherwise they won 0 \u00a2. Importantly, the information gained by exerting higher levels of effort was entirely non-instrumental, as it only affected participants\u2019 certainty regarding the lottery outcome, without affecting the outcome of the lottery itself, which was predetermined. Participants were informed about this feature, and confirmed that they understood that the non-instrumental nature of this information. \n\nAt the beginning of each trial, participants were shown a subset of cards from the full set of nine (the \u2018  Scenario\u2019   event)\u2014this represented partial information about the lottery outcome. We systematically manipulated the probability of winning on each trial by varying the number and proportion of revealed cards. This allowed us to manipulate both the initial level of uncertainty, as well as the expected valence of information presented. Uncertainty was maximal when the probability of winning (Pr(win)) was 0.5, and minimal as Pr(win) approached 0 or 1. Valence was neutral when Pr(win) = 0.5; negative when Pr(win) < 0.5; and positive when Pr(win) > 0.5. We were thus able to separate out the effect of valence on equivalent levels of uncertainty. For example, the uncertainty when Pr(win) = 0.9 is identical to that when Pr(win) = 0.1, but the former has an expected valence that is positive, and the latter negative. \n\nPr(win) was computed as the binomial probability that the winning card colour would be in the majority . This probability incorporates both the number of winning cards displayed at the Scenario event, together with all possible combinations of cards yet to be revealed: where   n   is the number of cards remaining to be drawn, and   n   is the number of additional winning cards required for a majority, given the number of wining cards (  n  ) already drawn: \n\nThis computation is the Bayes-optimal approach for computing probabilities for a binomial random variable, given the information that was available to participants . \n\nWe chose 16 starting card configurations to sample from Pr(win) at approximately even increments (generally 0.05\u20130.07). This ensured that we did not oversample card configurations that led to similar values of Pr(  win  ). For example, Pr(win) values between 0.64\u20130.69 could be the result of starting configurations comprising 3\u2009W(inning)/2\u2009L(osing) cards, 2\u2009W/1\u2009L, and 1\u2009W/0\u2009L. In such situations, we rationalised the number of configurations by omitting some configurations (e.g., 2\u2009W/1\u2009L). Note that an exception to the sampling interval of 0.05\u20130.07 was around Pr(win) = 0.5, in which the smallest possible increment was \u00b1 0.14 given the nine-card structure of the task. We also ensured that, for each positively valenced (Pr(win)) configuration (e.g., 4\u2009W/2\u2009L), we sampled from the corresponding negatively valenced (1 \u2212 Pr(win)) configuration (i.e., 2\u2009L/4\u2009W). Of the 16 starting configurations, 7 were positively valenced, 7 were negatively valenced, and 2 were neutral (Supplementary Table\u00a0 ). Each starting configuration was presented once at every effort level for every participant. \n\nParticipants were required to decide between one of two options\u2014they could either remain ignorant about the concealed cards (the non-informative option), or choose to reveal all the cards to discover the lottery outcome (the informative option). Choosing either option required the exertion of some degree of effort. Importantly, however, choosing the non-informative option required individuals to exert only minimal effort (Level 1), whereas choosing the informative option required effort levels equal to or greater than the non-informative option (Levels 1\u20136). Note that the design of this task was closely matched to the effort-discounting task, in which participants made choices between a fixed baseline and variable offer. This included having a condition in which the informative and non-informative options were matched in effort, as a sanity-check to confirm that participants preferred informative over non-informative options when effort was not a factor. It is also worth noting that, by design, there was no ambiguity associated with the decisions that participants had to make. On each trial, both the informative and non-informative options had the same fixed probability of winning (i.e., each option was associated with the same combinations of cards). Furthermore, each option was associated with a single, known outcome\u2014the informative option always led to the full set of cards being revealed, and the non-informative option never did. \n\nThe Scenario was displayed for 4\u2009s followed by a random jitter of 3\u20136\u2009s. Participants were then prompted to make a button press response indicating their preference (the \u2018  Choice\u2019   event). They were provided with a motor cue (\u2018Y\u2019 for the informative, and \u2018N\u2019 for the non-informative option) that appeared randomly on the left or the right of the screen, and mapped onto the corresponding button press response (e.g., in Fig.\u00a0 , informative = left button press; non-informative = right). This ensured that the Scenario event could isolate activity unique to decision-making, separate from that associated with motor preparation. Participants had two seconds in which to make their response, and their choice was then highlighted until the end of that two-second period. Immediately thereafter, participants were prompted to exert their chosen amount of effort within a 2.5\u2009s window (the \u2018  Effort\u2019   event). If they failed to reach the required effort level in time, they automatically forfeited the lottery and received 0 cents. These two motor response screens (choice + effort) were followed by a second random jitter of 3\u20136\u2009s. \n\nParticipants were then shown the set of cards they chose to view (the \u2018  Reveal\u2019   event). If participants chose the non-informative option, they were simply shown the same starting configuration of cards they had seen in the Scenario event. However, if they chose the informative option, the full set of cards was revealed for 2\u2009s. Finally, after a further random jitter of 3\u20136\u2009s, participants were provided with the monetary outcome of the lottery (\u2018You won: 10 \u00a2\u2019 or \u2018You won: 0 \u00a2\u2019; the \u2018  Outcome\u2019   event). This outcome was displayed for 1\u2009s. Note that the outcome provided complementary information to the preceding reveal\u2014uncertainty about the lottery outcome was reduced during the Reveal event when the informative option was chosen, and during the Outcome event when the non-informative option was chosen. A further random jitter of 3\u20136\u2009s was imposed between the \u2018  Outcome\u2019   event, and the \u2018  Scenario\u2019   event on the next trial. \n\nTo ensure that participants maintained task engagement, 5% of trials were catch trials, in which participants had to press any button within two seconds of a white X appearing on one of the cards. This could occur during either the Scenario or the Reveal events. If participants were successful, they would proceed to the next trial without penalty; failure to respond in time resulted in a penalty of 50 cents. Across all catch trials in all 26 participants, only one participant missed a single response (mean correct responses on catch trials across the group = 99.0%). In total, there were three runs of 32 trials (16 initial card configurations, each sampled once for each of the six effort levels). Participants completed a block of practice trials outside of the scanner before completing the main task in the scanner. \n\n\n\n### Mixed-effects analyses \n  \nIn addition to computational modelling (see below), choice behaviour on the effort-discounting and information-seeking tasks were analysed with mixed-effects logistic regression analyses using the   lme4   package in R . For these analyses, we included random intercepts for all participants, as well as random slopes for all within participants predictors .   p  -values for omnibus tests were computed using Wald chi-square tests with Type-III sums of squares. All continuous predictors were   z  -scored prior to analysis to allow for comparison of standardised coefficients between predictors. For all continuous regression effects, we report a chi-square statistic, a   p  -value, and a standardised regression coefficient (which can be interpreted as a change in the log-odds of the outcome variable corresponding to a one standard deviation increase in the predictor variable). \n\n\n### Computational models \n  \n#### Defining information content and entropy \n  \nAs discussed in the \u201cResults\u201d, the information content of an object,   I  (  O  ), was defined as   I  (  O  ) =   H  (  O  )  \u2212   H  (  O  ) , where   H  (  O  )  represents the entropy of beliefs prior to the stimulus being revealed, and   H  (  O  )  the entropy of beliefs after it was revealed.   H  (  O  )  was computed based on the starting card configuration presented in the Scenario display.   H  (  O  )  for each of the informative and non-informative options were computed based on the capacity of each option to reduce uncertainty. The informative stimuli were associated with complete resolution of uncertainty (i.e.,   H  (  O  )  = 0), and their information content was therefore   I  (  O  )  =   H  (  O  ) . In contrast, non-informative stimuli had no capacity to reduce uncertainty (i.e.,   H  (  O  )  =   H  (  O  ) ), and their information content was therefore   I  (  O  )  = 0. Note that all of the details that are required to compute the information gain from both the informative and non-informative stimuli were available to participants at the time of making a choice. \n\n\n#### Model fitting \n  \nThe 21 candidate models were fit using a hierarchical Bayesian approach. Choices from the effort-discounting and information-seeking tasks were fit simultaneously, and   k   and \u03b2 were held constant within participants across both tasks. Model comparisons were performed using the Watanabe-Akaike Information Criterion (WAIC) , a statistic for comparing models fit with hierarchical Bayesian methods. Like other information criteria (e.g., AIC, BIC, DIC), it selects models according to their goodness-of-fit (marginal likelihood, estimated as the mean log-likelihood of data across posterior samples), minus a penalty for the model\u2019s effective complexity (estimated as the variance of the log-likelihood across posterior samples), such that more parsimonious models are favoured over more complex ones . \n\nWe conducted two sets of model comparison analyses: in the first, we sought to identify the best-fitting model overall by identifying the single model with the best WAIC value. In the second, we sought to compare different model \u2018families\u2019 (i.e., those sharing features such as a common effort-discounting function or a common information-valuation function) to identify the model features that were associated with the best predictive performance across the entire model space. For the latter analysis, we compared model families by taking the mean overall WAIC across each of the models within a family. \n\nTo ensure parameters were constrained to values within an a priori plausible range, we transformed three parameters to lie within a bounded range using the cumulative normal distribution: 0 \u2264   k   \u2264 100; 0 \u2264 \u03b1 \u2264 50; and 0 \u2264   \u03b2   \u2264 20. Parameters were estimated using partial pooling, such that participant-level parameters were assumed to be drawn from group-level Gaussian prior distributions, the parameters of which were freely estimated from the data. The specific models are detailed in the \u201cResults\u201d section. \n\nGiven the significant correlation between   k   and   k  , we performed a control analysis to verify that they truly represented distinct constructs, rather than as common manifestations of the same latent cognitive process. We formulated an additional model that was identical to our best-fitting model, with the exception that it more parsimoniously estimated   k   and   k   as a single parameter (i.e., the model was fit under the constraint that   k   =   k  ). Importantly, this control model was still outperformed by the original two parameter model (\u0394 WAIC = 268.22, SE = 37.86). This implies that   k   and   k   are best modelled as distinct processes, which were free to vary independently of each other, but happened to be closely correlated. \n\n\n\n### Functional magnetic resonance imaging (fMRI) \n  \n#### Data acquisition \n  \nFunctional MRI data were collected on a 3 Tesla Siemens Skyra MRI scanner. Stimuli were displayed on an MRI-compatible monitor positioned at the head of the scanner bore, and participants viewed the monitor through a mirror mounted on a 32-channel head coil. Functional data were acquired with a T2*-weighted gradient-echo-planar imaging (EPI) sequence using interleaved slice acquisition (T  2200\u2009ms; T  30\u2009ms; flip angle 90\u00b0; 38 contiguous slices with a slice thickness of 3.0\u2009mm without an interslice gap; voxel size 3.0 mm  on a base matrix of 64 \u00d7 64 pixels, oriented along the AC-PC line). In each run, we collected 455 volumes, with the first eight volumes removed to allow for steady-state tissue magnetisation. We also acquired a structural T1-weighted magnetisation-prepared rapid gradient-echo (MPRAGE) sequence for anatomical localisation (T  1,900\u2009ms; T  2.49\u2009ms; flip angle 9\u00b0; 192 slices with a slice thickness of 0.90\u2009mm; voxel size 0.9 mm  on a base matrix of 256 \u00d7 256 pixels), and gradient-echo field maps to correct for geometric distortions caused by inhomogeneities in the magnetic field. \n\n\n#### Pre-processing \n  \nData pre-processing was performed with FMRIPREP version stable , a Nipype  based tool. Each T1-weighted (T1w) volume was corrected for INU (intensity non-uniformity) using N4BiasFieldCorrection v2.1.0  and skull-stripped using antsBrainExtraction.sh v2.1.0 (using the OASIS template). Brain surfaces were reconstructed using recon-all from FreeSurfer v6.0.1 , and the brain mask estimated previously was refined with a custom variation of the method to reconcile ANTs-derived and FreeSurfer-derived segmentations of the cortical gray-matter of Mindboggle . Spatial normalisation to the ICBM 152 Nonlinear Asymmetrical template version 2009c  was performed through nonlinear registration with the antsRegistration tool of ANTs v2.1.0 , using brain-extracted versions of both T1w volume and template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using fast (FSL v5.0.9 ). \n\nFunctional data were slice-time corrected using 3dTshift from AFNI v16.2.07  and motion corrected using mcflirt (FSL v5.0.9) . This was followed by co-registration to the corresponding T1w using boundary-based registration  with six degrees of freedom, using bbregister (FreeSurfer v6.0.1). Motion correcting transformations, BOLD-to-T1w transformation and T1w-to-template (MNI) warp were concatenated and applied in a single step using antsApplyTransforms (ANTs v2.1.0) using Lanczos interpolation. \n\nPhysiological noise regressors were extracted applying CompCor . Principal components were estimated for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). A mask to exclude signal with cortical origin was obtained by eroding the brain mask, ensuring it only contained subcortical structures. Six tCompCor components were then calculated including only the top 5% variable voxels within that subcortical mask. For aCompCor, six components were calculated within the intersection of the subcortical mask and the union of CSF and WM masks calculated in T1w space, after their projection to the native space of each functional run. Frame-wise displacement  was calculated for each functional run using the implementation of Nipype. \n\n\n#### Analyses \n  \nData were analysed using SPM12 (Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, United Kingdom;  ), implemented in MATLAB. Each participant\u2019s data were modelled using fixed effects analyses. The effects of the experimental paradigm were estimated for each participant on a voxel-by-voxel basis using the principles of the general linear model (GLM). Predictor functions were formed by modelling the onsets of the events of interest with a stick (delta) function convolved with the canonical haemodynamic response function. Low-frequency noise was removed with a 128\u2009s high-pass filter. The GLM included three regressors of interest: the Scenario event, the Reveal event, and the Outcome event, each of which was associated with a parametric modulator (see below). Other regressors which were included, but not analysed, included the motor events (i.e., the Choice and Effort events), and the onsets of the catch trials and their outcomes. The six head motion parameters derived during realignment (three translations and three rotations) were incorporated as additional nuisance regressors. \n\nThe main focus of this model-based fMRI study was to determine the neurocomputational mechanisms underlying: (1) the subjective valuation of information, and (2) the reduction of uncertainty across individual participants. To address the first goal, we computed the subjective value of information (i.e.,   k   \u2219   I   +   k   \u2219   W  ) for the chosen option on every trial for every participant using the parameters from our best-fitting model. As discussed in the \u201cResults\u201d,   I   represented the content of information, which was weighted by an individual\u2019s preference to reduce uncertainty,   k  ; and   W   represented the valence of information, which was weighted by an individual\u2019s preference for positively valenced information,   k  . In addition to the value of information, we computed the subjective value of effort (i.e.,   k   \u2219   E  ) for every trial using the same model. We then entered these two subjective values as orthogonalised, parametric modulators for the Scenario event-related regressor. \n\nTo address the second goal, we computed the subjective value of information when it was finally delivered at the Reveal or Outcome screens. As for the first goal, the subjective value of information was defined through the winning model as   k   \u2219   I   +   k   \u2219   W  , which represents the amount by which uncertainty was reduced (as defined by the R\u00e9nyi entropy function with a participant-specific \u03b1 parameter), added to the valence of information. These subjective values were then entered as parametric modulators for the Reveal and Outcome events separately. We note that the visual displays for the Reveal and Outcome events were quite distinct, but the effects of information value as a parametric modulator was analysed for each event separately. Regression coefficients were estimated at the subject level using the standard restricted minimum-likelihood estimation implemented in SPM12. Variance inflation factors for all of our regressors were < 4, indicating that multicollinearity between regressors was not an issue in our design  (Supplementary Table\u00a0 ). A GLM design matrix for a representative participant is provided in Supplementary Fig.\u00a0 . \n\nSPM contrast images from the first level were then taken to a second-level group analysis. We restricted our analyses to all voxels within regions-of-interest (ROIs) comprising the ACC, vmPFC, OFC and VS using the Harvard-Oxford Cortical and Subcortical Structural Atlas (corresponding to the \u2018anterior cingulate\u2019, \u2018medial frontal\u2019, \u2018frontal orbital\u2019 and \u2018nucleus accumbens\u2019 labels; Harvard Center for Morphometric Analysis,  ). To define those regions sensitive to the prospective valuation of information at the Scenario event, we took first-level SPM contrast images for the two subjective value modulators, and input these into a second-level factorial ANOVA with factors of Information and Effort. To define those regions sensitive to the value of information when it was definitively delivered, we took first-level SPM contrast images for the information value modulator at each of the Reveal and Outcome events, and input these into a second-level   t  -test for each event separately. In all analyses, we considered significant those voxels which survived cluster-wise corrections for family-wise error (FWE,   p   < .05), with a cluster-forming threshold of   p   = .001 (uncorrected). We additionally conducted the same analyses with the same contrasts at whole-brain level for an exploration of these effects without our a priori defined ROIs. \n\n\n\n### Reporting summary \n  \nFurther information on research design is available in the\u00a0  linked to this article. \n\n\n\n## Supplementary information \n  \n\n\n\n\n \n", "metadata": {"pmcid": 8669024, "text_md5": "3b917ff7f76c638c7e0f8bfef2e2fd2f", "field_positions": {"authors": [0, 77], "journal": [78, 89], "publication_year": [91, 95], "title": [106, 182], "keywords": [196, 243], "abstract": [256, 1711], "body": [1720, 74783]}, "batch": 1, "pmid": 34903804, "doi": "10.1038/s42003-021-02850-3", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8669024", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=8669024"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8669024\">8669024</a>", "list_title": "PMC8669024  Neurocomputational mechanisms underlying the subjective value of information"}
