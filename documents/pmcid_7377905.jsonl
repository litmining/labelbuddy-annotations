{"text": "Bang, Dan and Ershadmanesh, Sara and Nili, Hamed and Fleming, Stephen M\neLife, 2020\n\n# Title\n\nPrivate\u2013public mappings in human prefrontal cortex\n\n# Keywords\n\nprefrontal cortex\ncontext\ndecision-making\nsocial cognition\ncognitive control\nmetacognition\nHuman\n\n\n# Abstract\n \nA core feature of human cognition is an ability to separate private states of mind \u2013 what we think or believe \u2013 from public actions \u2013 what we say or do. This ability is central to successful social interaction \u2013 with different social contexts often requiring different mappings between private states and public actions in order to minimise conflict and facilitate communication. Here we investigated how the human brain supports private-public mappings, using an interactive task which required subjects to adapt how they communicated their confidence about a perceptual decision to the social context. Univariate and multivariate analysis of fMRI data revealed that a private-public distinction is reflected in a medial-lateral division of prefrontal cortex \u2013 with lateral frontal pole (FPl) supporting the context-dependent mapping from a private sense of confidence to a public report. The concept of private-public mappings provides a promising framework for understanding flexible social behaviour. \n \n\n# Body\n \n## Introduction \n  \nA striking aspect of human social behaviour is how often we say things we do not really mean simply because the situation requires it. For example, a politician may have doubts about a policy but, in order to boost voters\u2019 faith in her, defend it with great confidence. Conversely, an employee may be certain that his manager is wrong but, in order to minimise social friction, tentatively present his argument. Central to these scenarios is a distinction between private states of mind \u2013 what we think or believe \u2013 and public actions \u2013 what we say or do. A general ability to separate private and public aspects of mental states is thought to have evolved under the constraints of social communication ( ). In having a \u2018control buffer\u2019 between private states and public actions, an agent may avoid revealing its current state to competitors (e.g., by suppressing signs of fragility). It also allows an agent to deceive competitors (e.g., by displaying signs of strength) without interfering with processes that are needed for resolving its current state (e.g., taking steps to replenish energy). \n\nIn modern life, where people navigate complex social worlds, this ability to adapt private-public mappings to the context takes on new functions \u2013 including minimising conflict and facilitating communication. For example, social norms pertaining to politeness vary between contexts, such that a response which is appropriate in one context may be very inappropriate in another (e.g., commenting on a person\u2019s appearance at home versus at work). Contextual modulation of private-public mappings is, however, particularly challenging: social norms may be arbitrary, social contexts are typically diffuse over time and space, and there is often a tension between the nature of our private states and the public actions required by the context. Indeed, context-inappropriate social behaviour is a common symptom in a variety of neuropsychiatric conditions \u2013 such as frontotemporal dementia ( ), autism ( ), schizophrenia ( ) and borderline personality disorder ( ) \u2013 at times with profound effects on quality of life. \n\nUnderstanding why and how social function is impaired in these conditions is likely to be aided by a more thorough characterisation of the cognitive and neural mechanisms that underpin contextual modulation of private-public mappings. Here we studied how the brain solves this problem using decision confidence as a model system. Confidence is well-suited for studying private-public mappings because there is often a dissociation between the confidence that we privately feel and that which we publicly communicate ( ;  ;  ). Further, recent experimental work has provided us with the tools to separately manipulate private and public aspects\u00a0of confidence ( ;  ). In our experiment, subjects were required to communicate their confidence about simple perceptual decisions in different social contexts, with each context requiring a different mapping from private to public confidence. For example, one context required subjects to overstate their confidence in order to maximise reward, whereas another required them to understate their confidence. \n\nPreliminary evidence suggests that a private-public distinction for confidence is reflected in a medial-lateral division of prefrontal cortex (PFC). First, recent work has indicated that dorsal anterior cingulate cortex (dACC) ( ;  ) and perigenual anterior cingulate cortex (pgACC) ( ;  ;  ;  ;  ) \u2013 both located in the medial wall of PFC \u2013 support the formation of an internal (private) sense of confidence. Second, a large body of literature has observed activation of lateral PFC, in particular the lateral frontal pole (FPl), in relation to explicit (public) reports of confidence ( ;  ;  ;  ;  ;  ;  ;  ) \u2013 raising the possibility that lateral PFC supports a mapping between private and public confidence. This hypothesis fits with a broader role of lateral PFC in cognitive control functions such as task or\u00a0set\u00a0switching ( ;  ). It also fits with the observation that injury to lateral PFC is associated with context-inappropriate social behaviour ( ). Here, by combining univariate and multivariate analyses of fMRI data, we provide evidence for this division of labour, showing that FPl supports the context-dependent mapping from an internal sense of confidence to a public report. \n\n\n## Results \n  \n### Experimental manipulation of private-public mappings \n  \nSubjects (  n  \u00a0=\u00a028) performed a social perceptual decision task, first in a behavioural session and subsequently during fMRI ( ). On each trial, subjects made a group decision about a visual stimulus with one of four partners. Subjects were told that the partners were created by replaying the responses of four people performing the perceptual task on a separate day but, in reality, the partners were simulated. First, subjects judged whether a field of dots was moving left or right. Next, after being informed about the identity of their partner on the current trial, subjects were asked to report their confidence in the perceptual judgement \u2013 an estimate which would enter into the group decision. Subjects were then shown the current partner\u2019s response for that trial. Finally, implementing a common group decision rule ( ), the individual decision made with higher confidence was automatically selected as the group decision, after which feedback about its accuracy was delivered. Subjects were incentivised to help each group achieve as many correct group decisions as possible but, by design, could only affect group decisions through their confidence reports. \n   Experimental framework for dissociating private and public confidence.  \nOn each trial, subjects made a perceptual group decision with one of four partners. They first decided whether a random dot motion stimulus was moving left or right. We varied the fraction of coherently moving dots in order to manipulate subjects\u2019 internal sense of confidence in their decision. Subjects were then informed about their partner on the current trial and were asked to submit a report of confidence in their initial decision (discrete scale from 1 to 6). Subjects were then shown the partner\u2019s response, after which the individual decision made with higher confidence was selected as the group decision. Finally, subjects received feedback about choice accuracy, before continuing to the next trial. We engineered the partners to have the same choice accuracy as subjects but to differ in mean confidence. Subjects were incentivised to help each group achieve as many correct decisions as possible: they were told that we would randomly select two trials for each group in each session (4 \u00d7 2\u00a0\u00d7\u00a02\u00a0=\u00a016 trials) and pay \u00a31 in bonus for every correct group decision (in reality, all subjects received \u00a310 in bonus). In this design, the strategy for maximising group accuracy (reward) is to match your partner\u2019s mean confidence. The structure of the task differed between the behavioural and fMRI sessions as explained in the main text. \n \n   Confidence matching maximises group accuracy and thereby reward.  \nThe heat map shows expected group accuracy as a function of the mean confidence of two players with the same\u00a0level of task performance (i.e.\u00a0sensory\u00a0noise). The heat map was derived analytically using the sensory\u00a0noise fitted to an example subject and by assuming maximum entropy confidence distributions (see  , for details on calculation). The heat map shows that expected group accuracy is highest along the identity line: that is, when a subject\u2019s mean confidence (y-axis) is matched to that of the current partner (x-axis; the four avatars indicate the four partners\u2019 mean confidence as specified in\u00a0the task). Under our incentive structure, expected reward is proportional to expected group accuracy: the higher the expected group accuracy, the higher the probability that a randomly selected group decision will be correct. \n  \n\n   Schematic of study protocol.  \nSubjects took part in separate behavioural and fMRI sessions on the same day. The prescan session involved four phases. In phase 1, we calibrated four levels of coherence so as to achieve target levels of choice accuracy (60%, 70%, 80% and 90%). In phases 2\u20134, we trained subjects on the social task. In phase 2, subjects were paired with the partners in a block-wise manner (each partner is indicated by a unique colour and name). There were four cycles of blocks of 10 trials per partner (e.g.,   A\u2013B\u2013C\u2013D\u2013A\u2013B\u2013C\u2013D\u2013A\u2013B\u2013C\u2013D\u2013A\u2013B\u2013C\u2013D  ). The context screen was shown before each block of trials but not after a perceptual decision. In phase 3, subjects were paired with the four partners in an interleaved manner, with the current partner\u2019s identity revealed after each perceptual decision. In phase 4, the \u2018showdown\u2019 stage was played out in the background. In addition, we introduced a condition where the social context was hidden. The scan session involved four runs, using the same design as in phase 4 of the prescan session. We matched the distribution of conditions (coherence\u00a0\u00d7\u00a0context) across scan runs in order to facilitate multivariate analysis of the fMRI data. \n  \n\n   Confidence distributions used to generate four partners who differ in mean confidence.  \nThe distributions were constructed so as to have maximum entropy for a given level of mean confidence (see  , for details on calculation). \n  \n \nWe varied two features of the task in a factorial (4\u00a0\u00d7\u00a04) manner. First, we varied the fraction of coherently moving dots (coherence) to manipulate subjects\u2019 internal sense of confidence in a perceptual judgement. In general, the higher the coherence, the higher subjects\u2019 confidence. Second, we engineered the partners (context) to have the same choice accuracy as subjects but to differ in mean confidence. In this case, the strategy for maximising group accuracy (and thereby reward) is to match a partner\u2019s mean confidence ( ). If a subject always reports higher confidence than a partner, then they would not benefit from the trials where they were wrong but the partner was correct. In contrast, if a subject always reports lower confidence than a partner, then they would not benefit from the trials where the partner was wrong but they were correct. The design thus allowed us to separate public from private confidence and thereby probe private-public mappings in behaviour and brain activity. \n\nThe aim of the behavioural session was to calibrate levels of coherence so as to achieve target levels of choice accuracy and to train subjects on the social task ( ). The training had three phases. First, subjects were paired with the four partners in a block-wise manner. Second, the partners were interleaved, with the identity of the current partner revealed after the perceptual choice. Finally, using the same design as in the fMRI session, the \u2018showdown\u2019 stage was played out in the background, with subjects not seeing the partner\u2019s response or the group outcome. This change, which was introduced to minimise inter-trial dependencies in behavioural and neural responses, meant that subjects had to rely on their knowledge (expectations) about the partners learned in the preceding behavioural session. In addition, to establish a baseline for behavioural and neural responses, we added a condition where the partner\u2019s identity was hidden. The fMRI session consisted of four scan runs, with the distribution of conditions matched across runs in order to facilitate multivariate analysis of the fMRI data (i.e. four trials for each coherence x context condition in each scan run). To help subjects keep track of the behaviour of each group, they were informed every 20 trials how often their individual decision had been selected as the group decision for a particular partner. These selection statistics were reset after each scan run. \n\n\n### Confidence reports reflect motion coherence and social context \n  \nWe first tested whether subjects\u2019 confidence reports in the fMRI session varied as a function of our factorial design (see   for analysis of prescan session). As intended, subjects\u2019 confidence reports were influenced by both motion coherence and social context ( , ordinal regression; coherence:   t  (27) = 6.95, p<0.001, context:   t  (27) = 4.82, p<0.001, interaction:   t  (27) = \u22120.03, p=0.975). More specifically, subjects\u2019 reported confidence increased with the level of coherence ( ) and the mean confidence of the current partner ( ). In other words, the confidence reported for a specific level of coherence depended on the current partner\u2019s mean confidence ( ) \u2013 demonstrating that subjects flexibly adjusted the mapping from an internal sense of confidence to an explicit report of confidence according to the social context. \n   Separate influences of motion coherence and social context on confidence reports.  \n(  A  ) Mean confidence reported for each level of coherence. (  B  ) Mean confidence reported when playing with each partner. The question mark indicates a condition where the partner\u2019s identity was hidden. (  C  ) Heat map visualising mean confidence in each condition of our factorial design (confidence was z-scored for each subject before averaging across subjects). Warmer colours indicate higher confidence. All data are from the fMRI session. In (  A  ) and (  B  ), data are represented as group mean\u00a0\u00b1\u00a0SEM. Each dot is a subject. \n \n   Analysis of confidence reports in prescan session.  \nRows 1\u20133 indicate phases 2\u20134 in the behavioural session\u00a0(see\u00a0 ). Row 4 indicates the fMRI session and is included for comparison. (  A  ) Mean confidence reported for each level of coherence. (  B  ) Mean confidence reported when playing with each partner. The question mark indicates a condition in which the partner\u2019s identity was hidden. (  C  ) Heat map over mean confidence in each condition of our factorial design (confidence was z-scored for each subject before averaging across subjects). Warmer colours indicate higher confidence. In (  A  ) and (  B  ), data are represented as group mean\u00a0\u00b1\u00a0SEM. Each dot is a subject. \n  \n\n   Analysis of confidence reports separated by partner identity.  \nEach partner was identified by a unique colour (pink, blue, green or red) and name (Hamed, Max, Sara or Jennifer) \u2013 with the name indicating the partner\u2019s gender. The attributes were randomly assigned to the four partner types (low, medium-low, medium-high and high). Visualisation of mean confidence reported for each partner name indicates that there was no modulation by partner identity. As the task was not optimised for studying identity effects (e.g., a subject does not experience the same name in association with different partner types or the same partner type in association with different names), we did not seek to further unpack behaviour in terms of partner identity. Data are represented as group mean\u00a0\u00b1\u00a0SEM. Each dot is a subject. \n  \n \n\n### Encoding of motion coherence and social context in prefrontal cortex \n  \nWe focused our fMRI analysis on three regions of interest (ROIs) that have been identified as putative neural substrates of decision confidence across a variety of studies but whose role in the generation of a context-dependent confidence report is unclear ( ). First, dACC and pgACC, located in the medial wall of PFC, have been consistently linked to the formation of an internal (private) sense of confidence ( ;  ;  ;  ;  ;  ;  ). For example, a recent fMRI study found that pgACC tracked all variables necessary for the formation of an internal sense of confidence in a novel psychophysical task that isolates decision confidence from its component parts ( ). Second, FPl, a region in human prefrontal cortex with no homologue in the monkey brain ( ), has consistently been found to track explicit (public) reports of confidence ( ;  ;  ;  ;  ;  ;  ). Of the three ROIs, FPl is of particular interest. We have previously hypothesised that FPl supports the mapping from private to public confidence ( ). First, FPl is not activated by tasks that vary private confidence in the absence of explicit reports ( ). Second, the microstructure ( ;  ) and integrity ( ) of FPl predicts the degree to which an individual\u2019s confidence reports reflect their task performance \u2013 a relationship which may be explained by a role of FPl in maintaining a stable mapping from private to public confidence. However, to date, this hypothesis about the function of FPl has never been directly tested. \n   Encoding of motion coherence and social context in lateral frontal pole.  \n(  A  ) Regions of interest (ROIs). (  B  ) We modelled neural responses to the context screen, including both linear and quadratic terms for coherence and context as parametric modulators \u2013 with the quadratic context term indexing the need for a context-dependent private-public mapping. (  C  ) ROI contrast estimates for coherence (K), quadratic coherence (K ), context (C) and quadratic context (C ). We tested significance (asterisk) by comparing contrast estimates across subjects to zero (p<0.05, one-sample   t  -test). Statistical results are summarised in  . Data are represented as group mean\u00a0\u00b1\u00a0SEM. (  D  ) Visualisation of whole-brain activation for quadratic context in lateral prefrontal cortex (clusters significant at p<0.05, FWE-corrected for multiple comparisons, with a cluster-defining threshold of p<0.001, uncorrected). See Appendix 1 for whole-brain activations in response to context screen and Appendix 2 for whole-brain activations in response to presentation of the motion stimulus. dACC: dorsal anterior cingulate cortex. pgACC: perigenual anterior cingulate cortex. FPl: lateral frontal pole. \n \n   Evaluation of quadratic terms.  \nThe analysis of ROI responses to the context screen shown in   was based on a model (GLM1) that included linear and quadratic terms for coherence (K) and context (C) as parametric modulators. Both the linear and the quadratic terms were derived from our factorial design and theoretically motivated. Nevertheless, we ran an independent set of analyses to validate the inclusion of the quadratic terms in our model. To this end, we extracted ROI activity estimates under GLM3 \u2013 originally estimated for RSA \u2013 which modelled neural responses to the context screen separately for each condition of our factorial design (4 \u00d7 4\u00a0=\u00a016). We applied a full model (linear and quadratic) and a reduced model (only linear) to these activity estimates within a regression framework and compared their goodness-of-fit (here defined as adjusted R  which controls for the number of model predictors). This approach revealed that the goodness-of-fit was higher for the full than the reduced model in FPl and that this difference was higher for FPl than the other ROIs. (  A  ) Heat map visualising mean ROI activity estimates for each condition of our factorial design under GLM3 (activity estimates were z-scored for each subject before averaging across subjects). (  B  ) Mixed-effects analysis of ROI activity estimates. Plots show (  left  ) fixed effects under full model and (  right  ) difference in adjusted R  between full and reduced model under a linear mixed-effects regression model (both fixed and random effects for each subject). (  C  ) Group-average analysis of ROI activity estimates. Plots show (  left  ) fixed effects under full model and (  right  ) difference in adjusted R  between full and reduced model under a linear regression analysis of the mean ROI activity estimates shown in panel A. \n  \n \nAs an initial assessment of the contribution of the three ROIs to a context-dependent mapping from private to public confidence, we first estimated a general linear model (GLM1) of neural activity locked to the screen that revealed the current partner (context screen;  ). We selected the context screen as our time window of interest for two reasons. First, the context screen is the first point in a trial that information about the current partner is revealed \u2013 any context-related regressors would have little meaning if assigned to timepoints earlier on in a trial. Second, during the presentation of the context screen, subjects have all the information needed to internally decide on a context-dependent confidence report, but the neural response will not be confounded by the engagement of motor processes needed to select a confidence report \u2013 a motor plan can only be prepared after the randomised\u00a0initial\u00a0location of the confidence marker is revealed. Building on our factorial design, we included linear and quadratic terms for coherence and context as parametric modulators of the neural response to the context screen. In this model, the quadratic context term captures the intuition that larger shifts in the mapping from private to public confidence are required when playing with both low-confidence and high-confidence partners ( ), whereas the quadratic coherence term controls for potential non-linear influences of an internal sense of confidence on the\u00a0neural response ( ). \n\nUnder this model, we would expect activity in neural areas which track private confidence to vary as a function of motion coherence, whereas neural areas which support a mapping from private to public confidence should also track information about the social context. Consistent with a role in private-public mappings, FPl tracked both motion coherence and social context ( ; see statistical results in  ). In particular, FPl activity was higher for higher levels of coherence and for both low-confidence and high-confidence partners \u2013 contexts that involved a greater need for the employment of a context-dependent private-public mapping \u2013 as indexed by the quadratic context term. As for the ROIs hypothesised to support the formation of an internal sense of confidence, only pgACC tracked motion coherence ( ). While an encoding of motion coherence on its own is insufficient to establish an area as a neural substrate for private confidence, this result is consistent with the previous finding that pgACC tracked a combination of variables that underpinned changes in private confidence ( ). \n   Encoding of motion coherence and social context in lateral frontal pole.  \nTable shows statistical results for the analysis of ROI responses to the context screen shown in  . The model (GLM1) included separate condition regressors for trials where the context was signalled and trials where the context was hidden. The condition regressor for signalled-context trials was parametrically modulated by linear and quadratic terms for coherence (K and K ) and context (C and C ). In addition to the contrast estimates for these parametric modulators, the table also shows the contrast between signalled-context and hidden-context trials. Statistical testing was performing by comparing contrast estimates across subjects to zero using a one-sample   t  -test. dACC: dorsal anterior cingulate cortex. pgACC: perigenual anterior cingulate cortex. FPl: lateral frontal pole. \n  \nFinally, we ran an exploratory whole-brain analysis using the same GLM as in the ROI analysis (see Appendix 1). Here\u00a0we focus on context-related effects: while neural encoding of an internal sense of confidence has been investigated by previous research, our study is the first to manipulate the contextual requirements on the mapping of this internal sense onto explicit confidence reports. We observed activations in relation to the quadratic context term in neural areas that are typically implicated in studies of social cognition \u2013 including bilateral temporoparietal junction ( ;  ) \u2013 and cognitive control \u2013 including a region anterior to our dACC ROI and in right dorsolateral PFC ( ). Notably, and consistent with our ROI analysis, the quadratic context term also revealed significant clusters in bilateral anterior-lateral PFC that overlapped with our FPl ROI ( ). \n\n\n### Encoding of trial-by-trial confidence in prefrontal cortex \n  \nThe preceding analysis of neural activity utilised our experimental dissociation of private and public confidence and did not directly incorporate subjects\u2019 behaviour. In order to further probe the contribution of our ROIs to a context-dependent mapping from private to public confidence, we next used subjects\u2019 confidence reports to unpack ROI response profiles at a trial-by-trial level. As shown in  , subjects\u2019 confidence reports reflect factors relating both to the perceptual decision and the social context. A simple correlation between reported confidence and ROI activity would therefore not reveal whether the relationship was driven by private or public aspects of confidence, or both. To separate the contribution of the perceptual decision and the social context, we leveraged a previously established model-based approach ( ) to estimate the confidence that subjects would have reported on a given trial had there been no contextual modulation \u2013 an estimate that could then be compared to the confidence that subjects actually reported. \n\nOur model-based estimate of private confidence is obtained by (1) fitting an ordinal regression model to the behavioural session in order to characterise the influence of motion coherence, choice reaction time and each social context on a subject\u2019s confidence reports and (2) applying the fitted model to data from the fMRI session while setting the influence of each social context to zero ( ). Importantly, this model-based estimate provides a more direct proxy of private confidence than motion coherence alone by also taking into account the time taken to make a decision \u2013 a factor which has been shown to affect private confidence over and above the strength of the perceptual evidence ( ). Indeed, our model-based approach indicated that private confidence was comparable for fast decisions made in response to low-coherence stimuli and slow decisions in response to high-coherence stimuli ( ). \n   Encoding of private and reported confidence in prefrontal cortex.  \n(  A  ) Model-based estimate of private confidence. We fitted an ordinal regression model to a subject\u2019s confidence reports from the behavioural session (we used the data from the final phase as this phase had the same task design as the fMRI session). The model has a set of weights, which parameterise the influence of the perceptual decision (coherence and choice reaction time) and social context (one term for each partner), and a set of thresholds, which parameterise report biases. We used the fitted model to predict the confidence that\u00a0a subject would have reported in the fMRI session had there been no contextual modulation \u2013 by applying the model to a subject\u2019s data while setting the context weights to zero. This prediction is a probability distribution over reports (e.g., a report of \u20181\u2019 has a 10% probability, \u20182\u2019 has 20% probability and so on). We used the expectation under this distribution as our estimate of private confidence. (  B  ) GLM analysis of the effects of private confidence and empirically observed confidence reports on ROI activity time courses. Vertical dashed line indicates the\u00a0onset of the\u00a0context screen\u00a0-\u00a0the context screen, which is presented for 1 s, is shown .5 s after the submission of the perceptual decision and is immediately followed by the confidence scale. Analyses were performed on trials in which the context was explicitly signalled. We tested significance (coloured square) for each time point by comparing coefficients across subjects to zero (p<0.05, one-sample   t  -test). \n \n   Model-based estimate of private confidence varies with both motion coherence and choice reaction time.  \nFor each subject, we used the model fitted to their data (see  ) to estimate private confidence (y-axis) for each level of motion coherence (lines) and for 10 choice reaction times specified using quantiles (x-axis). We then averaged the model-based estimate of private confidence across subjects for visualisation. \n  \n\n   Cross-validation accuracy for confidence model.  \nWe used a leave-one-trial-out procedure to assess cross-validation accuracy within the data used to fit the confidence model (final phase of the behavioural session).\u00a0For each subject, we iteratively fitted the model to all trials but one and computed the negative log likelihood of the report observed on the left-out trial under the confidence model (where the probability distribution over reports depends on the fitted model) and a null model (where the probability distribution over reports is uniform). We then summed the cross-validated negative log-likelihoods across all trials and computed the difference between the confidence model and the null model (y-axis) \u2013 with a positive value indicating higher cross-validation accuracy under the confidence model than the null model. In support of our approach, the difference between the confidence model and the null model was positive in all subjects. \n  \n \nWe related both the model-based estimate of private confidence and the empirically observed confidence reports to ROI activity time\u00a0courses\u00a0within a regression framework ( ). Our analysis showed that all three ROIs encoded the model-based estimate of private confidence (pink line). The encoding profiles peaked around 2 s after the onset of the context screen, which, given the slow dynamics of the fMRI signal, is in line with the model-based estimate of private confidence being associated with the earlier perceptual decision rather than the social context. Of the three ROIs, only dACC encoded the empirically observed confidence reports (cyan line). Consistent with a sequential computation of the private and public aspects of confidence, the dACC encoding profile of reported confidence peaked 5\u20136 s after the onset of the context screen. Given the inclusion of the model-based estimate of private confidence in this analysis, an effect of reported confidence is likely to be driven by the social context. Taken together, these results indicate that dACC tracks the input and the output of a private-public mapping. \n\nWe next reasoned that, if FPl provides the context-dependent private-public mapping that is used to transform a private state (input) into a public report (output), then connectivity between FPl and dACC/pgACC should vary with the contextual requirements of the task. In particular, connectivity should be modulated by the relationship between \u2018what I would have said\u2019 had there been no contextual modulation and \u2018what I actually said\u2019. To test this prediction, we conducted a psychophysiological interaction analysis that quantified connectivity between FPl and dACC/pgACC as a function of the difference between the model-based estimate of private confidence and the empirically observed confidence reports. We included both the individual variables as well as their interaction to allow for differences in the impact of both understating (i.e. private\u00a0>\u00a0reported) and overstating (i.e. private\u00a0<\u00a0reported) confidence on connectivity. Our analysis revealed a close coupling between FPl and dACC ( ). First, around the onset of the context screen, there was a transient increase in FPl-dACC connectivity associated with the model-based estimate of private confidence (pink line). Second, 6\u20138 s after the onset of the context screen, FPl-dACC connectivity varied with not only the model-based estimate of private confidence but also the empirically observed confidence reports (cyan line) and their interaction (green line). Visualisation of these effects showed that FPl-dACC connectivity was (1) higher for larger shifts in the mapping from private to reported confidence (off-diagonal elements are warmer than diagonal elements in  ) and (2) highest when confidence was understated rather than overstated (bottom-right elements are warmer than top-left elements in  ). Taken together, these results suggest that dACC integrates contextualised signals from FPl in order to guide trial-by-trial behaviour. \n   Functional connectivity between medial and lateral prefrontal context varies with contextual requirements of task.  \n(  A  ) Psychophysiological interaction analysis of ROI activity time courses. Traces are coefficients from a GLM in which we predicted dACC/pgACC activity from the interaction between FPl activity and (1) the model-based estimate of private confidence (pink), (2) the empirically observed confidence reports (cyan) and (3) the interaction between private and reported confidence (green) \u2013 while controlling for the main effect of each term. Vertical dashed line indicates the\u00a0onset of the\u00a0context screen\u00a0-\u00a0the context screen, which is presented for 1 s, is shown .5 s after the submission of the perceptual decision and is immediately followed by the confidence scale. Analyses were performed on trials in which the context was explicitly signalled. We tested significance (coloured square) for each time point by comparing coefficients across subjects to zero (p<0.05, one-sample   t  -test). (  B  ) Visualisation of FPl-dACC connectivity. Hotter colours indicate greater FPl-dACC connectivity as a function of variation (in   z  -score units) in private confidence (x-axis) and reported confidence (y-axis). FPl-dACC connectivity was estimated using group-level coefficients averaged across a time window from 6 s to 8 s (box in panel A). \n  \n\n### Representation of task space in lateral frontal pole \n  \nFinally, we reasoned that, if FPl indeed orchestrates the context-dependent mapping from private to public confidence, then this area should also carry detailed information about the different social situations engendered by our task. In computational terms, our task comprises 16 states (social situations), with each state corresponding to a combination of coherence and context (e.g., the state on the current trial may be \u2018low coherence + high-confidence partner\u2019, whereas on the next trial a new combination of coherence and context will be encountered). By design, each of these 16 states requires subtly different behavioural responses in order to maximise reward \u2013 a relationship reflected by subjects\u2019 confidence reports ( ). If FPl supports this contextual modulation of behavioural responses, then it should represent the different states of the task as distinct. \n\nWe tested this prediction using representational similarity analysis (RSA) and a metric known as the exemplar discriminability index (EDI) ( ). Like other multivariate methods, RSA considers the pattern of activity across voxels within an ROI rather than the mean activity across voxels. The EDI metric asks whether a multivariate pattern is more stable across scan runs   within   conditions than   between   conditions \u2013 the intuition being that higher within-condition stability shows that an ROI represents the conditions as distinct ( ). We obtained the condition-specific multivariate patterns by modelling the neural response to the context screen separately for each condition of our factorial design (GLM3). In support of a role in orchestrating private-public mappings, FPl \u2013 unlike dACC or pgACC \u2013 carried a representation of the full task space as well as the sub-spaces of coherence and context ( ;\u00a0see statistical results in  ). \n   Task space representation in lateral frontal pole.  \n(  A  ) A split-data representational dissimilarity matrix (sdRDM) is constructed by (1) computing the Mahalanobis distance between the voxel activity pattern in scan run   i   and the voxel activity pattern averaged across scan runs   j   \u2260   i   for every pair of conditions and (2) averaging the sdRDMs across scan runs. The exemplar discriminability index (EDI) is computed as the average dissimilarity across off-diagonal elements (blue) minus the average dissimilarity across diagonal elements (green). A positive EDI indicates that the voxel activity pattern within an ROI is more stable within conditions than between conditions and therefore that the ROI discriminates between the conditions. Simulated data are presented to aid visualisation. (  B  ) ROI EDIs for the full task space (KxC) as well as the sub-spaces of coherence (K) and context (  C  ). We tested significance (asterisk) by comparing EDIs across subjects to zero (p<0.05, one-tailed sign-rank test). Statistical results are summarised in  . Data are represented as group mean\u00a0\u00b1\u00a0SEM. See Appendix 3 for whole-brain EDI searchlight analysis. dACC: dorsal anterior cingulate cortex. pgACC: perigenual anterior cingulate cortex. FPl: lateral frontal pole. \n     Task space representation in lateral frontal pole.  \nTable shows statistical results for the analysis of ROI task space representations shown in  . Condition-specific multivariate patterns were obtained by modelling the neural response to the context screen separately for each condition of our factorial design (GLM3; only signalled-context trials). ROI EDIs were then computed separately for the full task space (KxC) as well as the sub-spaces of coherence (K) and context (C). Statistical testing was performed by comparing EDIs across subjects to zero using a one-tailed sign-rank test. dACC: dorsal anterior cingulate cortex. pgACC: perigenual anterior cingulate cortex. FPl: lateral frontal pole. \n  \n\n\n## Discussion \n  \nContextual modulation of social behaviour \u2013 a core part of healthy social function \u2013 is facilitated by the ability to map private states onto public actions in a flexible manner. Here we studied how the brain supports such private-public mappings, by using a social perceptual decision task that required subjects to use learned context-dependent mappings from private to public confidence in order to maximise reward. Combining univariate and multivariate analyses of fMRI data, we found that a private-public distinction is reflected in a medial-lateral division of prefrontal cortex. In line with recent studies ( ;  ), we found that dACC and pgACC tracked aspects of private confidence \u2013 as estimated by a model-based approach that controlled for the impact of the social context on subjects\u2019 confidence reports. Further, we found that dACC tracked not only private confidence \u2013 the \u2018input\u2019 to a private-public mapping \u2013 but also the confidence that subjects actually reported under the contextual requirements of our task \u2013 the \u2018output\u2019. By contrast, FPl, which was hypothesised to govern the mapping from private to public confidence itself, tracked the need for a context-dependent private-public mapping in our task and carried a high-dimensional representation of the different social situations induced by our task. Finally, and in support of a role for FPl in orchestrating the mapping from private to public confidence, FPl-dACC connectivity varied with the contextual requirements of our task \u2013 with an increase in connectivity when a larger shift in the mapping from private to public confidence was required. \n\nMore broadly, our results are in line with a role of lateral PFC in cognitive control, defined as the ability to use task representations to guide thought and behaviour ( ;  ). In a typical study on cognitive control, the appropriate stimulus-response mapping on a particular trial depends on a contextual cue (e.g., respond \u20181\u2019 when stimulus is blue in context A and \u20182\u2019 in context B). The complexity of the control problem is then increased by introducing additional hierarchical rules (e.g., another cue indicating whether to respond to the colour or size of the stimulus). Both functional neuroimaging and patient studies indicate that lateral PFC is required when control problems increase in complexity \u2013 for example, by providing a model of the current task abstracted across individual episodes or acquired through instruction ( ;  ). Our results suggest that similar neural and cognitive mechanisms are recruited to solve the private-public mapping problem inherent to social interaction. One open question is, however, whether private-public mappings involve additional computations beyond those invoked by typical cognitive control paradigms, given that the \u2018stimulus\u2019 requiring a different response involves an intervening subjective (metacognitive) state. \n\nAn alternative explanation of our results is that a division of labour between medial and lateral PFC reflects the engagement of a serial-stage process \u2013 a perceptual decision followed by a confidence report \u2013 rather than the resolution of a private-public mapping. This explanation is, however, not supported by the data. The quadratic context term \u2013 encoded by FPl \u2013 compares conditions that are matched in general task characteristics and only differ in the contextual requirements on a private-public mapping. In particular, both \u2018inlying\u2019 contexts (medium-low and medium-high confidence) and \u2018outlying\u2019 contexts (low and high confidence) require sequential preparation of a private state and a public action \u2013 the difference between these two types of context is that the latter requires a larger shift in the mapping from private to public confidence. Further, we found that FPl activity was higher on trials where the context was directly signalled than on trials where the context was hidden from subjects ( ). Again, these two types of trial are matched in general task characteristics and only differ in the availability of a context-dependent private-public mapping. We highlight that these \u2018matched\u2019 comparisons also rule out the alternative explanation that the FPl activations reflect a distinction between implicit and explicit processing ( ). \n\nOur results may prompt a re-evaluation of the contribution of lateral PFC to metacognition \u2013 the ability to monitor and evaluate our ongoing thought and behaviour. Several studies have shown that lateral PFC tracks explicit reports of confidence ( ;  ), and that the microstructure of lateral PFC predicts the degree to which an individual\u2019s confidence reports reflect their objective performance ( ;  ). These results are often taken to show that lateral PFC underpins the computation of an internal sense of confidence, or the \u2018read-out\u2019 of such a variable from circuits involved in decision-making. Our study supports and refines this latter hypothesis, by showing that FPl may contextualise an internal sense of confidence for explicit report in accordance with task requirements. On this account, a relationship between anterior prefrontal structure or function and individual differences in metacognition may not reflect a contribution to insight per se but, rather, the ability to maintain a stable private-public mapping. More broadly, our results fit with a hypothesis that variation in metacognitive biases (e.g., overconfidence) reflect social rather than cognitive factors ( ) \u2013 a hypothesis supported by evidence that a private sense of confidence may in fact be computed in a statistically optimal manner ( ;  ;  ). \n\nRecent years has seen an interest in how the brain encodes structured representations of the world for efficient learning and decision-making ( ;  ;  ). In these scenarios, context may be particularly important for adaptive behaviour. In psychology, context is defined as the set of circumstances surrounding an event (e.g., we may hear a ringing phone in different environments such as our home or a friend\u2019s house) ( ;  ). Representing context is useful because it may carry information about what to expect or what to do (e.g., we should answer a ringing phone at home but not at a friend\u2019s house) ( ;  ). Context may also hold structural information that can be generalised across events (e.g., many behaviours that are acceptable at home are not acceptable when visiting others) ( ). There is evidence that such structural knowledge is encoded in the medial temporal lobe and ventral PFC ( ;  ). Our results complement this work by identifying representations in FPl that may support a mapping between private states and public actions that are appropriate for the current context. \n\nOur study highlights several questions for future research. First, how are context-dependent private-public mappings learned? Model-free reinforcement learning (e.g., Q-learning) ( ) may be able to learn the value of taking a public action given a private state and a social context but is likely to be too memory intensive (e.g., storing Q-values for every state-action pair in every context) and too slow (e.g., having to experience every state-action pair in every context) without model-based components (e.g., using a model of the world to generalise across state-action pairs or across contexts based on their similarity) ( ). Second, what happens when there is uncertainty about the current context? In our task, the context was either explicitly signalled or fully unknown. However, in everyday life, context typically falls into neither of these categories \u2013 it is partially observable and can be inferred from available cues. At a neural level, inference on context is likely to require the involvement of additional areas such as the hippocampus which has\u00a0been hypothesised to\u00a0support inference and generalisation based on structural knowledge ( ;  ). Finally, what is the nature of the PFC task representation identified by our study? In our task, each social context is associated with a distinct private-public mapping. It is therefore hard to tell whether PFC discriminates between social contexts or a more abstract construct such as behavioural policies. This question could be addressed by using a version of our task in which seemingly\u00a0distinct social contexts require subjects to adopt the same private-public mapping. \n\nHere we focused on confidence as a canonical computation that is often the target of private-public mappings, but our approach may be adapted to other internal states in order to further elucidate the neural basis of flexible social behaviour. We achieved contextual shaping of social behaviour through a group decision rule under which subjects had to adapt the mapping from private to public confidence according to the social context in order to maximise reward. However, not all domains involving dissociations between private and public aspects of mental states \u2013 such as emotions and preferences \u2013 can be readily embedded within a decision task. Nevertheless, incentive structures may be imposed onto the mapping between a private state and a public action in a manner that mimics social life. For example, subjects may be rewarded for understating experimentally controlled feelings of pain in one context but rewarded for overstating them in another one. Similarly, subjects may be rewarded for understating their preferences for consumer items \u2013 whose valuation can be established experimentally \u2013 in one context but rewarded for overstating them in another one. An open question is the extent to which the PFC activations observed in our study will generalise across domains. \n\nThe current conceptualisation of private-public mappings may offer insight into the multiple routes to social dysfunction across a range of neuropsychiatric conditions. Broadly, contextual modulation of social behaviour requires at least three distinct sets of computation \u2013 (1) context inference, (2) action selection and (3) learning from outcomes \u2013 each presumably supported by distinct neural substrates. In future, it may be possible to distinguish different aspects of social dysfunction along each of these dimensions. For example, context-inappropriate social behaviour may arise because an individual cannot identify the current context (e.g., due to hippocampal damage), cannot inhibit prepotent but context-inappropriate actions (e.g., due to prefrontal damage), or does not make correct inferences from past experience (e.g., due to disturbance in neuromodulatory systems supporting learning). Our study provides a starting point for developing such computational-level characterisations of social dysfunction. \n\n\n## Materials and methods \n  \n### Subject details \n  \nTwenty-eight adults (14 females; mean age\u00a0\u00b1\u00a0SD, 26.36\u00a0\u00b1\u00a07.00) took part in the study. Sample size was determined based on common sample sizes in the field and in order to balance power and resource constraints ( ;  ). Each subject received a flat rate for participation (\u00a345, \u00a310/hour) and a performance-based bonus (see below). All subjects provided informed consent including consent to publish and sharing of anonymised data. The study was approved by the Ethics Committee of University College London (8231/001). \n\n\n### Experimental details \n  \n#### Task and procedure \n  \nSubjects performed a social perceptual decision task in separate prescan and scan sessions ( ). We made modifications to the task within and between these sessions. Here we first describe the full task, before detailing the changes made. \n\nEach trial began with the presentation of a fixation cross at the centre of a circular aperture. After a uniformly sampled delay (prescan:. 5\u20131 s; scan: 1\u20134 s), subjects viewed a field of moving dots inside the aperture (.4\u00a0s). Once the stimulus terminated, subjects had to press one of two buttons to indicate whether the average direction of dot motion was left or right. Once a choice had been registered, the fixation cross turned grey (.5\u00a0s). Subjects were then presented with a screen informing them about their partner on the current trial (1 s). There were four partners in total. Each partner was indicated by a unique colour and name (randomised across subjects). Subjects were told that the partners were created by replaying the responses of people performing the perceptual task on another day but, in reality, all partners were simulated. \n\nNext, subjects had to indicate their confidence in the perceptual decision, by moving a marker along a scale from 1 to 6 in steps of 1. The marker started randomly in one of the six locations on the scale and was controlled by button press. Once a response had been registered, the marker turned grey (.5\u00a0s). Subjects were then presented with the partner\u2019s response on the corresponding trial (1 s), and the individual decision made with higher confidence was selected by the computer as the group decision, highlighted by a yellow triangle (2 s). Finally, subjects received feedback about the accuracy of the group decision (2 s), before continuing to the next trial. The feedback was indicated by replacing the yellow triangle with a green plus sign if the group decision was correct and a red cross if incorrect. Subjects were incentivised to help each group achieve as many correct decisions as possible: they were told that we would randomly select two trials for each group in each session (4 \u00d7 2\u00a0\u00d7\u00a02\u00a0=\u00a016 trials) and pay \u00a31 in bonus for every correct group decision (in reality, all subjects received \u00a310 in bonus). \n\nWe varied two features of the task in a factorial (4\u00a0\u00d7\u00a04) manner. First, we varied the fraction of coherently moving dots (coherence) to manipulate subjects\u2019 internal sense of confidence in a perceptual judgement (see stimulus calibration for specification of coherence levels). Second, we specified the partners (context) such that they had the same choice accuracy as subjects but differed in mean confidence (see simulation of partners). \n\nThe behavioural session involved four phases. In phase 1, we calibrated the coherence levels so as to achieve target levels of choice accuracy (see stimulus calibration). In phases 2\u20134, we trained subjects on the social task. In phase 2, subjects were paired with the four partners in a block-wise manner. In particular, there were 4 cycles of blocks of 10 trials per partner (e.g., A-B-C-D-A-B-C-D-A-B-C-D-A-B-C-D; 4 \u00d7 4\u00a0\u00d7\u00a010\u00a0=\u00a0160 trials). The identity of the current partner was shown before each block of 10 trials. In phase 3, subjects were paired with the four partners in an interleaved manner, with the identity of the current partner only revealed after a perceptual decision had been made (4 \u00d7 40\u00a0=\u00a0160 trials). In phase 4, the group decision and the group outcome, was played out in the background, with the next trial starting after subjects had indicated their confidence. In addition, we introduced a condition where the social context was hidden (5 \u00d7 40\u00a0=\u00a0200 trials). In each phase, the coherence levels were counterbalanced across trials within a social context, so that each coherence level was experienced the same number of times for each partner. To help subjects keep track of the behaviour of each group, they were informed every 40 trials how often their individual decision had been selected as the group decision for each partner (15 s). The selection statistics were reset after each phase. \n\nThe scan session involved four scan runs, using the same task design as in phase 4 of the prescan session. We matched the distribution of conditions (coherence\u00a0\u00d7\u00a0context) across scan runs in order to facilitate multivariate analysis of the fMRI data, with four repetitions per condition (4 \u00d7 4\u00a0\u00d7\u00a05\u00a0=\u00a080 trials per scan run). The screen informing subjects about how often their individual decision had been selected as the group decision for each partner was shown every 20 trials. The selection statistics were reset after each scan run. \n\n\n#### Random dot kinematograms \n  \nSubjects viewed random dot kinematograms (RDKs) contained in a circular white aperture (7 degrees in diameter). Each RDK was made up of three independent sets of dots (each dot was 0.12 degrees in diameter) shown in consecutive frames. Each set of dots were shown for one frame (about 16ms) and then replotted again three frames later (about 50ms). Each time a set of dots was replotted, a subset of the dots, determined by the motion coherence,  , was displaced in the direction of motion at a speed of 5 degrees s , whereas the rest of the dots were displaced at random locations within the aperture. The motion direction was to the left or the right along the horizontal meridian. The dot density was fixed at 30 dots degrees  s . To help subjects maintain fixation, a circular region (0.7 degrees in diameter) at the centre of the aperture was kept free of dots. A set of coherence levels,  , was identified for each subject in a separate stimulus calibration session. \n\n\n#### Stimulus calibration \n  \nSubjects performed the perceptual part of the task in two blocks. In block 1, we deployed a set of prespecified coherence levels,  . Each coherence level was used 20 times for each direction (5 x 20 x 2 = 200 trials). We then fitted a simple signal detection theory model with a single noise parameter,  , governing the statistical relationship between coherence and choice (see simulation of partners for details on model). We selected the noise parameter which minimised the sum of squared errors between predicted and observed choice accuracy across coherence levels. In block 2, we used the fitted noise parameter to select a set of coherence levels associated with the target choice accuracies 60%, 70%, 80% and 90%,  . Each coherence level was then used 25 times for each direction (4 x 25 x 2 = 200 trials). We repeated the fitting procedure and selected a final set of coherence levels for the main task (the final fitted noise parameter was in turn used to simulate the partners). \n\n\n#### Simulation of partners \n  \nWe used a signal detection theory\u00a0model to simulate the partners\u2019 choices and confidence reports in phases 2 and 3 of the prescan session ( ). In this model, an agent receives noisy sensory evidence,  , sampled from a Gaussian distribution,  ), and makes a choice by comparing the sensory evidence to zero, choosing left if   and right if  . The mean of the Gaussian distribution is given by coherence,  , and direction,  , with   indicating left and   indicating right. The standard deviation,  , is the level of sensory noise \u2013 specified by fitting the model to a subject\u2019s choices in the stimulus calibration session (see stimulus calibration). The agent computes an internal estimate of decision confidence,  , using the absolute value of the evidence strength,   \u2013 a quantity which is monotonically related to the probability that the perceptual choice is correct given the sensory evidence and the level of sensory noise. Finally, the agent maps this internal estimate onto a confidence report,  , by applying a set of thresholds,  . Precise control over the number of times that the agent selects a particular confidence report is achieved by first simulating a vector of  \u2019s \u2013 using the known sequence of stimuli in the task \u2013 and then setting the thresholds in  -space so as to achieve a desired confidence distribution. In this way, we created partners with low, medium-low, medium-high and high mean confidence (see   for confidence distributions). We simulated phases 2 and 3 separately, so that a particular partner had the same confidence distribution in each phase. In addition, we simulated  \u2019s for each partner in each session under the constraint that their choice accuracy was within 1% of the target choice accuracy for each coherence level (see stimulus calibration). In phase 4, and in the scan session, we did not simulate responses. Instead, to calculate how often a subject\u2019s individual decision had been selected as the group decision, we first computed for each trial the probability of a subject\u2019s decision being selected given their confidence report and the partner\u2019s confidence distribution and then averaged these probabilities across trials. \n\n\n\n### Behavioural analysis \n  \n#### Regression analysis \n  \nWe used ordinal regression (probit) to analyse subjects\u2019 trial-by-trial confidence reports. The model included (contrast-coded) coherence and context as predictors of interest and (log-transformed) choice reaction time, choice, motion direction and marker starting position as predictors of no interest. We z-scored all variables before analysis. We excluded trials in which the partner\u2019s identity was hidden. We performed a separate regression for each subject. We tested the group-level significance of a predictor by comparing the coefficients across subjects to 0 (p<0.05,\u00a0one-sample   t  -test). \n\n\n#### Confidence model \n  \nWe used a previously established approach ( ) to construct a model of private confidence for fMRI analysis. We fitted an ordinal regression model to a subject\u2019s confidence reports in the final phase of the behavioural session using six predictors: (1) z-scored, contrast-coded coherence, (2) z-scored, log-transformed choice reaction time and (3-6) a dummy variable for each explicitly signalled context. We then applied the fitted model to a subject\u2019s data in the fMRI session, while setting the fitted context coefficients to zero. This approach yields an out-of-sample prediction about the level of confidence that a subject would have reported on a given trial in the absence of contextual (i.e. partner-specific) modulation. The prediction takes the form of a probability distribution over possible responses (e.g., a report of \u20181\u2019 has a 10% probability, \u20182\u2019 has a 20% probability and so on). We used the expectation under this distribution as our estimate of private confidence. \n\n\n\n### fMRI analysis \n  \n#### Acquisition \n  \nMRI data were acquired on a 3T Siemens Prisma scanner with a 64-channel head coil. T1-weighted structural images were acquired using a 3D MPRAGE sequence: 1 \u00d7 1\u00a0\u00d7\u00a01 mm resolution voxels; 176 sagittal slices, 256 \u00d7 224 matrix; TR\u00a0=\u00a02530 ms; TE\u00a0=\u00a03.34 ms; TI\u00a0=\u00a01100 ms. BOLD T2 -weighted functional images were acquired using a gradient-echo EPI pulse sequence: 3 \u00d7 3\u00a0\u00d7\u00a03 mm resolution voxels; 48 transverse slices, 64 \u00d7 74 matrix; TR\u00a0=\u00a03.36; TE\u00a0=\u00a030 ms; slice tilt\u00a0=\u00a00 degrees, slice thickness\u00a0=\u00a02 mm; inter-slice gap\u00a0=\u00a01 mm; ascending slice order. Field maps were acquired using a double-echo FLASH (gradient echo) sequence: TE1\u00a0=\u00a010 ms; TE2\u00a0=\u00a012.46 ms; 64 slices were acquired with 2 mm slice thickness and a 1 mm gap; in-plane field of view is 192 \u00d7 192 mm  with 3 \u00d7 3 mm  resolution. \n\n\n#### Preprocessing \n  \nMRI data were pre-processed using SPM12. The first 4 volumes of each functional run were discarded to allow for T1 equilibration. Functional images were slice-time corrected, realigned and unwarped using the field maps ( ). Structural T1-weighted images were co-registered to the mean functional image of each subject using the iterative mutual-information algorithm. Each subject\u2019s structural image was segmented into grey matter, white matter and cerebral spinal fluid using a nonlinear deformation field to map it onto a template tissue probability map ( ). These deformations were applied to structural and functional images to create new images spatially normalised to the Montreal Neurological Institute (MNI) space and interpolated to 2 \u00d7 2\u00a0\u00d7\u00a02 mm voxels. Normalized images were spatially smoothed using a Gaussian kernel with full-width half-maximum of 8 mm. The motion correction parameters estimated from the realignment procedure and their first temporal derivatives \u2013 12 \u2018motion\u2019 regressors in total \u2013 were included as confounds in the first-level analysis for each subject. \n\n\n#### Physiological monitoring \n  \nPeripheral measurements of a subject\u2019s pulse and breathing were made together with scanner slice synchronisation pulses using a Spike2 data acquisition system (Cambridge Electronic Design Limited, Cambridge UK). The cardiac pulse signal was measured using an MRI compatible pulse oximeter (Model 8600 F0, Nonin Medical, Inc Plymouth, MN) attached to a subject\u2019s finger. The respiratory signal, thoracic movement, was monitored using a pneumatic belt positioned around the abdomen close to the diaphragm. A physiological noise model was constructed to account for artifacts related to cardiac and respiratory phase and changes in respiratory volume using an in-house MATLAB toolbox ( ). Models for cardiac and respiratory phase and their aliased harmonics were based on RETROICOR ( ) and a similar, earlier method ( ). Basis sets of sine and cosine Fourier series components extending to the 3rd harmonic were used to model physiological fluctuations. Additional terms were included to model changes in respiratory volume ( ;  ) and heart rate ( ). This procedure yielded a total of 14 \u2018biophysical\u2019 regressors that were sampled at a reference slice in each image volume. The regressors were included as confounds in the first-level analysis for each subject. \n\n\n#### Regions of interest \n  \nWe focused on three a priori ROIs highlighted by previous research on decision confidence. The dACC mask was an 8 mm sphere around the peak coordinates (MNI coordinates [  x y z  ] = [0 17 46]) identified by  . The pgACC mask was defined using the coherence x distance\u00a0second-level   t  -map from  . The FPl mask was defined using the right-hemisphere atlas developed by   and mirrored to the left hemisphere to create a bilateral mask. \n\n\n#### Univariate analysis \n  \nUnivariate analysis of fMRI data was performed using SPM12. Our main analysis was based on an event-related GLM (GLM1) of the neural response to the context screen. This model included three condition regressors. First, the context screen when the partner was signalled (signalled, 1 s boxcar). Second, the context screen when the partner was hidden (hidden, 1 s boxcar). Third, the update screen informing subjects how often their individual decision had been selected as the group decision for each partner (update, 15 s boxcar). We parametrically modulated the signalled condition regressor using our task factors: (1) K, contrast-coded coherence, {\u22121.5,\u22120.5,.5,1.5}; (2) K , contrast-coded coherence squared; (3) C, contrast-coded context, {\u22121.5,\u22120.5,.5,1.5}; and (4) C , contrast-coded context squared. For comparability with earlier studies on decision confidence, we also estimated an event-related GLM (GLM2) of the neural response to the presentation of the motion stimulus. This modelled included one condition regressor \u2013 a boxcar lasting the duration of the stimulus (.4\u00a0s) \u2013 parametrically modulated by linear and quadratic coherence terms as defined above. \n\nParametric modulators were not orthogonalized. We excluded trials in which subjects\u2019 choice reaction times were 2.5 SD below or above their grand mean reaction time within a scan run (0\u20132 trials per subject per run). In addition to the condition regressors, we added motion and biophysical parameters as additional \u2018nuisance\u2019 regressors. Regressors were convolved with a canonical hemodynamic response function. Regressors were modelled separately for each scan run, and constants were included to account for differences in mean activation between runs and scanner drifts. A high-pass filter (128 s cutoff) was applied to remove low-frequency drifts. Whole-brain statistical testing was performed by applying one-sample   t  -tests against 0 to the first-level contrast images. We report clusters significant at p<0.05, FWE-corrected for multiple comparisons, with a cluster-defining threshold of p<0.001, uncorrected. For the ROI analysis, we extracted mean contrast estimates within the ROI masks from first-level contrast images and assessed group-level significance by applying one-sample   t  -tests against zero (p<0.05) to the extracted contrast estimates. \n\n\n#### Activity time course analysis \n  \nWe used activity time courses to study the neural encoding of trial-by-trial confidence and assess functional coupling between ROIs. We transformed each ROI mask from MNI to native space and extracted preprocessed BOLD time courses as the average of voxels within each mask. For each scan run, we regressed out variation due to head motion, applied a high-pass filter (128 s cut-off) to remove low-frequency drifts, and oversampled the BOLD time course by a factor of\u00a0~23 (time resolution of. 144 s). For each trial, we extracted activity estimates in a 12 s window time-locked to our event of interest (i.e. from 2 s prior to the onset of the context screen to 10 s after its onset). We excluded trials in which subjects\u2019 choice reaction times were 2.5 SD below or above their grand mean reaction time across trials (1\u201313 trials per subject). We applied a linear regression to each time point and then, by concatenating beta-weights across time points, generated a time course for each predictor of the regression model. We performed a separate analysis for each subject. We tested the group-level significance of a time point by comparing the beta-weights across subjects to 0 (p<0.05, one-sample   t  -test). \n\n\n#### Multivariate analysis \n  \nRepresentational similarity analysis (RSA) of fMRI data was performed using SPM12 and the RSA toolbox ( ). To estimate voxel activity patterns, we constructed an event-related GLM with a condition regressor locked to the context screen (1 s boxcar) for each coherence \u00d7 (signalled) context condition\u00a0(4 \u00d7 4\u00a0=\u00a016 regressors per scan run). The GLM for ROI analysis (GLM3) was based on unsmoothed data, whereas the GLM for searchlight analysis (GLM4) was based on smoothed data. As in GLM1, we included regressors for hidden context and update screen and motion and biophysiological regressors as additional \u2018nuisance\u2019 variables. Regressors were convolved with a canonical hemodynamic response function. Regressors were modelled separately for each scan run, and constants were included to account for differences in mean activation between runs and scanner drifts. A high-pass filter (128 s cutoff) was applied to remove low-frequency drifts. \n\nThe exemplar discriminability index (EDI) is a test of whether an ROI carries information about a set of conditions ( ) \u2013 in our case the 16 coherence\u00a0\u00d7\u00a0context conditions that make up the full task space. The hypothesis is that, if a neural area represents the conditions as distinct, then its voxel activity pattern should be more stable across scan runs   within   conditions than   between   conditions. This hypothesis is tested by first constructing a split-data representational dissimilarity matrix (sdRDM) for each scan run that contains the Mahalanobis distance (i.e. multivariate noise normalisation and Euclidean distance) between the voxel activity pattern in scan run   i   and the voxel activity pattern averaged across scan runs   j   \u2260   i   for all condition pairs and then averaging the run-specific sdRDMs across scan runs. An EDI metric is then be computed as the average dissimilarity across the off-diagonal elements minus the average dissimilarity across the diagonal elements ( ). A positive EDI shows that the voxel activity pattern in an area is more stable within conditions than between conditions and therefore that the area carries information about the conditions. \n\nROI analysis was performed by computing the EDI metric from voxel activity estimates under the first-level model within our ROI masks. As the EDI should theoretically not be below zero, we assessed group-level significance for ROI analysis using a one-tailed sign-rank test (p<0.05). Searchlight analysis \u2013 as executed by the RSA toolbox \u2013 was performed by computing the EDI metric for a spherical cluster of voxels centred at each voxel within each subject\u2019s first-level map. Consistent with previous RSA studies ( ), the diameter of the sphere was 15 mm (around 100 voxels). The sphere was adapted in shape if it was near the edges of a whole-brain group-level mask \u2013 the mask was defined as the intersection of the whole-brain masks obtained for each subject during estimation of the first-level model. Whole-brain statistical testing was performed by applying one-sample   t  -tests against 0 to the first-level EDI maps. We report clusters significant at p<0.05, FWE-corrected for multiple comparisons, with a cluster-defining threshold of p<0.001, uncorrected. We note that the searchlight analysis is not directly comparable to the ROI analysis but, rather, complements it. First, the FPl ROI analysis is more sensitive to subtle pattern information as the FPl ROI contains around 10 times more voxels than the searchlight sphere. Second, our FPl ROI is bilateral and thus contains a substantial proportion of non-contiguous voxels. By contrast, the searchlight sphere is restricted to contiguous voxels within a relatively restricted region and can therefore only identify localised pattern information. Finally, our FPl ROI is anatomically defined and thus has a shape which cannot be captured by a searchlight sphere. \n\nWe note that the number of trials per condition per scan run (i.e. 4) is compatible with previous studies employing RSA ( ). Constraints on per-subject scanning time means that there is an inherent trade-off between the ability to estimate a neural pattern within a condition (the estimate improves with repetitions of a condition) and the ability to estimate neural pattern dissimilarities between conditions (the estimate improves with the number of conditions). We adopted a condition-rich design as our goal was to test whether an ROI treats the different conditions (i.e. task states) as distinct and not to characterise the ROI pattern for any particular condition. We note that our analysis of the sub-spaces of coherence and context were based on 16 trials per condition per run and not four trials per condition per run as in the analysis of the full task space. \n\n\n\n### Data and code availablity \n  \nData and code for reproducing figures as well as associated analyses are available on GitHub:  ;   (copy archived at  ).\u00a0Whole-brain group-level statistical maps are available on NeuroVault:  . \n\n\n \n", "metadata": {"pmcid": 7377905, "text_md5": "685755a1f914b72928023066c574ae7f", "field_positions": {"authors": [0, 71], "journal": [72, 77], "publication_year": [79, 83], "title": [94, 144], "keywords": [158, 255], "abstract": [268, 1277], "body": [1286, 72651]}, "batch": 1, "pmid": 32701449, "doi": "10.7554/eLife.56477", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7377905", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7377905"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7377905\">7377905</a>", "list_title": "PMC7377905  Private\u2013public mappings in human prefrontal cortex"}
