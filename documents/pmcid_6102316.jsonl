{"text": "Wolf, Dhana and Mittelberg, Irene and Rekittke, Linn-Marlen and Bhavsar, Saurabh and Zvyagintsev, Mikhail and Haeck, Annina and Cong, Fengyu and Klasen, Martin and Mathiak, Klaus\nFront Hum Neurosci, 2018\n\n# Title\n\nInterpretation of Social Interactions: Functional Imaging of Cognitive-Semiotic Categories During Naturalistic Viewing\n\n# Keywords\n\nsocial cognitive neuroscience\nnatural film viewing\nfunctional imaging\nsemiotics\nsocial interaction\n\n\n# Abstract\n \nSocial interactions arise from patterns of communicative signs, whose perception and interpretation require a multitude of cognitive functions. The semiotic framework of Peirce\u2019s Universal Categories (UCs) laid ground for a novel cognitive-semiotic typology of social interactions. During functional magnetic resonance imaging (fMRI), 16 volunteers watched a movie narrative encompassing verbal and non-verbal social interactions. Three types of non-verbal interactions were coded (\u201cunresolved,\u201d \u201cnon-habitual,\u201d and \u201chabitual\u201d) based on a typology reflecting Peirce\u2019s UCs. As expected, the auditory cortex responded to verbal interactions, but non-verbal interactions modulated temporal areas as well. Conceivably, when speech was lacking, ambiguous visual information (unresolved interactions) primed auditory processing in contrast to learned behavioral patterns (habitual interactions). The latter recruited a parahippocampal-occipital network supporting conceptual processing and associative memory retrieval. Requesting semiotic contextualization, non-habitual interactions activated visuo-spatial and contextual rule-learning areas such as the temporo-parietal junction and right lateral prefrontal cortex. In summary, the cognitive-semiotic typology reflected distinct sensory and association networks underlying the interpretation of observed non-verbal social interactions. \n \n\n# Body\n \n## Introduction \n  \nDuring social interactions, a multitude of auditory and visual cues interact to convey meaning. These cues range from spoken words and manual gestures to facial expressions, eye gaze, body orientation, and body movements ( ;  ;  ;  ). Interpreting social interactions requires the interaction of various cognitive functions; among these are social attention mechanisms, mentalizing, language comprehension, and the recognition of faces, communicative gestures, goal-directed movements, and emotions ( ;  ;  ). In a laboratory setting, naturalistic stimuli such as movies or film sequences capture this complexity because they provide a means to represent the interacting information dynamically and within context ( ;  ;  ). With regard to social interactions in complex scenes, validated comprehensive typologies are lacking and their neural processing is unclear. \n\nDuring watching movies or film sequences, different neural networks were found involved depending on the study protocol and stimulus material. The most consistently reported neural correlates of social-cognitive functions encompass superior temporal gyrus (STG), temporo-parietal junction (TPJ), medial prefrontal cortex (PFC), fusiform gyrus, and precuneus ( ;  ;  ;  ). In particular, the posterior STG and TPJ of the right hemisphere serve as key regions during the processing of real-life social interactions and joint attention ( ; for a meta-analysis see  ). Both regions may contribute to the analysis of social relations in movie clips ( ). Specific social signals in movies (e.g., faces, movement, social interactions, or speech) may even partially segregate four networks ( ): Scenes depicting social interactions engaged two of those networks, namely a temporal-amygdala network and a prefrontal-insula network. The introduction of an explicit mentalizing task modulated neuronal recruitment patterns ( ).; rating an agent\u2019s intention activated three independent neural networks, i.e., for face processing and recognition, language comprehension, as well as self-referential mental activity. Taken together, the significance of several cortical and subcortical structures for the processing of social interaction has become evident, but their specific contribution to the interpretation of interaction events, especially during naturalistic stimulation, remains to be determined. \n\nAlthough social interactions comprise several interwoven, multimodal cues, a behavioral pattern, as a whole, acts as a communicative sign and can thus be described using sign theory (semiotics). Semiotic categories describe cognitive categories, among other related phenomena ( ). Thus, semiotic models are amenable to cognitive-behavioral and neuroscientific testing ( ;  ;  ). Among one of the most influential contributions to the field of semiotics are the UCs introduced by Charles Sanders Peirce ( ,  ). Peirce\u2019s theory has been considered an appropriate semiotic framework for the study of cognitive processes ( ;  ;  ;  ) and has been applied to theoretical and empirical investigations in the fields of cognitive semiotics, linguistics, media science, and neurosciences. This semiotic theory is well suited for neuroimaging studies of multimodal communication because it emphasizes the perspective of the interpreting mind ( ), represented by the observers brain activity. This framework may describe the relation between perceived signs (e.g., the interactions shown in movie clips) and the   interpretant   ( ), i.e., the resulting cognitive representation in the participant\u2019s mind and subsequent brain activity during a functional magnetic resonance imaging (fMRI) experiment. \n\nWith regard to the representation, transmission, and interpretation of signs, Peirce\u2019s UCs distinguish between three levels: \u201cFirstness\u201d pertains to potential, not-yet-resolved meaning; \u201cSecondness\u201d encapsulates the specific, contextualized meaning of a sign, particularly of non-habitual and non-conventional signs; and \u201cThirdness\u201d involves entrenched habits, patterns, and rules ( ). While semiotic categories typically interact to various degrees in a given sign process, one of them can be expected to predominate and, thus, determine the sign\u2019s main function, as well as the way it is perceived and interpreted ( ). We categorized non-verbal social interactions occurring within a film sequence into three types (  Figure   ): (1) \u201cunresolved\u201d interactions are ambiguous in the respective situation and their outcomes are not yet determined (emphasizing Firstness); (2) \u201cnon-habitual\u201d interactions counteract learned behavioral patterns and are disambiguated by the local context (emphasizing Secondness); and (3) \u201chabitual interactions\u201d include implicitly or explicitly learned behavioral patterns, which conform to social conventions (emphasizing Thirdness). (4) Verbal interactions largely rely on the conventional codes of a given language and culture and are subsumed in a forth category (high degree of Thirdness; see   Figure   ). This operationalization aims at the description of the sign-interpretant relation with respect to the UCs. We yielded three processing modes for the interpretation of non-verbal interactions and one for all verbal interactions, because spoken language is highly conventionalized and dominated by the Thirdness category. \n  \nCoded interaction types. Social interaction events occurring in the movie excerpt were annotated.   (A)   Peirce\u2019s semiotic framework of the Universal Categories inspired the differentiation of three cognitive processes during the interpretation of non-verbal and one during verbal social interactions. (1) Unresolved non-verbal interactions are ambiguous and the social situation is not yet resolved (reflecting the Firstness category of potential, not-yet-resolved meaning); (2) \u201cnon-habitual interactions\u201d counteract learned behavioral patterns and are disambiguated by the local context (reflecting the Secondness category of contextualized meaning); (3) \u201chabitual interactions\u201d rely on learned behavioral patterns and social conventions (reflecting the Thirdness category of conventional and habitual meaning); and, finally (4) words rely on the conventional codes of the language and thus verbal interaction reflect always the Thirdness category.   (B)   The movie frames depict exemplary events for each of the coded types of social interactions: (1) unresolved: two people wordlessly stare at each other; (2) non-habitual: a cyclist is grabbed by a passerby; (3) habitual: a carried child is touched in greeting; and (4) verbal: two persons engage in a conversation.   (C)   Visualization of the time series of coded events in the 12-min movie excerpt. Copyrights of screen shots:  . \n  \nPeirce\u2019s UCs were chosen as the theoretical background to study social interactions because they have inspired various theoretical models that have been widely used to describe and interpret communicative actions and signs. However, experimental evidence is still scarce for Peirce\u2019s basic constructs. Peirce aimed at a general semiotic theory that accounts for all kinds of sign processes in all kinds of modalities, including those occurring in nature and scientific inquiry; hence, his model of sign processes goes beyond communication   per se   ( ;  ). The UCs have inspired theoretical models developed to characterize and interpret manual gestures (e.g.,  ,  ;  ;  ,  ,  ;  ), onomatopoeia in language ( ;  ), and images ( ;  ), and further, describe narrative comprehension in both spoken and written stories ( ), film sequences ( ,  ;  ) and comics ( ;  ; see also   on multimodality). Qualitative analyses utilized aspects of Peirce\u2019s UCs for the investigation of mental imagery, human gestures, language evolution, and developmental aspects of communication and culture (for a review, see  ). However, despite many theoretical and qualitative approaches, empirical investigations are still rare. Best known, the sign-object relation is one aspect of the UCs, and has founded a prominent theoretical framework for empirical analyses of manual gestures (as \u201ciconic\u201d (UC1), \u201cdeictic\u201d (UC2), and \u201cemblematic\u201d (UC3) gestures;  ) in behavioral and neuroimaging studies on gesture perception and comprehension (for reviews, see  ;  ;  ). The sign-interpretant relation of the UCs has scarcely been used as a construct for neuroimaging studies. We investigated conventionality in co-speech gestures with the sign-interpretant relation of thirdness (UC3,  ). Perceiving a gesture as conventional increased intersubject covariance (ISC) in left inferior frontal gyrus (IFG) and posterior STG. The present study employed aspects of the UCs to create stimulus categories in a neurocognitive experiment. Social interactions were labeled with semiotic categories derived from the UCs and their neural response patterns were analyzed. \n\nAssuming that semiotic categories influence the cognitive and neural processing of the interpretant, the semiotic characterization of social interactions differentiates neural processes during the observation of social interactions. Functional MRI recorded neural responses to social interactions portrayed during a 20-min movie narrative. The three types of non-verbal interactions (unresolved, non-habitual, and habitual) and any verbal interactions were coded. First, we aimed to confirm that this method yields neural correlates of social interactions encompassing the relevant sensory, language, visual, and social cognitive networks. In specific, we hypothesized that brain areas supporting the interpretation of verbal interactions lean more toward auditory processes whereas non-verbal interactions elicit stronger visuo-spatial processing. Second, the recruitment of these brain areas during the observation of non-verbal interactions was expected to depend on the predominant semiotic category (visible by the extracted beta values). Third, we explored neural patterns contributing to the encoding of Peirce\u2019s semiotic categories in a whole-brain analysis. \n\n\n## Materials and Methods \n  \n### Study Participants \n  \nSixteen right-handed native German speakers (seven women, age 26.1 \u00b1 3.8, range 22\u201334 years) participated in the present study. Participants had normal or corrected-to-normal vision, normal hearing, and no history of psychiatric, neurological, or mental disorders. The study protocol was approved by the local Ethics Committee and the experiment was designed and conducted in accordance with the Declaration of Helsinki. All participants gave written informed consent and received financial reimbursement. \n\n\n### Stimulation \n  \nParticipants were presented with a film sequence showing a 20-min excerpt from the German movie \u201cLola rennt\u201d (Engl.: \u201cRun Lola Run\u201d; 10:20\u201330:20 min; X-Filme Creative Pool, Germany, 1998). The movie excerpt was chosen because it comprises a self-contained narrative with a fast-paced story line within a reasonable time frame (20-min). Video was delivered by a projector system with reflecting mirrors (Psychology Software Tools, Sharpsburg, PA, United States), and audio was delivered by earplugs (Nordic Neurolab Bergen, Norway). The sound was individually adjusted to a comfortable hearing level. Stimulus delivery and timing was controlled using the stimulation software Presentation (Neurobehavioral Systems Inc., United States). Before the film sequence started, a fixation cross was presented for 25 s. The participants were asked to watch attentively. \n\n\n### Coding of Social Interactions in the Movie \n  \nA film sequence is a naturalistic stimulus in which a multitude of features interact. In order to model the specific appearance of social interactions we used an established content-coding approach for model-based analysis ( ;  ;  ,  ;  ). We annotated the onsets and duration of social interaction events in the movie excerpt on a frame-by-frame basis with 67 ms accuracy, corresponding to a 15 Hz frame rate. The content-coding system distinguished three types of non-verbal social interactions: (1) unresolved, (2) non-habitual, and (3) habitual; as well as four verbal interactions (for an overview, see   Figure   ). For each event, exactly one of the interaction types was annotated. Verbal interactions were coded whenever speech was involved in the interaction event. The duration of a verbal interaction event corresponded to the duration of the utterance. Pauses up to two seconds between words or utterances were coded as continuous verbal interaction. Pauses lasting longer than two seconds were coded as a non-verbal interaction. Non-verbal interactions could immediately precede or follow a verbal interaction (e.g., an \u201cunresolved interaction\u201d is followed by a \u201cverbal interaction\u201d). Furthermore, non-verbal interaction types may immediately follow each other (e.g., an \u201cunresolved interaction\u201d is followed by a \u201chabitual interaction\u201d). The complete movie excerpt was annotated twice by two independent coders. Inter-coder reliability for the differentiation between interaction types was determined with Krippendorff\u2019s alpha (.62). In cases when the coders disagreed, a supervisory decision was taken by a third coder (D.W.). In total, 170 interaction events were annotated yielding a total duration of 476.5 s (average duration: 2.8 \u00b1 5.8 s, mean \u00b1 SD). Of those interaction events, 65 were coded as \u201cunresolved\u201d (total duration: 132.6 s; average: 1.7 \u00b1 2.5 s), 19 events were coded as \u201cnon-habitual\u201d (total duration: 10.0 s; average: 0.5 \u00b1 0.6 s), 22 events were coded as \u201chabitual\u201d (total duration: 42.2 s; average: 1.9 \u00b1 2.5 s), and 64 events were coded as \u201cverbal\u201d (total duration: 291.7 s; average: 4.6 \u00b1 8.8 s). \n\n\n### MR Data Acquisition \n  \nFunctional MRI was conducted using a 3 Tesla Siemens Scanner (Magnetom Trio, Siemens Medical Systems, Erlangen, Germany) and a 32-channel phased-array receive-only head coil. Echo planar imaging (EPI) collected functional images sensitive to the blood-oxygenation-level-dependent (BOLD) contrast. The applied EPI sequence acquired multiple echoes after a single excitation pulse. Subsequently, the obtained images were weighted and combined. This procedure increases signal-to-noise ratio ( ), which may be particularly beneficial for investigations that utilize naturalistic stimuli. With the following parameters, 487 volumes were acquired: 24 slices; echo time (TE) = 17.0, 45.9, and 74.9 ms; repetition time (TR) = 2540 ms; flip angle (FA) = 90\u00b0; slice thickness = 3.5 mm; slice gap = 0.5 mm; matrix size = 64 \u00d7 64, field of view (FOV) = 224 mm  \u00d7 224 mm ; voxel size = 3.5 mm  \u00d7 3.5 mm  \u00d7 3.5 mm , and bandwidth = 2232 Hz/pixel. \n\n\n### Data Analysis \n  \nFunctional MRI data analysis was conducted using the software Statistical Parametric Mapping (SPM 8, Wellcome Department of Imaging Neuroscience UCL, London, United Kingdom). The first five volumes of each session were discarded to reduce T1 saturation effects. Images were spatially realigned, normalized to the stereotactic MNI space (Montreal Neurological Institute;  ) and resampled to 2 mm \u00d7 2 mm\u00d72 mm voxels. Spatial smoothing with a full-width-at-half-maximum (FWHM) Gaussian kernel of 12 mm was applied to the normalized data. The single-echo images were combined after normalization based on the optimized-CNR approach, i.e., each image voxel was weighted with a function of the estimated signal-to-noise ratio and the expected BOLD sensitivity ( ;  ; see   for detailed methodological descriptions). \n\nThe onset and duration of each coded event entered a general linear model (GLM) with one predictor of interest for each interaction type (unresolved, non-habitual, habitual, and verbal). Using the canonical response function, a model for the BOLD responses to the events was constructed. In the first-level statistical analysis, the contrast of the four stimuli types against the baseline (the ongoing movie) was determined. The four contrast maps of each subject entered the repeated-measures ANOVA for second-level analysis. An   F  -test determined effects of the four interaction types against baseline.   Post hoc   t  -tests compared the verbal with the non-verbal interactions. A second   F  -test explored the activation patterns differentiating the semiotic categories of observed non-verbal interactions.   Post hoc   t  -tests compared non-verbal interaction types in a pairwise fashion. Each map in the second-level group analyses was corrected with a voxelwise family-wise error (FWE;  ) of   p   < 0.05. All remaining clusters survived a clusterwise   p   < 0.05 thresholding. \n\nRegion-of-interest (ROI) analyses investigated differences between the three non-verbal interaction types. Therefore, the selected ROIs differentiated the verbal from the non-verbal interactions and vice versa. For the verbal condition, peak locations were obtained from the contrast \u201cverbal > non-verbal.\u201d For the non-verbal conditions, the inversed contrast \u201cnon-verbal > verbal\u201d was considered; extended clusters were segregated into meaningful anatomical structures according to the AAL atlas ( ): fusiform gyrus (bilateral), calcarine gyrus (bilateral), right IFG pars triangularis (IFG PTr), and right middle frontal gyrus (MFG). Due to the orthogonality of the SPM second-level design matrix, we assumed orthogonality of the estimate for the \u201cverbal versus non-verbal\u201d contrast with the one for the contrasts between the non-verbal subtypes; therefore the data were explored with standard univariate ANOVAs. Significant differences across the non-verbal interaction types were determined with one-factor ANOVAs and corrected for multiple comparisons according to Bonferroni-Holm. Statistics were performed with IBM SPSS (Statistics for Windows, Version 20.0, Armonk, NY, United States). \n\nIn a supplementary analysis the validity of the obtained neural functioning for the processing of verbal information and social interaction was confirmed with anatomical masks from Neurosynth ; this toolbox provides neuroanatomical information based on meta-analysis of fMRI studies. The images for the terms \u201cverbal\u201d (615 studies) and \u201csocial interaction\u201d (94 studies) were merged and served for small-volume correction of the contrasts \u201cverbal > non-verbal\u201d and \u201cnon-verbal > verbal\u201d as well as the individual   t  -contrasts comparing the non-verbal interaction types. Segregation of anatomical structures and the extraction of ROI data were performed as described above. Significant differences in peak-voxel activation were explored with univariate ANOVAs. \n\n\n\n## Results \n  \n### Neural Responses to the Observation of Social Interactions \n  \nDuring social interactions, several brain regions exhibited activity increases, including primary auditory and visual areas as well as higher order visual pathways (  Figure    and   Table   ). Previous studies reported medial PFC activations (e.g.,  ), which emerged in our data only after lowering the threshold to   p   < 0.001 uncorrected. Differences between verbal and non-verbal interactions were investigated with   t  -tests contrasting responses to verbal interactions against the average response to the three non-verbal interaction types. The contrast \u201cverbal > non-verbal\u201d yielded strong bilateral activation in auditory processing areas (STG extending into middle temporal gyrus (MTG);   Figure    and   Table   ). The reversed contrast \u201cnon-verbal > verbal\u201d yielded widespread brain regions, in particular, the visual pathway emerged encompassing occipital, inferior temporal, and superior parietal cortices as well as right prefrontal areas (  Figure    and   Table   ). \n  \nNeural correlates of social interactions. Social interaction events in a movie narrative were coded as four types (unresolved, non-habitual, habitual, and verbal). An   F  -test across the four predictors revealed widespread brain activation of auditory and visual networks. Such pattern is commonly observed during the perception of naturalistic social stimuli, suggesting an important role for the observation of social interaction events. LH, left hemisphere; RH, right hemisphere; IFG, inferior frontal gyrus; IOG, inferior occipital gyrus; IPL, inferior parietal lobe; ITG, inferior temporal gyrus; MOG, middle occipital gyrus; MTG, middle temporal gyrus; (p)STG, (posterior) superior temporal gyrus; SPL, superior parietal lobe; TPJ, temporo-parietal junction;   z  -coordinates are indicated beneath each slice. \n    \nNeural networks for the processing of verbal and non-verbal interactions. The contrasts between   (A)   verbal (\u201cverbal > non-verbal\u201d) and   (B)   non-verbal (\u201cnon-verbal > verbal\u201d) interactions separated the networks for visual-based and sound-based information processing. ROI analyses of regional peak voxels revealed specific contributions for the non-verbal interaction types (\u201cunresolved,\u201d \u201cnon-habitual,\u201d and \u201chabitual\u201d). Auditory regions were recruited during the observations of unresolved interactions but suppressed during habitual interactions. Non-habitual interactions yielded the involvement of visual and prefrontal areas. LH, left hemisphere; RH, right hemisphere; IFG, inferior frontal gyrus; MFG, middle frontal gyrus; STG, superior temporal gyrus;   p   < 0.05;   p   < 0.01;   p   < 0.001;   z  -coordinates are indicated beneath each slice. \n    \nCluster table for   F  -tests. \n      \nCluster table for comparison between verbal and non-verbal interactions. \n    \nTo differentiate the effect of the three non-verbal interaction types, a ROI analysis was performed in the peak-voxels of the contrasts between verbal and non-verbal interactions. Verbal interactions yielded higher responses in bilateral auditory cortices than non-verbal ones [left: MNI (  x,y,z  ) = \u221262, \u221226, \u22122 (STG); right: 62, 0, \u22128 (STG);   Figure   ]. In the left hemispheric ROI only, a modulation with respect to the three non-verbal interaction types emerged (left:   F   = 7.00,   p   = 0.002; right:   F   = 1.78,   p   = 0.18, n.s.). The activation differences were characterized by a gradient from unresolved to non-habitual to habitual interactions (see inserts in   Figure   ): In   post hoc   t  -tests, unresolved interactions yielded higher activity as compared to habitual interactions (  t   = 5.28,   p   < 0.001) and to non-habitual interactions (  t   = 2.60,   p   = 0.02; habitual versus non-habitual:   t   = 0.98,   p   = 0.344, n.s.). For the non-verbal contrast, six ROIs emerged: left fusiform gyrus (\u221232, \u221264, and \u221218), right fusiform gyrus (28, \u221238, and \u221222), left calcarine gyrus (2, \u221280, and \u22124), right calcarine gyrus (16, \u221256, and 8), right IFG PTr (54, 24, and 32), and right MFG (44, 0, and 58). In each ROI a significant difference between the non-verbal conditions emerged (all   p   < 0.001;   Figure   ). In the   post hoc t  -test, non-habitual interactions yielded larger activation than the two other types (all   t   > 3.80,   p   < 0.003; see inserts in   Figure   ). After applying the Neurosynth-based mask, two ROIs emerged for verbal interactions over nonverbal interactions (peak voxels: left STG: \u221262, \u221226, and \u22122; right STG: 62, \u22122, and \u22126) and five ROIs for non-verbal interactions (peak voxels: left fusiform gyrus: \u221232, \u221262, and \u221218; right fusiform gyrus: 30, \u221262, and \u221216; left calcarine gyrus: \u221210, \u221290, and 4; right calcarine gyrus: 14, \u221268, and 8; right IFG PTr: 54, 24, and 32). The Neurosynth-mask did not cover the cluster detected in the right MFG. In each of the remaining ROIs, the significant differences between the non-verbal conditions as well as the larger activation for non-habitual interactions were confirmed (all   p   < 0.001;   Supplementary Figure   ). Thus, the functional responses obtained during watching naturalistic stimulation were in accordance with meta-analytical maps for verbal stimulation and social interactions. The widespread activation of cortical regions during the processing of non-verbal interactions was grounded in the processing of non-habitual interactions. \n\n\n### Brain Regions Underlying UCs in Non-verbal Interactions \n  \nWe further explored brain regions that engaged differentially in the encoding of the semiotic categories of the observed non-verbal social interactions. Thereto, we conducted mappings of the differences between the three conditions with an   F  -test and   post hoc t  -tests. The   F  -test yielded an extended pattern of brain regions with the highest activations in the fusiform gyrus and middle occipital gyrus (MOG; see   Figure    and   Table   ), similar to those obtained for the contrast between non-verbal and verbal interactions (compare with   Figure   ). Of the six directed comparisons in the   post hoc t  -tests, four yielded significant clusters at a threshold according to a   p   < 0.05 (  Figure    and   Table   ). First, specific contributions of both other types \u2013 anticipation and non-habituality \u2013 emerged when contrasted to habitual interactions: Neural responses were increased in the left STG and TPJ during unresolved interactions (right upper panel in   Figure   ) and in the right fusiform gyrus and bilateral TPJ during non-habitual interactions (left upper panel in   Figure   ). Using the unresolved condition as baseline, habitual interactions yielded higher activation in the left parahippocampal gyrus and bilateral MOG (right lower panel in   Figure   ), and non-habitual interactions elicited higher activation in the right IFG as well as bilateral fusiform gyrus, TPJ, and MOG (left lower panel in   Figure   ). The contrasts \u201cunresolved > non-habitual\u201d and \u201chabitual > non-habitual\u201d did not yield differences at the same threshold. After correction of the contrasts with the Neurosynth-based mask, each of the detected clusters fell \u2013 at least partly \u2013 into the brain mask (  Supplementary Figure    and   Supplementary Table   ). Involvement of the reported brain regions in processing of verbal information and social interaction was thereby validated based on this meta-analytical approach. \n  \nNeural networks for the processing of non-verbal interactions.   (A)   The specific   F  -test differentiated processing networks for the semiotic categories (\u201cunresolved,\u201d \u201cnon-habitual,\u201d and \u201chabitual\u201d).   (B)   Post hoc t  -maps determined specific effects in four directed contrasts. As an extension to the ROI analysis, the TPJ may be relevant for the interpretation of unresolved or non-habitual interactions, whereas the hippocampus and the LOC responded most strongly to habitual interactions. LH, left hemisphere; RH, right hemisphere; IFG, inferior frontal gyrus; LOC, lateral occipital complex; pSTG, posterior superior temporal gyrus; MFG, middle frontal gyrus; MOG, middle occipital gyrus; SOG, superior occipital gyrus; TPJ, temporo-parietal junction;   z  -coordinates are indicated beneath each slice. \n    \nCluster table for comparison between non-verbal interaction types (  Figure   ). \n    \n\n\n## Discussion \n  \nWe identified types of non-verbal social interactions in a movie narrative based on a coding scheme derived from the semiotic framework of Peirce\u2019s UCs and segregated neural processes during the observation of such interactions. Three non-verbal interaction types were determined: unresolved (predominant Firstness Category), non-habitual (Secondness), and habitual (Thirdness). These non-verbal interactions together with the verbal ones yielded activations in brain structures involved during naturalistic viewing conditions. The non-verbal interactions yielded lower auditory activation than verbal ones, but significant effects of type emerged: Unresolved events primed auditory cortex, whereas habitual ones suppressed it. Increased activity after non-verbal compared to verbal interactions in the visual cortex and right lateral PFC was due to non-habitual interactions. Further exploration across interaction types revealed that non-habitual interactions yielded higher TPJ activations than unresolved and, most markedly, habitual interactions. The latter recruited the parahippocampal gyrus and lateral occipital complex (LOC) more than unresolved interactions. In summary, Peirce\u2019s cognitive-semiotic categories distinguished three modes for interpreting social interactions. Their underlying cognitive mechanisms led to neural representations of perception and interpretation during the observation of an ongoing film sequence. \n\n### Neural Responses to Social Interactions \n  \nWidespread brain regions encompassing visual, auditory, and object-processing areas responded to social interactions shown in a movie. Similar patterns of activation have been observed when contrasting social versus non-social contents depicted in photographs ( ) and movie clips ( ;  ;  ). In particular, the reported brain structures comprised bilateral fusiform cortex, superior temporal cortex extending into the TPJ, right inferior frontal cortex, and dorsomedial PFC. Such pattern is readily expected from sensory and perceptual processing, but lacks involvement of the language networks (i.e., left IFG \u201cBroca\u201d and pSTG \u201cWernicke\u201d). Similarly, under naturalistic stimulation conditions in previous studies not explicitly investigating language processing, language network responded weakly only ( ;  ;  ). The weak recruitment of prefrontal structures in our study (not surpassing the corrected threshold) may be explained by the lack of an explicit task aiming at social cognition ( ;  ). Indeed, frontal-cortical activation was found to be variable during film clips ( ;  ). Taken together, the content-coded social interactions yielded activation patterns in established networks for perceptual processes and social cognition, yielding validity to our event related coding of social interactions during naturalistic stimulation. \n\n\n### Neuronal Correlates of Interactions Types \n  \nThe contrast between non-verbal and verbal interactions separated networks for auditory and visual processing. As expected, the bilateral STG responded most strongly to verbal interactions, whereas non-verbal interactions activated visual pathways. The latter finding suggests that during verbal stimulation visual cues are less processed ( ). In addition to this clear pattern, the non-verbal, non-auditory interactions yielded a cross-modal modulation in the bilateral STG extending into the MTG. Both the ROI analysis and the comparative mapping across interaction types revealed that STG recruitment was increased for unresolved interactions and was decreased for habitual interactions. Attempts to disambiguate unresolved, socially relevant interactions may prime temporal auditory areas to seek additional auditory cues. In a similar vein, during an audio-visual emotion judgment task, the influence of one modality was greater when the other modality provided ambiguous information ( ). This effect is thought to be based on cross-modal modulation of basic perception. For instance, magnetoencephalographic studies reported anticipatory pre-activation of auditory cortex by visual motion cues ( ) and modulatory effects of predictability in an audio-visual apparent motion task ( ). The cross-modal priming effect also enhances processing of communication and interaction. A modulation of superior temporal regions supporting auditory processing has been reported for changes in perceived communicative intent ( ), contextual embedding of speech ( ), stimulus familiarity ( ), and perceived intentionality of actions ( ). Taken together, the STG and MTG were sensitive to interpretation processes for communicative actions and interactions. Thus, in the absence of speech, ambiguous visual information (unresolved social interactions, Firstness category) increased neural involvement in processing anticipated speech and behavior. \n\nNon-verbal interactions recruited visual areas and the right lateral PFC more than verbal interactions. This activation was entirely due to responses to non-habitual interactions (Secondness category) and not to the unresolved or habitual ones. It seems that observing non-habitual interactions required enhanced visual processing. Implication of the right lateral PFC regions indicates that the processing focus may be particularly on the contextualization of action and movement patterns. There is evidence that both the right IFG and MFG are involved in the representation of goal-directed aspects of actions ( ) and in the interpretation of actions in social contexts ( ). Indeed, the lateral PFC supports learning and employing rule knowledge relevant to actions (for a review, see  ). More specifically, the right PFC contributes to the creation and testing of rules ( ;  ), particularly when these need to be integrated into contextual information ( ;  ). In previous research, the involvement of the lateral PFC during the learning and application of rules has been implicated in both concrete experiential tasks and the formation of abstract behavior-independent rules ( ;  ), and, further, to patterns of appropriate behavior within a given social context ( ;  ;  ). In the same vein, the right IFG was related to contextual integration involved in the comprehension of unconventional communicative object configurations ( ). Our finding that observing non-habitual interactions recruits right IFG/MFG contributes to this line of research. When encountering a behavior which discords with context-based expectations, new hypotheses of social rules and intentions need to be formulated; this process may recruit right IFG/MFG. This view is in agreement with the conceptualizing of Secondness by Peirce, where the interpreter contextualizes signs and has not yet formed rules ( ). \n\nIn non-habitual interactions the observed agent did not act in accordance with socially accepted behavior and, therefore, displayed unexpected behaviors that contrasted with the observer\u2019s predictions ( ). This may have led, first, to an allocation of attention toward the agent\u2019s actions ( ) as well as toward the reaction of the interacting partner, and, second, to a re-evaluation and remodeling of the agent\u2019s intentions and motivations ( ;  ). When directly contrasting non-habitual with habitual interactions and with unresolved interactions, we detected particularly strong bilateral TPJ activation. A susceptibility of TPJ to other people\u2019s intentions was demonstrated for the right TPJ in response to observing incorrect goal-oriented hand/arm movements ( ), observing motoric and social errors ( ), and intentional whole body action ( ). These findings indicate enhanced recruitment of TPJ during the evaluation and modeling of an observed agent\u2019s intentions. \n\nAn alternative explanation for increased activation in visual processing areas, TPJ, and right frontal cortex may reside in the increased saliency of unexpected behaviors. Although expectation (stimulus is expected versus unexpected) and attention (stimulus is relevant versus irrelevant) are dissociable mechanisms in the visual system ( ), both may have interacted during the observation of non-habitual interactions. Increased activation in the right TPJ and the IFG has been found for experimentally induced competition between several salient visual events during free viewing of movie clips ( ). However, the scenes depicted single or interacting people and thus were social in nature as well. Furthermore, a sharp differentiation between salience-induced attentional processes and mentalizing processes (as part of Theory of Mind) may be inconsequential during social cognition. Both processes can be understood in terms of contextual updating, which is a suggested key function of TPJ ( ). Therefore, during observation of socially relevant scenes, attentional processes may help evaluate the appropriateness of the observed actions and model possible motives and reactions of the interacting partner. \n\n\n### Habitual Non-verbal Interactions \n  \nThe contrasts between verbal and non-verbal interactions have elucidated the distinct contributions of unresolved and non-habitual interactions. Further, specific effects for habitual interactions (Thirdness category) emerged in the direct contrasts between non-verbal interaction types. The bilateral LOC and the left parahippocampal gyrus were activated more in response to habitual than to unresolved interactions. Habitual \u2013 and thus rule-conforming \u2013 actions are well-learned and regularly encountered in everyday life. Therefore, visual scene analysis and matching input to memory representations may dominate the interpretation process. The LOC is traditionally associated with processing and recognizing faces, body parts, and goal-directed movements as well as general motion patterns (for a review, see  ). The parahippocampal gyrus contributes to associative memory and visuo-spatial processing (for a review, see  ). Therefore, the LOC-parahippocampal network may represent real-world scenes complementing the perception of photographs ( ) and movie clips ( ). Interpreting interactions as habitual and conforming to social rules seems to be associated with processing in object-recognition and memory structures. \n\nHabitual interactions are not only well-learned but also conform to schematic behavioral patterns and social rules. The LOC-parahippocampal network may additionally contribute to the extraction, recognition, and contextualization of behavioral patterns. Involvement of the LOC has been reported for contextual guidance during visual search in complex scenes ( ), the creation of category-level templates for recognizing humans and objects ( ), and the abstraction of actions from agents ( ). Similarly, increased activation in the parahippocampal gyrus has been reported both for goal-oriented actions ( ) and for more abstract functions of scene analysis such as scene categories ( ), locational concepts ( ), and perceptual schema representations ( ). These processes may contribute to the understanding of action schemas, which are, on a mechanistic level, the basis of habitual social interactions. Thus, our results indicate that during the observation of habitual interactions, the parahippocampal gyrus and the LOC interact to evaluate the observed action patterns. \n\n\n### Universal Categories and Neural Activation Patterns \n  \nThe interpretation of social interactions requires synergy of various cognitive functions raging from multimodal perception and social attention to language comprehension and mentalizing ( ;  ;  ). As novel means to a comprehensive typology, Peirce\u2019s semiotic framework of UCs was utilized to inform three types of social interactions. These interaction types were presented in a movie context and yielded distinct neural patterns. The Firstness category is predominant in unresolved social interactions, which recruited bilateral STG. Conceivably, in ambiguous social situations, attention was directed toward the auditory modality (e.g.,  ), as is predicted by the \u201cprinciple of inverse effectiveness\u201d ( ). The perception of a stimulus can be altered by a cue from another modality ( ); in particular, audiovisual stimuli of lower intensity yield larger recognition benefit that those with higher intensity ( ;  ). During unresolved interactions, when information density of the visual modality was reduced, auditory processing increased. Spoken language is highly codified and thus effectively resolves a situation. \n\nSocial interactions of the Secondness category (non-habitual) required the highest processing demand in visuo-spatial, mentalizing, and contextual rule-learning areas (IFG). This pattern suggests increased attention toward the unexpected behavior and a re-evaluation of the observed agent\u2019s intentions within the situational context ( ). This mismatch between prior expectations and reality triggers a cognitive prediction error, which has been associated particularly with dorsolateral PFC ( ;  ). Prediction error processing elicits attentional orienting and underlies mentalizing and contextual learning ( ). \n\nThe observation of habitual interactions (Thirdness category) recruited brain regions supporting conceptual processing and associative memory retrieval. Habitual behaviors may be encoded as learned action patterns and social schemas ( ), Social schemas are memory representations of typical contexts ( ), which guide and facilitate the processing of social information ( ) and their reconstruction from memory ( ); the latter involves the ventromedial PFC regions ( ) rather than lateral PFC. \n\nTaken together, characterizing non-verbal social interactions with Peirce\u2019s cognitive-semiotic categories enabled the holistic neurosemiotic investigation of complex social cognition. Such a semiotic approach offers a novel means to investigate the neural representation of communication in naturalistic stimuli. \n\nBuilding on Peirce\u2019s semiotic theory, various theoretical frameworks highlight specific aspects of communicative signs. For instance, the UCs have been instrumental to empirical analyses of manual gestures ( ,  ;  ;  ,  ,  ;  ). McNeill\u2019s Peirce-inspired differentiation of gestures into iconic gestures (icon, Firstness category), deictic gestures (index, Secondness category), and emblems (symbol, Thirdness category;  ,  ) has become a prominent strand within gesture research. Neuroimaging studies on gesture perception and comprehension revealed that manual gestures in general recruited the language systems (IFG and posterior superior temporal sulcus) and the action-movement systems (inferior parietal and premotor cortex;  ) whereas iconic gestures, representing salient visual features of an object referred to in speech, activated a fronto- posterior temporal network ( ). Furthermore, emblems, being symbolic and highly conventionalized signs, recruited the language networks ( ;  ). \n\nSymbolic and conventionalized meaning corresponds to Thirdness in Peirce\u2019s UCs ( ;  ;  ) and is considered in neurocognitive investigations not only for gesture comprehension ( ;  ) but also for the perception of communicative signs in a broader sense ( ;  ;  ). For instance, pictures of objects activated the language network (like words) if they were perceived as symbolic ( ) or when they conveyed abstract social meaning ( ). Furthermore, Peirce\u2019s UCs have inspired theories regarding the emergence of social conventions and symbolic communication during language evolution ( ) and during child development ( ). These examples emphasize the applicability of Peirce\u2019s semiotics for the investigation of communicative signs and behaviors with respect to various signal properties. However, since empirical studies are still scarce and the operationalizations vary across studies, the picture is yet incoherent and impedes generalizations ( ;  ). The application of UCs has a high potential with regards to investigating communication processes and should be further explored in the context of social learning or social impairments such as seen in patients with schizophrenia or autism spectrum disorders. \n\n\n### Methodological Considerations and Limitations \n  \nIn order to relate functional responses to the social interaction types we conducted a GLM analysis and corrected the resulting brain maps with voxelwise FWE correction (  p   < 0.05). To minimize spurious activation voxels, only cluster with size according to a cluster-wise FWE correction are reported. Furthermore, localizations were confirmed with a Neurosynth-based a priori mask, with one exception. The cluster in right MFG for non-verbal interactions over verbal interaction failed to overlap with the mask and, thus, may constitute a false positive result and needs to be confirmed in follow up studies. \n\nThe unequal distribution of events and event-durations introduces differences in the amount of observations. This heterogeneity may cause a violation of the heteroscedasticity assumption for analyses of variance. Therefore, the model estimation was done with assuming unequal-variance as provided by SPM. Thus we minimized the statistical bias due to the violation of the heteroscedasticity assumption of the regressors. The imbalance of event numbers and durations constitutes a limitation of the analysis, but also reflects the nature of naturalistic stimulation. Naturalistic stimuli such as movie clips are inherently complex and contain a multitude of diverse, dynamic, and interacting information. Although natural viewing conditions offer superior ecological validity compared to more traditional experimental paradigms, the stimulus conditions are less well controlled ( ). The number of events and the total duration vary across the coded interaction types. With our content-coding based GLM approach, we aimed to model the neural responses to social interaction types by generalizing across movie scenes and, therefore, by and large independently of other movie contents. However, since the presentation of events is not controlled or randomized, the stimuli may differ in complexity and may coincide with other influencing factors or physical characteristics. Nevertheless, the congruent neural patterns to other studies investigating social interactions lend credibility to this pseudo-experimental design, as shown in previous studies employing similar content-coding methodology (e.g.,  ). \n\nThe movie \u201cLola rennt\u201d comprised a large variety of social situations and scenes as well as different cinematographic elements and thus may be considered a comprehensive naturalistic stimulus; nevertheless, the activation patterns may be stimulus-specific and may not generalize to other movie-excerpts. Until now, movie excerpts were mainly analyzed with data driven methods such as ISC and independent-component analysis (ICA), instead of a model-based approach. Therefore, additional studies using model-based analyses need to determine stimulus-independence and generalizability of the here presented activation patterns. \n\nPeirce\u2019s pragmatic approach to communication processes makes his theory well suited for systematic analyses ( ,  ;  ). Our content-coding based design is a theory-driven approach to iteratively obtain a meaningful typology of non-verbal social interactions ( ). The coding results show a good reliability. Validity is, on the one hand, established by the theoretical foundation and, on the other hand, confirmed by the meaningful neural contributions ( ). The approach based on semiotic categories facilitates neurocognitive analysis; however, additional non-categorical, continuous measures may reflect interaction-related features in more detail. Further refinements of the operationalization can target not only the validity of the coding but may employ the UCs to also describe other processes that underlie the perception and comprehension of various kinds of signs. \n\n\n\n## Conclusion \n  \nWe operationalized Peirce\u2019s semiotic typology to describe basic social cognitive categories of non-verbal interactions in a movie narrative. Functional imaging revealed specific and meaningful responses in the brain to the observed events. Firstness: During the observation of unresolved interactions, the ambiguous visual information enhanced neural involvement in bilateral STG even in the absence of speech \u2013 conceivably as a cognitive mechanism to attend to additional resolving cues in another modality. Secondness: In response to non-habitual interactions that contrasted contextual expectations, the visual and prefrontal cortices as well as the TPJ supported the interpretation of intentions and the re-evaluation of social rules. Thirdness: The interpretation of habitual interactions recruited neural correlates for object recognition and associative memory. Semiotic approaches may help to elucidate mechanisms of social communication beyond confined linguistic theories. \n\n\n## Author Contributions \n  \nDW have designed, tested and applied the content coding scheme, analyzed and interpreted the data, and wrote the manuscript. IM have applied the semiotic theory on content coding scheme and edited the manuscript. L-MR have applied the semiotic theory on content coding scheme and edited the manuscript. SB have planned the study and collected the data. MZ have implemented the fMRI measurement details and assisted in data collection. AH have designed, tested, and applied the content coding scheme. MK have assisted in designing the content coding scheme and edited the manuscript. FC have counselled and assisted in data analysis. KM have planned the study, assisted in data analysis and interpretation, and edited the manuscript. \n\n\n## Conflict of Interest Statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n\n## ID: T1\n\n### Label: Table 1\n\n                                        Peak voxel location Cluster size [voxel]        Peak F-value Peak voxel Peak voxel.1 Peak voxel.2\n0                                        Unnamed: 0_level_1   Unnamed: 1_level_1  Unnamed: 2_level_1          x            y            z\n1              F-test across interaction types (Figure ???)                  NaN                 NaN        NaN          NaN          NaN\n2                                Superior temporal gyrus L\u2217               39,566               74.17        \u221262          \u221226           \u22122\n3                                         Fusiform gyrus R\u2217                  NaN               62.72         28          \u221240          \u221216\n4                              Inferior frontal gyrus PTr R                  409               11.98         48           22           30\n5                                    Middle frontal gyrus R                  NaN                4.87         56           24           36\n6                                        Precentral gyrus R                  NaN                4.36         38            0           42\n7                                 Middle cingulate cortex L                   92               11.41        \u221212          \u221232           40\n8                                    Middle frontal gyrus R                   13                9.44         46            2           60\n9   F-test across non-verbal interaction types (Figure ???)                  NaN                 NaN        NaN          NaN          NaN\n10                                        Fusiform gyrus R\u2217               21,862               65.49         30          \u221262          \u221214\n11                                        Fusiform gyrus R\u2217                  NaN                60.9         32          \u221250          \u221212\n12                              Inferior occipital gyrus L\u2217                  NaN               57.31        \u221236          \u221266           \u22128\n13                             Inferior frontal gyrus PTr R                  957               21.34         50           22           30\n14                                   Middle frontal gyrus R                  NaN                17.3         46            2           60\n15                                       Precentral gyrus R                  NaN               16.85         36            0           40\n16                                 Superior parietal lobe R                   34               15.02         28          \u221256           48\n\n### Caption\n\nCluster table for F-tests.\n\n### Footer\n\nClusters with a minimum cluster size of 10 voxels and located within the brain mask are reported. T- or F-values are reported at pFWE < 0.05; peak voxel coordinates are given in MNI-space. \u2217Cluster extends to other hemisphere. PTr, pars triangularis.\n\n\n\n## ID: T2\n\n### Label: Table 2\n\n                                   Peak voxel location cluster size        peak t-value peak voxel peak voxel.1 peak voxel.2\n0                                   Unnamed: 0_level_1      [voxel]  Unnamed: 2_level_1          x            y            z\n1   Verbal > non-verbal interaction types (Figure ???)          NaN                 NaN        NaN          NaN          NaN\n2                            Superior temporal gyrus L        946.0                11.6        \u221262          \u221226           \u22122\n3                            Superior temporal gyrus R        767.0               10.61         62            0           \u22128\n4   Non-verbal > verbal interaction types (Figure ???)          NaN                 NaN        NaN          NaN          NaN\n5                                        Cerebellum L\u2217     235190.0               28.16        \u221232          \u221264          \u221220\n6                                    Fusiform gyrus R\u2217          NaN               23.91         28          \u221238          \u221222\n7                                    Fusiform gyrus L\u2217          NaN               18.45        \u221228          \u221238          \u221222\n8                         Inferior frontal gyrus PTr R         47.0                7.43         56           26           34\n9                               Middle frontal gyrus R         16.0                6.79         44            0           58\n10                                         Precuneus R         13.0                6.74          2          \u221260           54\n\n### Caption\n\nCluster table for comparison between verbal and non-verbal interactions.\n\n### Footer\n\nClusters with a minimum cluster size of 10 voxels and located within the brain mask are reported. T- or F-values are reported at pFWE < 0.05; peak voxel coordinates are given in MNI-space. \u2217Cluster extends to left hemisphere. PTr, pars triangularis.\n\n\n\n## ID: T3\n\n### Label: Table 3\n\n                           Peak voxel location Cluster size [voxel]        Peak T-value Peak voxel Peak voxel.1 Peak voxel.2\n0                           Unnamed: 0_level_1   Unnamed: 1_level_1  Unnamed: 2_level_1          x            y            z\n1           Unresolved > habitual interactions                  NaN                 NaN        NaN          NaN          NaN\n2                    Superior temporal gyrus L                 55.0                 7.0        \u221256          \u221226           \u22126\n3                  Temporo-parietal junction L                 19.0                6.71        \u221258          \u221252           14\n4           Habitual > unresolved interactions                  NaN                 NaN        NaN          NaN          NaN\n5                      Parahippocampal gyrus L                127.0                8.96        \u221240          \u221250           \u22128\n6                     Middle occipital gyrus L                  NaN                6.63        \u221238          \u221262           \u22122\n7                     Middle occipital gyrus L                366.0                 8.9        \u221236          \u221274           18\n8                     Middle occipital gyrus R                455.0                8.29         48          \u221274           10\n9         Non-habitual > habitual interactions                  NaN                 NaN        NaN          NaN          NaN\n10                 Temporo-parietal junction L                918.0                9.61        \u221250          \u221252           10\n11                 Temporo-parietal junction R                562.0                7.64         52          \u221242           14\n12                            Fusiform gyrus R                 11.0                6.53         24          \u221244          \u221216\n13      Non-habitual > unresolved interactions                  NaN                 NaN        NaN          NaN          NaN\n14                           Fusiform gyrus R\u2217               9215.0                13.0         20          \u221242          \u221214\n15  Inferior frontal gyrus, pars opercularis R                493.0                5.39         48           18           26\n16                          Precentral gyrus R                 72.0                4.72         48            2           50\n\n### Caption\n\nCluster table for comparison between non-verbal interaction types (Figure 4).\n\n### Footer\n\nClusters with a minimum cluster size of 10 voxels and located within the brain mask are reported. T- or F-values are reported at pFWE < 0.05. Peak voxel coordinates are given in MNI-space. \u2217Cluster extends to left hemisphere.\n\n", "metadata": {"pmcid": 6102316, "text_md5": "a8a18ded93e2edb2186b6e906e6cb2cb", "field_positions": {"authors": [0, 178], "journal": [179, 197], "publication_year": [199, 203], "title": [214, 332], "keywords": [346, 445], "abstract": [458, 1845], "body": [1854, 50589], "tables": [50603, 57922]}, "batch": 1, "pmid": 30154703, "doi": "10.3389/fnhum.2018.00296", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6102316", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6102316"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6102316\">6102316</a>", "list_title": "PMC6102316  Interpretation of Social Interactions: Functional Imaging of Cognitive-Semiotic Categories During Naturalistic Viewing"}
